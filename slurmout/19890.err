/ceph/home/muhan01/wangxiyuan/GraphAsSet/utils.py:20: UserWarning: not equivalent to Identity
  warnings.warn("not equivalent to Identity")
/ceph/home/muhan01/wangxiyuan/GraphAsSet/utils.py:20: UserWarning: not equivalent to Identity
  warnings.warn("not equivalent to Identity")
Traceback (most recent call last):
  File "/ceph/home/muhan01/wangxiyuan/GraphAsSet/main.py", line 492, in <module>
    main()
  File "/ceph/home/muhan01/wangxiyuan/GraphAsSet/main.py", line 438, in main
    loss = train(lossfn, model, device, train_loader,
  File "/ceph/home/muhan01/wangxiyuan/GraphAsSet/main.py", line 65, in train
    ampscaler.scale(value_loss).backward()
  File "/ceph/home/muhan01/miniconda3/envs/torch2/lib/python3.10/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/ceph/home/muhan01/miniconda3/envs/torch2/lib/python3.10/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/ceph/home/muhan01/miniconda3/envs/torch2/lib/python3.10/site-packages/torch/autograd/function.py", line 274, in apply
    return user_fn(self, *args)
  File "/ceph/home/muhan01/miniconda3/envs/torch2/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2365, in backward
    out = call_compiled_backward()
  File "/ceph/home/muhan01/miniconda3/envs/torch2/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2341, in call_compiled_backward
    out = call_func_with_args(
  File "/ceph/home/muhan01/miniconda3/envs/torch2/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1249, in call_func_with_args
    out = normalize_as_list(f(args))
  File "/ceph/home/muhan01/miniconda3/envs/torch2/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/ceph/home/muhan01/miniconda3/envs/torch2/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 248, in run
    return model(new_inputs)
  File "/tmp/torchinductor_muhan01/5z/c5zsglt2ipz7nrwb7o2ptxafdb4n42xbghjmrswo73xfuytby27f.py", line 4441, in call
    buf164 = empty_strided((6, 416, 416, 64), (11075584, 26624, 64, 1), device='cuda', dtype=torch.float16)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 23.69 GiB total capacity; 21.90 GiB already allocated; 84.94 MiB free; 22.42 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Traceback (most recent call last):
  File "/ceph/home/muhan01/wangxiyuan/GraphAsSet/main.py", line 492, in <module>
    main()
  File "/ceph/home/muhan01/wangxiyuan/GraphAsSet/main.py", line 438, in main
    loss = train(lossfn, model, device, train_loader,
  File "/ceph/home/muhan01/wangxiyuan/GraphAsSet/main.py", line 65, in train
    ampscaler.scale(value_loss).backward()
  File "/ceph/home/muhan01/miniconda3/envs/torch2/lib/python3.10/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/ceph/home/muhan01/miniconda3/envs/torch2/lib/python3.10/site-packages/torch/autograd/__init__.py", line 200, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
  File "/ceph/home/muhan01/miniconda3/envs/torch2/lib/python3.10/site-packages/torch/autograd/function.py", line 274, in apply
    return user_fn(self, *args)
  File "/ceph/home/muhan01/miniconda3/envs/torch2/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2365, in backward
    out = call_compiled_backward()
  File "/ceph/home/muhan01/miniconda3/envs/torch2/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 2341, in call_compiled_backward
    out = call_func_with_args(
  File "/ceph/home/muhan01/miniconda3/envs/torch2/lib/python3.10/site-packages/torch/_functorch/aot_autograd.py", line 1249, in call_func_with_args
    out = normalize_as_list(f(args))
  File "/ceph/home/muhan01/miniconda3/envs/torch2/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py", line 209, in _fn
    return fn(*args, **kwargs)
  File "/ceph/home/muhan01/miniconda3/envs/torch2/lib/python3.10/site-packages/torch/_inductor/compile_fx.py", line 248, in run
    return model(new_inputs)
  File "/tmp/torchinductor_muhan01/qw/cqwv3ut5qrpqvbi6pqmhqikrvxmhc4b7gvxhui5k2jmmlu36lpci.py", line 4419, in call
    buf137 = empty_strided((159744, 1, 415), (415, 415, 1), device='cuda', dtype=torch.float16)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 128.00 MiB (GPU 0; 23.69 GiB total capacity; 21.65 GiB already allocated; 14.94 MiB free; 22.49 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
