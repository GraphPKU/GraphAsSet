/ceph/home/muhan01/wangxiyuan/GraphAsSet/utils.py:20: UserWarning: not equivalent to Identity
  warnings.warn("not equivalent to Identity")
Namespace(dataset='pepstruct', repeat=1, num_workers=0, amp=True, compile=True, batch_size=12, testbatch_size=12, epochs=80, wd=0.1, lr=0.0003, beta=0.9, minlr=0.0, K=0.0, gradclipnorm=1.0, decompnoise=1e-06, seedoffset=0, warmstart=8, conststep=84, cosstep=8, use_y_scale=False, dp=0.0, eldp=0.0, act='silu', lossparam=0.0, advloss=False, embdp=0.0, embbn=False, emborthoinit=False, degreeemb=False, embln=True, featdim=-1, hiddim=72, caldim=-1, normA=False, laplacian=True, sqrtlambda=True, elres=True, usesvmix=True, vmean=True, vnorm=True, elvmean=True, elvnorm=True, snorm=True, gsizenorm=1.85, l_encoder='deepset', l_layers=3, l_combine='mul', l_aggr='mean', l_res=True, l_mlptailact1=True, l_mlplayers1=2, l_mlpnorm1='ln', l_mlptailact2=False, l_mlplayers2=0, l_mlpnorm2='none', num_layers=8, sv_uselinv=True, sv_tailact=True, sv_res=True, sv_numlayer=1, sv_norm='none', el_uselinv=True, el_uselins=False, el_tailact=True, el_numlayer=2, el_norm='none', el_uses=False, conv_uselinv=True, conv_tailact=True, conv_numlayer=1, conv_norm='none', predlin_numlayer=1, predlin_norm='none', lexp='mlp', lexp_layer=2, lexp_norm='ln', outln=False, pool='mean', Tm=1, save='pepstruct.8.72.wd1e-1', load=None, use_pos=False, align_size=32)
fixed l1reg
10873 2331 2331
split 10873 2331 2331
num_task 11
PiOModel(
  (inputencoder): QInputEncoder(
    (xemb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0): Embedding(18, 72, padding_idx=0)
        (1): Embedding(4, 72, padding_idx=0)
        (2-3): 2 x Embedding(8, 72, padding_idx=0)
        (4): Embedding(6, 72, padding_idx=0)
        (5): Embedding(2, 72, padding_idx=0)
        (6): Embedding(7, 72, padding_idx=0)
        (7-8): 2 x Embedding(3, 72, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((72,), eps=1e-05, elementwise_affine=False)
      )
    )
    (edgeEmb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0-2): 3 x Embedding(5, 72, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((72,), eps=1e-05, elementwise_affine=False)
      )
    )
    (LambdaEmb): MLPEncoding(
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=1, out_features=144, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=144, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (LambdaEncoder): PermEquiLayer(
    (set2set): Sequential(
      (0): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (1): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (2): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (3): Identity()
    )
    (set2vec): Sequential(
      (0): MLP(
      (lin): Sequential(
        (0): NoneNorm()
      )
    )
    )
  )
  (elprojs): ModuleList(
    (0-7): 8 x sv2el(
      (linv1): Linear(in_features=72, out_features=72, bias=False)
      (linv2): Linear(in_features=72, out_features=72, bias=False)
      (lins1): Identity()
      (lins2): Identity()
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): NoneNorm()
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (svmixs): ModuleList(
    (0-7): 8 x svMix(
      (linv1): Linear(in_features=72, out_features=72, bias=False)
      (linv2): Linear(in_features=72, out_features=72, bias=False)
      (linv3): Identity()
      (lins1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins3): Identity()
    )
  )
  (convs): ModuleList(
    (0-7): 8 x DirCFConv(
      (lins): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (linv): Linear(in_features=72, out_features=72, bias=False)
    )
  )
  (predlin): MLP(
    (lin): Sequential(
      (0): Linear(in_features=72, out_features=11, bias=True)
    )
  )
  (predln): Identity()
  (vln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (elvln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (sln): LayerNorm((72,), eps=1e-05, elementwise_affine=False)
)
numel 499691
Epoch 1 train time : 863.5 loss: 5.50e-01
 test time : 305.4 Train 0.0 Validation 0.40114647150039673 Test 0.40676480531692505
GPU memory 40.28
Epoch 2 train time : 418.8 loss: 3.64e-01
 test time : 74.7 Train 0.0 Validation 0.370330274105072 Test 0.37672048807144165
Epoch 3 train time : 417.4 loss: 3.35e-01
 test time : 75.1 Train 0.0 Validation 0.31942856311798096 Test 0.32686999440193176
Epoch 4 train time : 414.9 loss: 3.30e-01
 test time : 75.0 Train 0.0 Validation 0.29786059260368347 Test 0.3064665198326111
Epoch 5 train time : 416.7 loss: 3.22e-01
 test time : 75.4 Train 0.0 Validation 0.3001343905925751 Test 0.30600470304489136
Epoch 6 train time : 415.9 loss: 3.20e-01
 test time : 75.5 Train 0.0 Validation 0.3049491345882416 Test 0.31139323115348816
Epoch 7 train time : 419.0 loss: 3.16e-01
 test time : 75.6 Train 0.0 Validation 0.29921668767929077 Test 0.3061215579509735
Epoch 8 train time : 440.3 loss: 3.17e-01
 test time : 75.5 Train 0.0 Validation 0.3096874952316284 Test 0.31756290793418884
Epoch 9 train time : 415.3 loss: 3.11e-01
 test time : 75.3 Train 0.0 Validation 0.3021659553050995 Test 0.30939146876335144
Epoch 10 train time : 417.5 loss: 3.11e-01
 test time : 75.3 Train 0.0 Validation 0.2941521108150482 Test 0.3014884293079376
Epoch 11 train time : 418.3 loss: 3.09e-01
 test time : 75.3 Train 0.0 Validation 0.29700759053230286 Test 0.3018750846385956
Epoch 12 train time : 419.2 loss: 3.06e-01
 test time : 75.5 Train 0.0 Validation 0.28497281670570374 Test 0.2915758192539215
Epoch 13 train time : 419.6 loss: 3.04e-01
 test time : 75.5 Train 0.0 Validation 0.2933407127857208 Test 0.2998538911342621
Epoch 14 train time : 417.9 loss: 3.01e-01
 test time : 76.7 Train 0.0 Validation 0.298067569732666 Test 0.30410972237586975
Epoch 15 train time : 410.2 loss: 2.99e-01
 test time : 75.6 Train 0.0 Validation 0.2936289310455322 Test 0.2984451949596405
Epoch 16 train time : 417.2 loss: 2.98e-01
 test time : 75.5 Train 0.0 Validation 0.310831755399704 Test 0.3129284381866455
Epoch 17 train time : 418.8 loss: 2.92e-01
 test time : 76.5 Train 0.0 Validation 0.2977152168750763 Test 0.2998114228248596
Epoch 18 train time : 417.1 loss: 2.93e-01
 test time : 74.6 Train 0.0 Validation 0.2766331136226654 Test 0.27782025933265686
Epoch 19 train time : 412.7 loss: 2.89e-01
 test time : 75.1 Train 0.0 Validation 0.2813779413700104 Test 0.2828370928764343
Epoch 20 train time : 416.2 loss: 2.90e-01
 test time : 75.4 Train 0.0 Validation 0.2756606936454773 Test 0.2789030969142914
Epoch 21 train time : 411.7 loss: 2.88e-01
 test time : 75.4 Train 0.0 Validation 0.28618401288986206 Test 0.2918214797973633
Epoch 22 train time : 420.5 loss: 2.88e-01
 test time : 77.0 Train 0.0 Validation 0.2730351984500885 Test 0.276529997587204
Epoch 23 train time : 417.5 loss: 2.87e-01
 test time : 75.3 Train 0.0 Validation 0.2783026099205017 Test 0.2800743877887726
Epoch 24 train time : 418.3 loss: 2.84e-01
 test time : 75.2 Train 0.0 Validation 0.2794472873210907 Test 0.28990527987480164
Epoch 25 train time : 413.8 loss: 2.84e-01
 test time : 75.6 Train 0.0 Validation 0.28359854221343994 Test 0.2852853536605835
Epoch 26 train time : 415.7 loss: 2.85e-01
 test time : 76.5 Train 0.0 Validation 0.2810525894165039 Test 0.2865234315395355
Epoch 27 train time : 419.2 loss: 2.85e-01
 test time : 75.4 Train 0.0 Validation 0.2727527916431427 Test 0.2759477198123932
Epoch 28 train time : 419.0 loss: 2.83e-01
 test time : 75.4 Train 0.0 Validation 0.28984788060188293 Test 0.29566237330436707
Epoch 29 train time : 417.0 loss: 2.83e-01
 test time : 75.0 Train 0.0 Validation 0.2710164487361908 Test 0.27307528257369995
Epoch 30 train time : 419.5 loss: 2.80e-01
 test time : 75.4 Train 0.0 Validation 0.2694892883300781 Test 0.2719908654689789
Epoch 31 train time : 418.1 loss: 2.80e-01
 test time : 75.4 Train 0.0 Validation 0.2754271626472473 Test 0.2811426818370819
Epoch 32 train time : 414.0 loss: 2.78e-01
 test time : 75.2 Train 0.0 Validation 0.2782312035560608 Test 0.2769884467124939
Epoch 33 train time : 420.1 loss: 2.77e-01
 test time : 75.4 Train 0.0 Validation 0.2660810947418213 Test 0.2681557834148407
Epoch 34 train time : 418.4 loss: 2.77e-01
 test time : 75.1 Train 0.0 Validation 0.2685736119747162 Test 0.27165788412094116
Epoch 35 train time : 417.6 loss: 2.77e-01
 test time : 75.3 Train 0.0 Validation 0.2733483910560608 Test 0.27542227506637573
Epoch 36 train time : 417.1 loss: 2.75e-01
 test time : 75.8 Train 0.0 Validation 0.27749156951904297 Test 0.2810762822628021
Epoch 37 train time : 419.0 loss: 2.75e-01
 test time : 75.5 Train 0.0 Validation 0.26574671268463135 Test 0.26870962977409363
Epoch 38 train time : 418.6 loss: 2.76e-01
 test time : 75.4 Train 0.0 Validation 0.27639880776405334 Test 0.27979621291160583
Epoch 39 train time : 420.7 loss: 2.74e-01
 test time : 75.2 Train 0.0 Validation 0.2652710974216461 Test 0.2687103748321533
Epoch 40 train time : 420.2 loss: 2.73e-01
 test time : 74.7 Train 0.0 Validation 0.2665683627128601 Test 0.2700265944004059
Epoch 41 train time : 412.6 loss: 2.74e-01
 test time : 75.9 Train 0.0 Validation 0.26900210976600647 Test 0.2749122381210327
Epoch 42 train time : 413.6 loss: 2.73e-01
 test time : 75.3 Train 0.0 Validation 0.26673850417137146 Test 0.26873770356178284
Epoch 43 train time : 414.0 loss: 2.73e-01
 test time : 75.2 Train 0.0 Validation 0.28092506527900696 Test 0.28817084431648254
Epoch 44 train time : 418.3 loss: 2.72e-01
 test time : 75.3 Train 0.0 Validation 0.26170602440834045 Test 0.2644929587841034
Epoch 45 train time : 417.1 loss: 2.70e-01
 test time : 75.3 Train 0.0 Validation 0.28011253476142883 Test 0.28316348791122437
Epoch 46 train time : 414.1 loss: 2.71e-01
 test time : 75.5 Train 0.0 Validation 0.272983193397522 Test 0.27397269010543823
Epoch 47 train time : 416.2 loss: 2.71e-01
 test time : 75.5 Train 0.0 Validation 0.26405400037765503 Test 0.2689378559589386
Epoch 48 train time : 417.7 loss: 2.69e-01
 test time : 75.7 Train 0.0 Validation 0.27466246485710144 Test 0.2778971791267395
Epoch 49 train time : 421.6 loss: 2.69e-01
 test time : 75.3 Train 0.0 Validation 0.28579702973365784 Test 0.29141536355018616
Epoch 50 train time : 418.0 loss: 2.70e-01
 test time : 75.4 Train 0.0 Validation 0.2641201317310333 Test 0.2677977979183197
Epoch 51 train time : 418.9 loss: 2.68e-01
 test time : 75.3 Train 0.0 Validation 0.26104748249053955 Test 0.26370295882225037
Epoch 52 train time : 416.9 loss: 2.67e-01
 test time : 75.4 Train 0.0 Validation 0.25885963439941406 Test 0.26424723863601685
Epoch 53 train time : 419.4 loss: 2.68e-01
 test time : 75.5 Train 0.0 Validation 0.25780293345451355 Test 0.26300284266471863
Epoch 54 train time : 413.9 loss: 2.67e-01
 test time : 75.1 Train 0.0 Validation 0.2729324996471405 Test 0.27706485986709595
Epoch 55 train time : 413.5 loss: 2.67e-01
 test time : 75.2 Train 0.0 Validation 0.2594003677368164 Test 0.26253125071525574
Epoch 56 train time : 419.9 loss: 2.66e-01
 test time : 75.4 Train 0.0 Validation 0.26279234886169434 Test 0.26556694507598877
Epoch 57 train time : 418.6 loss: 2.66e-01
 test time : 75.3 Train 0.0 Validation 0.263676255941391 Test 0.2665019631385803
Epoch 58 train time : 415.5 loss: 2.65e-01
 test time : 75.3 Train 0.0 Validation 0.2570878863334656 Test 0.26084309816360474
Epoch 59 train time : 421.4 loss: 2.65e-01
 test time : 75.5 Train 0.0 Validation 0.26301151514053345 Test 0.2643049955368042
Epoch 60 train time : 415.6 loss: 2.63e-01
 test time : 75.0 Train 0.0 Validation 0.2586970329284668 Test 0.2632219195365906
Epoch 61 train time : 418.9 loss: 2.65e-01
 test time : 75.6 Train 0.0 Validation 0.2600751221179962 Test 0.2675587832927704
Epoch 62 train time : 414.2 loss: 2.66e-01
 test time : 75.2 Train 0.0 Validation 0.2573832869529724 Test 0.262594074010849
Epoch 63 train time : 416.0 loss: 2.63e-01
 test time : 75.5 Train 0.0 Validation 0.2607041001319885 Test 0.2646658718585968
Epoch 64 train time : 414.7 loss: 2.64e-01
 test time : 75.9 Train 0.0 Validation 0.25708696246147156 Test 0.2608223557472229
Epoch 65 train time : 418.3 loss: 2.64e-01
 test time : 75.5 Train 0.0 Validation 0.2586855888366699 Test 0.26450538635253906
Epoch 66 train time : 416.0 loss: 2.64e-01
 test time : 77.1 Train 0.0 Validation 0.25722044706344604 Test 0.2632235288619995
Epoch 67 train time : 417.9 loss: 2.64e-01
 test time : 75.5 Train 0.0 Validation 0.25850197672843933 Test 0.2620595097541809
Epoch 68 train time : 417.1 loss: 2.62e-01
 test time : 75.5 Train 0.0 Validation 0.2610235810279846 Test 0.26758190989494324
Epoch 69 train time : 416.4 loss: 2.62e-01
 test time : 76.5 Train 0.0 Validation 0.2566050887107849 Test 0.2604582905769348
Epoch 70 train time : 415.9 loss: 2.62e-01
 test time : 75.5 Train 0.0 Validation 0.25433167815208435 Test 0.2605731785297394
Epoch 71 train time : 418.4 loss: 2.62e-01
 test time : 75.7 Train 0.0 Validation 0.25847429037094116 Test 0.2641127407550812
Epoch 72 train time : 417.2 loss: 2.62e-01
 test time : 75.3 Train 0.0 Validation 0.2659945785999298 Test 0.27321693301200867
Epoch 73 train time : 419.2 loss: 2.62e-01
 test time : 75.2 Train 0.0 Validation 0.254963219165802 Test 0.26114001870155334
Epoch 74 train time : 421.8 loss: 2.63e-01
 test time : 75.4 Train 0.0 Validation 0.2593362331390381 Test 0.2649002969264984
Epoch 75 train time : 417.2 loss: 2.63e-01
 test time : 75.5 Train 0.0 Validation 0.25743603706359863 Test 0.2647674083709717
Epoch 76 train time : 414.7 loss: 2.60e-01
 test time : 74.6 Train 0.0 Validation 0.25821876525878906 Test 0.26366299390792847
Epoch 77 train time : 416.9 loss: 2.60e-01
 test time : 75.6 Train 0.0 Validation 0.2683742046356201 Test 0.2738833725452423
Epoch 78 train time : 416.5 loss: 2.60e-01
 test time : 75.5 Train 0.0 Validation 0.25677427649497986 Test 0.261948823928833
Epoch 79 train time : 416.7 loss: 2.60e-01
 test time : 75.5 Train 0.0 Validation 0.26197633147239685 Test 0.26865652203559875
Epoch 80 train time : 414.9 loss: 2.60e-01
 test time : 75.5 Train 0.0 Validation 0.2582506835460663 Test 0.2652963101863861
Best @69 validation score: 0.2543 Test score: 0.2606
[[69, tensor(0.2543), tensor(0.2606)]]
all runs:  69.0 0.25433167815208435 0.2605731785297394 0.0 0.0 0.0 
