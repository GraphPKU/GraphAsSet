/ceph/home/muhan01/wangxiyuan/GraphAsSet/utils.py:20: UserWarning: not equivalent to Identity
  warnings.warn("not equivalent to Identity")
Namespace(dataset='pepstruct', repeat=1, num_workers=0, amp=True, compile=True, batch_size=4, testbatch_size=6, epochs=80, wd=0.1, lr=0.001, beta=0.9, minlr=0.0, K=0.0, gradclipnorm=1.0, decompnoise=1e-06, seedoffset=0, warmstart=8, conststep=56, cosstep=8, use_y_scale=False, dp=0.0, eldp=0.0, act='silu', lossparam=0.0, advloss=False, embdp=0.0, embbn=False, emborthoinit=False, degreeemb=False, embln=True, featdim=-1, hiddim=64, caldim=-1, normA=False, laplacian=True, sqrtlambda=True, elres=True, usesvmix=True, vmean=True, vnorm=True, elvmean=True, elvnorm=True, snorm=True, gsizenorm=1.85, l_encoder='deepset', l_layers=3, l_combine='mul', l_aggr='mean', l_res=True, l_mlptailact1=True, l_mlplayers1=2, l_mlpnorm1='ln', l_mlptailact2=False, l_mlplayers2=0, l_mlpnorm2='none', num_layers=12, sv_uselinv=True, sv_tailact=True, sv_res=True, sv_numlayer=1, sv_norm='none', el_uselinv=True, el_uselins=False, el_tailact=True, el_numlayer=2, el_norm='none', el_uses=False, conv_uselinv=True, conv_tailact=True, conv_numlayer=1, conv_norm='none', predlin_numlayer=1, predlin_norm='none', lexp='mlp', lexp_layer=2, lexp_norm='ln', outln=False, pool='mean', Tm=1, save=None, load=None, use_pos=False, align_size=32)
fixed l1reg
10873 2331 2331
split 10873 2331 2331
num_task 11
PiOModel(
  (inputencoder): QInputEncoder(
    (xemb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0): Embedding(18, 64, padding_idx=0)
        (1): Embedding(4, 64, padding_idx=0)
        (2-3): 2 x Embedding(8, 64, padding_idx=0)
        (4): Embedding(6, 64, padding_idx=0)
        (5): Embedding(2, 64, padding_idx=0)
        (6): Embedding(7, 64, padding_idx=0)
        (7-8): 2 x Embedding(3, 64, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=False)
      )
    )
    (edgeEmb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0-2): 3 x Embedding(5, 64, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=False)
      )
    )
    (LambdaEmb): MLPEncoding(
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=1, out_features=128, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
    (distEmb): MLPEncoding(
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=1, out_features=128, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (LambdaEncoder): PermEquiLayer(
    (set2set): Sequential(
      (0): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (1): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (2): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (3): Identity()
    )
    (set2vec): Sequential(
      (0): MLP(
      (lin): Sequential(
        (0): NoneNorm()
      )
    )
    )
  )
  (elprojs): ModuleList(
    (0-11): 12 x sv2el(
      (linv1): Linear(in_features=64, out_features=64, bias=False)
      (linv2): Linear(in_features=64, out_features=64, bias=False)
      (lins1): Identity()
      (lins2): Identity()
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): NoneNorm()
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (svmixs): ModuleList(
    (0-11): 12 x svMix(
      (linv1): Linear(in_features=64, out_features=64, bias=False)
      (linv2): Linear(in_features=64, out_features=64, bias=False)
      (linv3): Identity()
      (lins1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins3): Identity()
    )
  )
  (convs): ModuleList(
    (0-11): 12 x DirCFConv(
      (lins): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (linv): Linear(in_features=64, out_features=64, bias=False)
    )
  )
  (predlin): MLP(
    (lin): Sequential(
      (0): Linear(in_features=64, out_features=11, bias=True)
    )
  )
  (predln): Identity()
  (vln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (elvln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (sln): LayerNorm((64,), eps=1e-05, elementwise_affine=False)
)
numel 570059
Epoch 1 train time : 1165.5 loss: 4.43e-01
 test time : 605.2 Train 0.0 Validation 0.32190147042274475 Test 0.3300749659538269
GPU memory 17.33
Epoch 2 train time : 462.5 loss: 3.47e-01
 test time : 80.3 Train 0.0 Validation 0.31911754608154297 Test 0.3306080102920532
Epoch 3 train time : 429.6 loss: 3.36e-01
 test time : 80.5 Train 0.0 Validation 0.3243309259414673 Test 0.3322581350803375
Epoch 4 train time : 430.3 loss: 3.29e-01
 test time : 80.3 Train 0.0 Validation 0.3361356854438782 Test 0.34647780656814575
Epoch 5 train time : 427.4 loss: 3.28e-01
 test time : 80.3 Train 0.0 Validation 0.30897486209869385 Test 0.3159758150577545
Epoch 6 train time : 429.4 loss: 3.22e-01
 test time : 80.3 Train 0.0 Validation 0.35445940494537354 Test 0.3580362796783447
Epoch 7 train time : 430.3 loss: 3.19e-01
 test time : 80.3 Train 0.0 Validation 0.3382777273654938 Test 0.34517720341682434
Epoch 8 train time : 428.5 loss: 3.16e-01
 test time : 80.4 Train 0.0 Validation 0.2898431718349457 Test 0.29816970229148865
Epoch 9 train time : 426.9 loss: 3.12e-01
 test time : 80.1 Train 0.0 Validation 0.3009703457355499 Test 0.310950368642807
Epoch 10 train time : 428.2 loss: 3.07e-01
 test time : 80.5 Train 0.0 Validation 0.28590431809425354 Test 0.29221010208129883
Epoch 11 train time : 427.9 loss: 3.05e-01
 test time : 80.1 Train 0.0 Validation 0.28827929496765137 Test 0.2923455834388733
Epoch 12 train time : 426.6 loss: 3.07e-01
 test time : 80.4 Train 0.0 Validation 0.2833508849143982 Test 0.29035449028015137
Epoch 13 train time : 428.7 loss: 3.04e-01
 test time : 80.3 Train 0.0 Validation 0.28743693232536316 Test 0.2927876114845276
Epoch 14 train time : 428.1 loss: 3.05e-01
 test time : 80.4 Train 0.0 Validation 0.2821374535560608 Test 0.28802356123924255
Epoch 15 train time : 427.6 loss: 3.04e-01
 test time : 80.2 Train 0.0 Validation 0.28835517168045044 Test 0.29550015926361084
Epoch 16 train time : 427.4 loss: 3.02e-01
 test time : 80.3 Train 0.0 Validation 0.2927546799182892 Test 0.2992497384548187
Epoch 17 train time : 429.9 loss: 3.02e-01
 test time : 80.2 Train 0.0 Validation 0.28980278968811035 Test 0.2950436770915985
Epoch 18 train time : 427.7 loss: 3.03e-01
 test time : 80.2 Train 0.0 Validation 0.2841416597366333 Test 0.29028627276420593
Epoch 19 train time : 425.9 loss: 3.04e-01
 test time : 80.2 Train 0.0 Validation 0.29016196727752686 Test 0.2963588833808899
Epoch 20 train time : 427.6 loss: 3.03e-01
 test time : 80.3 Train 0.0 Validation 0.28491705656051636 Test 0.2905092239379883
Epoch 21 train time : 426.4 loss: 3.02e-01
 test time : 80.2 Train 0.0 Validation 0.28506165742874146 Test 0.29092103242874146
Epoch 22 train time : 428.9 loss: 3.04e-01
 test time : 80.2 Train 0.0 Validation 0.28891807794570923 Test 0.2959955632686615
Epoch 23 train time : 426.3 loss: 3.01e-01
 test time : 80.3 Train 0.0 Validation 0.2801254689693451 Test 0.28407564759254456
Epoch 24 train time : 425.5 loss: 3.02e-01
 test time : 80.2 Train 0.0 Validation 0.28505805134773254 Test 0.2907242178916931
Epoch 25 train time : 429.0 loss: 3.02e-01
 test time : 80.4 Train 0.0 Validation 0.2766721248626709 Test 0.28170034289360046
Epoch 26 train time : 424.6 loss: 3.02e-01
 test time : 80.2 Train 0.0 Validation 0.29447153210639954 Test 0.30070263147354126
Epoch 27 train time : 427.7 loss: 3.01e-01
 test time : 80.3 Train 0.0 Validation 0.2904494106769562 Test 0.2969844341278076
Epoch 28 train time : 426.3 loss: 3.02e-01
 test time : 80.2 Train 0.0 Validation 0.2938842475414276 Test 0.30027511715888977
Epoch 29 train time : 425.2 loss: 3.01e-01
 test time : 80.3 Train 0.0 Validation 0.2881370186805725 Test 0.2934752106666565
Epoch 30 train time : 430.0 loss: 3.00e-01
 test time : 80.2 Train 0.0 Validation 0.27883875370025635 Test 0.2858980894088745
Epoch 31 train time : 428.6 loss: 3.00e-01
 test time : 80.2 Train 0.0 Validation 0.3011412024497986 Test 0.3076203167438507
Epoch 32 train time : 427.4 loss: 3.02e-01
 test time : 80.2 Train 0.0 Validation 0.28325891494750977 Test 0.2904353141784668
Epoch 33 train time : 429.0 loss: 3.00e-01
 test time : 80.2 Train 0.0 Validation 0.27916014194488525 Test 0.28349050879478455
Epoch 34 train time : 425.1 loss: 3.00e-01
 test time : 80.3 Train 0.0 Validation 0.3131040930747986 Test 0.3208007216453552
Epoch 35 train time : 423.8 loss: 3.01e-01
 test time : 80.2 Train 0.0 Validation 0.2957860827445984 Test 0.3021104037761688
Epoch 36 train time : 425.2 loss: 3.00e-01
 test time : 80.4 Train 0.0 Validation 0.27909794449806213 Test 0.28453153371810913
Epoch 37 train time : 428.9 loss: 2.99e-01
 test time : 80.3 Train 0.0 Validation 0.28645163774490356 Test 0.2910270690917969
Epoch 38 train time : 426.5 loss: 3.01e-01
 test time : 80.2 Train 0.0 Validation 0.2745736539363861 Test 0.2801603078842163
Epoch 39 train time : 426.8 loss: 3.00e-01
 test time : 80.2 Train 0.0 Validation 0.31085649132728577 Test 0.31560182571411133
Epoch 40 train time : 427.2 loss: 3.00e-01
 test time : 80.2 Train 0.0 Validation 0.28645798563957214 Test 0.2944195568561554
Epoch 41 train time : 427.5 loss: 3.00e-01
 test time : 80.2 Train 0.0 Validation 0.32121700048446655 Test 0.3276374936103821
Epoch 42 train time : 427.0 loss: 3.01e-01
 test time : 80.2 Train 0.0 Validation 0.282702773809433 Test 0.2908676564693451
Epoch 43 train time : 426.1 loss: 2.98e-01
 test time : 80.2 Train 0.0 Validation 0.2784781754016876 Test 0.2828000783920288
Epoch 44 train time : 429.8 loss: 2.99e-01
 test time : 80.2 Train 0.0 Validation 0.3066485822200775 Test 0.3147644102573395
Epoch 45 train time : 427.0 loss: 2.99e-01
 test time : 80.4 Train 0.0 Validation 0.28138357400894165 Test 0.2862178683280945
Epoch 46 train time : 427.0 loss: 2.99e-01
 test time : 80.2 Train 0.0 Validation 0.3133907616138458 Test 0.3200378119945526
Epoch 47 train time : 425.4 loss: 2.97e-01
 test time : 80.3 Train 0.0 Validation 0.28069832921028137 Test 0.28802359104156494
Epoch 48 train time : 428.6 loss: 2.99e-01
 test time : 80.2 Train 0.0 Validation 0.29406481981277466 Test 0.3020577132701874
Epoch 49 train time : 427.0 loss: 2.98e-01
 test time : 80.2 Train 0.0 Validation 0.2952176034450531 Test 0.30345386266708374
Epoch 50 train time : 427.0 loss: 2.99e-01
 test time : 80.3 Train 0.0 Validation 0.3031345009803772 Test 0.309760183095932
Epoch 51 train time : 425.5 loss: 2.97e-01
 test time : 80.2 Train 0.0 Validation 0.2899445593357086 Test 0.2968825697898865
Epoch 52 train time : 425.4 loss: 2.98e-01
 test time : 80.3 Train 0.0 Validation 0.30048373341560364 Test 0.3044813871383667
Epoch 53 train time : 427.6 loss: 2.99e-01
 test time : 80.2 Train 0.0 Validation 0.28082531690597534 Test 0.284233421087265
Epoch 54 train time : 426.0 loss: 2.96e-01
 test time : 80.4 Train 0.0 Validation 0.28162258863449097 Test 0.28842058777809143
Epoch 55 train time : 427.4 loss: 2.99e-01
 test time : 80.2 Train 0.0 Validation 0.30373144149780273 Test 0.30619075894355774
Epoch 56 train time : 428.7 loss: 2.97e-01
 test time : 80.3 Train 0.0 Validation 0.2943379282951355 Test 0.30180180072784424
Epoch 57 train time : 427.2 loss: 3.00e-01
 test time : 80.2 Train 0.0 Validation 0.2894018888473511 Test 0.29405727982521057
Epoch 58 train time : 427.3 loss: 2.99e-01
 test time : 80.3 Train 0.0 Validation 0.28300824761390686 Test 0.290666401386261
Epoch 59 train time : 426.4 loss: 3.00e-01
 test time : 80.3 Train 0.0 Validation 0.30808448791503906 Test 0.31511053442955017
Epoch 60 train time : 426.8 loss: 2.98e-01
 test time : 80.2 Train 0.0 Validation 0.287242591381073 Test 0.29462316632270813
Epoch 61 train time : 425.5 loss: 3.00e-01
 test time : 80.2 Train 0.0 Validation 0.28455597162246704 Test 0.2899034321308136
Epoch 62 train time : 427.7 loss: 2.99e-01
 test time : 80.1 Train 0.0 Validation 0.28536880016326904 Test 0.2937432527542114
Epoch 63 train time : 427.0 loss: 2.98e-01
 test time : 80.2 Train 0.0 Validation 0.2769366204738617 Test 0.28061917424201965
Epoch 64 train time : 426.6 loss: 2.99e-01
 test time : 80.1 Train 0.0 Validation 0.284426212310791 Test 0.29147714376449585
Epoch 65 train time : 426.3 loss: 2.97e-01
 test time : 80.2 Train 0.0 Validation 0.28158560395240784 Test 0.2848530113697052
Epoch 66 train time : 427.7 loss: 2.95e-01
 test time : 80.1 Train 0.0 Validation 0.2873224914073944 Test 0.2945864796638489
Epoch 67 train time : 430.5 loss: 2.92e-01
 test time : 80.1 Train 0.0 Validation 0.28951218724250793 Test 0.29663699865341187
Epoch 68 train time : 428.7 loss: 2.88e-01
 test time : 80.1 Train 0.0 Validation 0.2774900197982788 Test 0.2825091779232025
Epoch 69 train time : 428.5 loss: 2.83e-01
 test time : 80.0 Train 0.0 Validation 0.2690812349319458 Test 0.2750532627105713
Epoch 70 train time : 426.3 loss: 2.77e-01
 test time : 80.2 Train 0.0 Validation 0.27702245116233826 Test 0.28357839584350586
Epoch 71 train time : 424.1 loss: 2.73e-01
 test time : 80.3 Train 0.0 Validation 0.26580125093460083 Test 0.2700233459472656
Epoch 72 train time : 429.6 loss: 2.69e-01
 test time : 80.2 Train 0.0 Validation 0.26447904109954834 Test 0.2686957120895386
Epoch 73 train time : 427.0 loss: 3.02e-01
 test time : 80.0 Train 0.0 Validation 0.2849707007408142 Test 0.28698915243148804
Epoch 74 train time : 428.7 loss: 2.97e-01
 test time : 80.2 Train 0.0 Validation 0.2813849151134491 Test 0.28741902112960815
Epoch 75 train time : 427.0 loss: 2.93e-01
 test time : 80.0 Train 0.0 Validation 0.28378668427467346 Test 0.2904648780822754
Epoch 76 train time : 429.4 loss: 2.89e-01
 test time : 80.1 Train 0.0 Validation 0.276297003030777 Test 0.28011444211006165
Epoch 77 train time : 425.3 loss: 2.83e-01
 test time : 80.1 Train 0.0 Validation 0.2691008746623993 Test 0.2735869586467743
Epoch 78 train time : 428.8 loss: 2.77e-01
 test time : 80.1 Train 0.0 Validation 0.26690003275871277 Test 0.2713279128074646
Epoch 79 train time : 424.5 loss: 2.73e-01
 test time : 80.3 Train 0.0 Validation 0.2650187015533447 Test 0.26895496249198914
Epoch 80 train time : 430.0 loss: 2.69e-01
 test time : 80.2 Train 0.0 Validation 0.265193372964859 Test 0.2691839933395386
Best @71 validation score: 0.2645 Test score: 0.2687
[[71, tensor(0.2645), tensor(0.2687)]]
all runs:  71.0 0.26447904109954834 0.2686957120895386 0.0 0.0 0.0 
