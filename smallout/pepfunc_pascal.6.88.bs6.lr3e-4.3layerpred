/ceph/home/muhan01/wangxiyuan/GraphAsSet/utils.py:20: UserWarning: not equivalent to Identity
  warnings.warn("not equivalent to Identity")
Namespace(dataset='pepfunc', repeat=1, num_workers=0, amp=True, compile=True, batch_size=6, testbatch_size=6, epochs=80, wd=0.1, lr=0.0003, beta=0.9, minlr=0.0, K=0.0, gradclipnorm=1.0, decompnoise=1e-06, seedoffset=0, warmstart=8, conststep=64, cosstep=8, use_y_scale=False, dp=0.0, eldp=0.0, act='silu', lossparam=0.0, advloss=False, embdp=0.0, embbn=False, emborthoinit=False, degreeemb=False, embln=True, featdim=-1, hiddim=88, caldim=-1, normA=False, laplacian=True, sqrtlambda=True, elres=True, usesvmix=True, vmean=True, vnorm=True, elvmean=True, elvnorm=True, snorm=True, gsizenorm=1.85, l_encoder='deepset', l_layers=3, l_combine='mul', l_aggr='mean', l_res=True, l_mlptailact1=True, l_mlplayers1=2, l_mlpnorm1='ln', l_mlptailact2=False, l_mlplayers2=0, l_mlpnorm2='none', num_layers=6, sv_uselinv=True, sv_tailact=True, sv_res=True, sv_numlayer=1, sv_norm='none', el_uselinv=True, el_uselins=False, el_tailact=True, el_numlayer=2, el_norm='none', el_uses=False, conv_uselinv=True, conv_tailact=True, conv_numlayer=1, conv_norm='none', predlin_numlayer=3, predlin_norm='none', lexp='mlp', lexp_layer=2, lexp_norm='ln', outln=False, pool='mean', Tm=1, save='pepfunc.wd1e-1.3layerpred', load=None, use_pos=False, align_size=32)
fixed bincls
10873 2331 2331
split 10873 2331 2331
num_task 10
PiOModel(
  (inputencoder): QInputEncoder(
    (xemb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0): Embedding(18, 88, padding_idx=0)
        (1): Embedding(4, 88, padding_idx=0)
        (2-3): 2 x Embedding(8, 88, padding_idx=0)
        (4): Embedding(6, 88, padding_idx=0)
        (5): Embedding(2, 88, padding_idx=0)
        (6): Embedding(7, 88, padding_idx=0)
        (7-8): 2 x Embedding(3, 88, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
      )
    )
    (edgeEmb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0-2): 3 x Embedding(5, 88, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
      )
    )
    (LambdaEmb): MLPEncoding(
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=1, out_features=176, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((176,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=176, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (LambdaEncoder): PermEquiLayer(
    (set2set): Sequential(
      (0): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (1): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (2): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (3): Identity()
    )
    (set2vec): Sequential(
      (0): MLP(
      (lin): Sequential(
        (0): NoneNorm()
      )
    )
    )
  )
  (elprojs): ModuleList(
    (0-5): 6 x sv2el(
      (linv1): Linear(in_features=88, out_features=88, bias=False)
      (linv2): Linear(in_features=88, out_features=88, bias=False)
      (lins1): Identity()
      (lins2): Identity()
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): NoneNorm()
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (svmixs): ModuleList(
    (0-5): 6 x svMix(
      (linv1): Linear(in_features=88, out_features=88, bias=False)
      (linv2): Linear(in_features=88, out_features=88, bias=False)
      (linv3): Identity()
      (lins1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins3): Identity()
    )
  )
  (convs): ModuleList(
    (0-5): 6 x DirCFConv(
      (lins): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (linv): Linear(in_features=88, out_features=88, bias=False)
    )
  )
  (predlin): MLP(
    (lin): Sequential(
      (0): Linear(in_features=88, out_features=88, bias=True)
      (1): NoneNorm()
      (2): SiLU(inplace=True)
      (3): Linear(in_features=88, out_features=88, bias=True)
      (4): NoneNorm()
      (5): SiLU(inplace=True)
      (6): Linear(in_features=88, out_features=10, bias=True)
    )
  )
  (predln): Identity()
  (vln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (elvln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (sln): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
)
numel 602898
Epoch 1 train time : 585.4 loss: 4.52e-01
 test time : 238.4 Train 0.0 Validation 0.27657774090766907 Test 0.2823997735977173
GPU memory 19.09
Epoch 2 train time : 387.8 loss: 3.26e-01
 test time : 63.7 Train 0.0 Validation 0.30309629440307617 Test 0.30936577916145325
Epoch 3 train time : 367.2 loss: 3.17e-01
 test time : 63.8 Train 0.0 Validation 0.33547431230545044 Test 0.34089717268943787
Epoch 4 train time : 365.9 loss: 2.98e-01
 test time : 63.8 Train 0.0 Validation 0.3805450201034546 Test 0.3808625638484955
Epoch 5 train time : 396.0 loss: 2.90e-01
 test time : 63.8 Train 0.0 Validation 0.39668866991996765 Test 0.3845476508140564
Epoch 6 train time : 366.4 loss: 2.86e-01
 test time : 63.8 Train 0.0 Validation 0.4203692376613617 Test 0.4184107184410095
Epoch 7 train time : 366.4 loss: 2.82e-01
 test time : 63.8 Train 0.0 Validation 0.38945627212524414 Test 0.38883405923843384
Epoch 8 train time : 366.4 loss: 2.79e-01
 test time : 64.5 Train 0.0 Validation 0.4223349690437317 Test 0.4203256070613861
Epoch 9 train time : 366.2 loss: 2.73e-01
 test time : 63.6 Train 0.0 Validation 0.42500704526901245 Test 0.4129687249660492
Epoch 10 train time : 369.5 loss: 2.68e-01
 test time : 63.6 Train 0.0 Validation 0.4621144235134125 Test 0.44782036542892456
Epoch 11 train time : 363.8 loss: 2.65e-01
 test time : 63.7 Train 0.0 Validation 0.46243152022361755 Test 0.44708114862442017
Epoch 12 train time : 367.2 loss: 2.58e-01
 test time : 63.8 Train 0.0 Validation 0.48922497034072876 Test 0.4581547677516937
Epoch 13 train time : 365.2 loss: 2.54e-01
 test time : 63.8 Train 0.0 Validation 0.4916742742061615 Test 0.472385972738266
Epoch 14 train time : 363.9 loss: 2.51e-01
 test time : 63.6 Train 0.0 Validation 0.504192054271698 Test 0.4891566336154938
Epoch 15 train time : 365.9 loss: 2.46e-01
 test time : 63.7 Train 0.0 Validation 0.5119467377662659 Test 0.4833943843841553
Epoch 16 train time : 367.5 loss: 2.44e-01
 test time : 63.8 Train 0.0 Validation 0.5085469484329224 Test 0.47700342535972595
Epoch 17 train time : 366.5 loss: 2.40e-01
 test time : 63.8 Train 0.0 Validation 0.5383092164993286 Test 0.5097702741622925
Epoch 18 train time : 365.7 loss: 2.37e-01
 test time : 63.7 Train 0.0 Validation 0.5359117388725281 Test 0.5059924125671387
Epoch 19 train time : 365.6 loss: 2.35e-01
 test time : 63.7 Train 0.0 Validation 0.520832896232605 Test 0.5068149566650391
Epoch 20 train time : 366.6 loss: 2.34e-01
 test time : 63.8 Train 0.0 Validation 0.5328108668327332 Test 0.509567141532898
Epoch 21 train time : 367.6 loss: 2.31e-01
 test time : 63.7 Train 0.0 Validation 0.5394635200500488 Test 0.529401421546936
Epoch 22 train time : 368.0 loss: 2.29e-01
 test time : 63.5 Train 0.0 Validation 0.5438425540924072 Test 0.519620418548584
Epoch 23 train time : 366.2 loss: 2.27e-01
 test time : 63.7 Train 0.0 Validation 0.5218164324760437 Test 0.5191834568977356
Epoch 24 train time : 366.6 loss: 2.25e-01
 test time : 63.8 Train 0.0 Validation 0.5390195250511169 Test 0.521173357963562
Epoch 25 train time : 363.7 loss: 2.23e-01
 test time : 63.7 Train 0.0 Validation 0.5695475935935974 Test 0.5423413515090942
Epoch 26 train time : 363.0 loss: 2.23e-01
 test time : 63.5 Train 0.0 Validation 0.5306624174118042 Test 0.5296322107315063
Epoch 27 train time : 364.9 loss: 2.20e-01
 test time : 63.5 Train 0.0 Validation 0.5430033802986145 Test 0.5264383554458618
Epoch 28 train time : 366.3 loss: 2.19e-01
 test time : 63.6 Train 0.0 Validation 0.5527423024177551 Test 0.539086639881134
Epoch 29 train time : 364.6 loss: 2.16e-01
 test time : 63.5 Train 0.0 Validation 0.5742990970611572 Test 0.5581858158111572
Epoch 30 train time : 364.2 loss: 2.13e-01
 test time : 63.5 Train 0.0 Validation 0.5778689384460449 Test 0.5550227165222168
Epoch 31 train time : 365.3 loss: 2.14e-01
 test time : 64.5 Train 0.0 Validation 0.5722099542617798 Test 0.5505534410476685
Epoch 32 train time : 362.6 loss: 2.11e-01
 test time : 63.8 Train 0.0 Validation 0.573919951915741 Test 0.5460308194160461
Epoch 33 train time : 367.2 loss: 2.11e-01
 test time : 63.7 Train 0.0 Validation 0.5700976252555847 Test 0.5518741607666016
Epoch 34 train time : 364.9 loss: 2.09e-01
 test time : 63.8 Train 0.0 Validation 0.5938425660133362 Test 0.5609734058380127
Epoch 35 train time : 364.7 loss: 2.07e-01
 test time : 63.7 Train 0.0 Validation 0.5653848648071289 Test 0.5462446212768555
Epoch 36 train time : 366.8 loss: 2.05e-01
 test time : 63.8 Train 0.0 Validation 0.5732430219650269 Test 0.5537678003311157
Epoch 37 train time : 365.2 loss: 2.06e-01
 test time : 63.7 Train 0.0 Validation 0.5833858251571655 Test 0.5696839094161987
Epoch 38 train time : 366.8 loss: 2.04e-01
 test time : 63.7 Train 0.0 Validation 0.6040390729904175 Test 0.5613107681274414
Epoch 39 train time : 364.8 loss: 2.03e-01
 test time : 64.5 Train 0.0 Validation 0.6075944900512695 Test 0.5723005533218384
Epoch 40 train time : 364.5 loss: 2.01e-01
 test time : 63.6 Train 0.0 Validation 0.5899736881256104 Test 0.5634078979492188
Epoch 41 train time : 366.3 loss: 2.01e-01
 test time : 63.7 Train 0.0 Validation 0.5905236005783081 Test 0.5778006911277771
Epoch 42 train time : 364.5 loss: 1.98e-01
 test time : 63.6 Train 0.0 Validation 0.5687676668167114 Test 0.5586117506027222
Epoch 43 train time : 366.2 loss: 1.98e-01
 test time : 63.6 Train 0.0 Validation 0.5995568037033081 Test 0.5711786150932312
Epoch 44 train time : 364.4 loss: 1.97e-01
 test time : 63.5 Train 0.0 Validation 0.5913759469985962 Test 0.5608258247375488
Epoch 45 train time : 362.8 loss: 1.95e-01
 test time : 63.7 Train 0.0 Validation 0.596237301826477 Test 0.569364070892334
Epoch 46 train time : 367.1 loss: 1.94e-01
 test time : 63.6 Train 0.0 Validation 0.5969969630241394 Test 0.5615521669387817
Epoch 47 train time : 365.8 loss: 1.94e-01
 test time : 64.2 Train 0.0 Validation 0.6001855134963989 Test 0.5726190805435181
Epoch 48 train time : 365.6 loss: 1.92e-01
 test time : 63.5 Train 0.0 Validation 0.5845446586608887 Test 0.570840060710907
Epoch 49 train time : 363.0 loss: 1.92e-01
 test time : 63.3 Train 0.0 Validation 0.5812854170799255 Test 0.5647168159484863
Epoch 50 train time : 364.5 loss: 1.90e-01
 test time : 63.8 Train 0.0 Validation 0.6070224046707153 Test 0.5679897665977478
Epoch 51 train time : 368.2 loss: 1.89e-01
 test time : 63.6 Train 0.0 Validation 0.599287211894989 Test 0.5903400182723999
Epoch 52 train time : 365.8 loss: 1.89e-01
 test time : 63.5 Train 0.0 Validation 0.6119974255561829 Test 0.5880022048950195
Epoch 53 train time : 363.4 loss: 1.87e-01
 test time : 63.7 Train 0.0 Validation 0.6030859351158142 Test 0.5644509196281433
Epoch 54 train time : 362.3 loss: 1.89e-01
 test time : 63.7 Train 0.0 Validation 0.6014310717582703 Test 0.5827207565307617
Epoch 55 train time : 364.2 loss: 1.87e-01
 test time : 63.7 Train 0.0 Validation 0.6048175692558289 Test 0.5747453570365906
Epoch 56 train time : 364.8 loss: 1.86e-01
 test time : 63.7 Train 0.0 Validation 0.5923933982849121 Test 0.5691369771957397
Epoch 57 train time : 364.8 loss: 1.85e-01
 test time : 63.6 Train 0.0 Validation 0.6061022877693176 Test 0.5734847187995911
Epoch 58 train time : 366.4 loss: 1.85e-01
 test time : 63.7 Train 0.0 Validation 0.59461909532547 Test 0.5637794137001038
Epoch 59 train time : 367.6 loss: 1.85e-01
 test time : 63.7 Train 0.0 Validation 0.5803701877593994 Test 0.5401941537857056
Epoch 60 train time : 364.1 loss: 1.83e-01
 test time : 63.5 Train 0.0 Validation 0.5752677917480469 Test 0.552678108215332
Epoch 61 train time : 364.8 loss: 1.82e-01
 test time : 63.6 Train 0.0 Validation 0.6195119619369507 Test 0.5877454876899719
Epoch 62 train time : 365.4 loss: 1.82e-01
 test time : 63.7 Train 0.0 Validation 0.5958216190338135 Test 0.5629233717918396
Epoch 63 train time : 367.5 loss: 1.81e-01
 test time : 63.7 Train 0.0 Validation 0.609093964099884 Test 0.5886545181274414
Epoch 64 train time : 364.7 loss: 1.80e-01
 test time : 63.7 Train 0.0 Validation 0.6064159274101257 Test 0.5707484483718872
Epoch 65 train time : 364.6 loss: 1.80e-01
 test time : 63.7 Train 0.0 Validation 0.6021363735198975 Test 0.593059241771698
Epoch 66 train time : 361.5 loss: 1.78e-01
 test time : 63.4 Train 0.0 Validation 0.6218441128730774 Test 0.5920685529708862
Epoch 67 train time : 364.8 loss: 1.79e-01
 test time : 63.6 Train 0.0 Validation 0.6106516718864441 Test 0.577032744884491
Epoch 68 train time : 363.5 loss: 1.77e-01
 test time : 63.4 Train 0.0 Validation 0.6007411479949951 Test 0.5721962451934814
Epoch 69 train time : 363.4 loss: 1.78e-01
 test time : 63.7 Train 0.0 Validation 0.6109899282455444 Test 0.5987603068351746
Epoch 70 train time : 365.2 loss: 1.76e-01
 test time : 64.1 Train 0.0 Validation 0.6144181489944458 Test 0.5927148461341858
Epoch 71 train time : 365.9 loss: 1.75e-01
 test time : 63.6 Train 0.0 Validation 0.5998271703720093 Test 0.5754927396774292
Epoch 72 train time : 365.6 loss: 1.76e-01
 test time : 63.5 Train 0.0 Validation 0.6041553616523743 Test 0.5808345675468445
Epoch 73 train time : 366.0 loss: 1.73e-01
 test time : 63.7 Train 0.0 Validation 0.6180669069290161 Test 0.5891331434249878
Epoch 74 train time : 364.1 loss: 1.70e-01
 test time : 63.3 Train 0.0 Validation 0.5917163491249084 Test 0.5818854570388794
Epoch 75 train time : 363.5 loss: 1.61e-01
 test time : 63.3 Train 0.0 Validation 0.6310282349586487 Test 0.6028377413749695
Epoch 76 train time : 363.5 loss: 1.49e-01
 test time : 63.7 Train 0.0 Validation 0.6394014358520508 Test 0.6138681173324585
Epoch 77 train time : 366.7 loss: 1.34e-01
 test time : 64.0 Train 0.0 Validation 0.6413902640342712 Test 0.6294866800308228
Epoch 78 train time : 363.0 loss: 1.20e-01
 test time : 63.9 Train 0.0 Validation 0.6440365314483643 Test 0.6289628744125366
Epoch 79 train time : 364.0 loss: 1.07e-01
 test time : 63.7 Train 0.0 Validation 0.6533528566360474 Test 0.6332938075065613
Epoch 80 train time : 367.7 loss: 9.97e-02
 test time : 63.9 Train 0.0 Validation 0.6537373065948486 Test 0.6307201385498047
Best @79 validation score: 0.6537 Test score: 0.6307
[[79, tensor(0.6537), tensor(0.6307)]]
all runs:  79.0 0.6537373065948486 0.6307201385498047 0.0 0.0 0.0 
