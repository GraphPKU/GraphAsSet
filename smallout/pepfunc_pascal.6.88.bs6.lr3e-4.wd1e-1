/ceph/home/muhan01/wangxiyuan/GraphAsSet/utils.py:20: UserWarning: not equivalent to Identity
  warnings.warn("not equivalent to Identity")
Namespace(dataset='pepfunc', repeat=1, num_workers=0, amp=True, compile=True, batch_size=6, testbatch_size=6, epochs=80, wd=0.1, lr=0.0003, beta=0.9, minlr=0.0, K=0.0, gradclipnorm=1.0, decompnoise=1e-06, seedoffset=0, warmstart=8, conststep=64, cosstep=8, use_y_scale=False, dp=0.0, eldp=0.0, act='silu', lossparam=0.0, advloss=False, embdp=0.0, embbn=False, emborthoinit=False, degreeemb=False, embln=True, featdim=-1, hiddim=88, caldim=-1, normA=False, laplacian=True, sqrtlambda=True, elres=True, usesvmix=True, vmean=True, vnorm=True, elvmean=True, elvnorm=True, snorm=True, gsizenorm=1.85, l_encoder='deepset', l_layers=3, l_combine='mul', l_aggr='mean', l_res=True, l_mlptailact1=True, l_mlplayers1=2, l_mlpnorm1='ln', l_mlptailact2=False, l_mlplayers2=0, l_mlpnorm2='none', num_layers=6, sv_uselinv=True, sv_tailact=True, sv_res=True, sv_numlayer=1, sv_norm='none', el_uselinv=True, el_uselins=False, el_tailact=True, el_numlayer=2, el_norm='none', el_uses=False, conv_uselinv=True, conv_tailact=True, conv_numlayer=1, conv_norm='none', predlin_numlayer=1, predlin_norm='none', lexp='mlp', lexp_layer=2, lexp_norm='ln', outln=False, pool='mean', Tm=1, save='pepfunc.we1e-1', load=None, use_pos=False, align_size=32)
fixed bincls
10873 2331 2331
split 10873 2331 2331
num_task 10
PiOModel(
  (inputencoder): QInputEncoder(
    (xemb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0): Embedding(18, 88, padding_idx=0)
        (1): Embedding(4, 88, padding_idx=0)
        (2-3): 2 x Embedding(8, 88, padding_idx=0)
        (4): Embedding(6, 88, padding_idx=0)
        (5): Embedding(2, 88, padding_idx=0)
        (6): Embedding(7, 88, padding_idx=0)
        (7-8): 2 x Embedding(3, 88, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
      )
    )
    (edgeEmb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0-2): 3 x Embedding(5, 88, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
      )
    )
    (LambdaEmb): MLPEncoding(
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=1, out_features=176, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((176,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=176, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (LambdaEncoder): PermEquiLayer(
    (set2set): Sequential(
      (0): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (1): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (2): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (3): Identity()
    )
    (set2vec): Sequential(
      (0): MLP(
      (lin): Sequential(
        (0): NoneNorm()
      )
    )
    )
  )
  (elprojs): ModuleList(
    (0-5): 6 x sv2el(
      (linv1): Linear(in_features=88, out_features=88, bias=False)
      (linv2): Linear(in_features=88, out_features=88, bias=False)
      (lins1): Identity()
      (lins2): Identity()
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): NoneNorm()
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (svmixs): ModuleList(
    (0-5): 6 x svMix(
      (linv1): Linear(in_features=88, out_features=88, bias=False)
      (linv2): Linear(in_features=88, out_features=88, bias=False)
      (linv3): Identity()
      (lins1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins3): Identity()
    )
  )
  (convs): ModuleList(
    (0-5): 6 x DirCFConv(
      (lins): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (linv): Linear(in_features=88, out_features=88, bias=False)
    )
  )
  (predlin): MLP(
    (lin): Sequential(
      (0): Linear(in_features=88, out_features=10, bias=True)
    )
  )
  (predln): Identity()
  (vln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (elvln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (sln): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
)
numel 587234
Epoch 1 train time : 1192.3 loss: 4.46e-01
 test time : 661.7 Train 0.0 Validation 0.2748994827270508 Test 0.2801026701927185
GPU memory 19.28
Epoch 2 train time : 389.7 loss: 3.24e-01
 test time : 64.1 Train 0.0 Validation 0.3166959881782532 Test 0.3151562809944153
Epoch 3 train time : 378.5 loss: 3.13e-01
 test time : 64.6 Train 0.0 Validation 0.3666723966598511 Test 0.3633846640586853
Epoch 4 train time : 377.0 loss: 2.97e-01
 test time : 64.3 Train 0.0 Validation 0.4016241133213043 Test 0.39178547263145447
Epoch 5 train time : 393.9 loss: 2.88e-01
 test time : 69.3 Train 0.0 Validation 0.4050968587398529 Test 0.4004826545715332
Epoch 6 train time : 398.4 loss: 2.84e-01
 test time : 73.2 Train 0.0 Validation 0.42424383759498596 Test 0.418283611536026
Epoch 7 train time : 403.9 loss: 2.80e-01
 test time : 73.4 Train 0.0 Validation 0.42442455887794495 Test 0.4185715317726135
Epoch 8 train time : 385.7 loss: 2.76e-01
 test time : 64.8 Train 0.0 Validation 0.4327976107597351 Test 0.42219725251197815
Epoch 9 train time : 375.9 loss: 2.71e-01
 test time : 63.5 Train 0.0 Validation 0.45497769117355347 Test 0.4432787299156189
Epoch 10 train time : 376.7 loss: 2.65e-01
 test time : 63.4 Train 0.0 Validation 0.4706272482872009 Test 0.4560003876686096
Epoch 11 train time : 391.9 loss: 2.59e-01
 test time : 68.6 Train 0.0 Validation 0.4740711748600006 Test 0.44290390610694885
Epoch 12 train time : 395.5 loss: 2.55e-01
 test time : 72.8 Train 0.0 Validation 0.5007911920547485 Test 0.4876931607723236
Epoch 13 train time : 405.9 loss: 2.51e-01
 test time : 71.4 Train 0.0 Validation 0.5058620572090149 Test 0.487567275762558
Epoch 14 train time : 387.3 loss: 2.47e-01
 test time : 64.2 Train 0.0 Validation 0.5058392882347107 Test 0.4864770472049713
Epoch 15 train time : 374.8 loss: 2.44e-01
 test time : 65.4 Train 0.0 Validation 0.524055004119873 Test 0.5080370903015137
Epoch 16 train time : 375.1 loss: 2.41e-01
 test time : 64.1 Train 0.0 Validation 0.5296950340270996 Test 0.5145162343978882
Epoch 17 train time : 390.0 loss: 2.37e-01
 test time : 68.7 Train 0.0 Validation 0.5282406806945801 Test 0.5144528150558472
Epoch 18 train time : 397.1 loss: 2.35e-01
 test time : 72.7 Train 0.0 Validation 0.5317840576171875 Test 0.5073251724243164
Epoch 19 train time : 406.0 loss: 2.34e-01
 test time : 72.0 Train 0.0 Validation 0.5421646237373352 Test 0.520753026008606
Epoch 20 train time : 387.2 loss: 2.31e-01
 test time : 64.1 Train 0.0 Validation 0.5493810176849365 Test 0.5293046236038208
Epoch 21 train time : 376.8 loss: 2.28e-01
 test time : 63.3 Train 0.0 Validation 0.5399039387702942 Test 0.5163607001304626
Epoch 22 train time : 374.7 loss: 2.27e-01
 test time : 63.3 Train 0.0 Validation 0.5446442365646362 Test 0.5319312810897827
Epoch 23 train time : 383.1 loss: 2.27e-01
 test time : 68.5 Train 0.0 Validation 0.553252100944519 Test 0.5468363165855408
Epoch 24 train time : 389.3 loss: 2.24e-01
 test time : 71.4 Train 0.0 Validation 0.5512144565582275 Test 0.5455121994018555
Epoch 25 train time : 404.0 loss: 2.23e-01
 test time : 71.8 Train 0.0 Validation 0.5662189722061157 Test 0.5491927862167358
Epoch 26 train time : 390.0 loss: 2.21e-01
 test time : 64.7 Train 0.0 Validation 0.5532461404800415 Test 0.5502501130104065
Epoch 27 train time : 376.1 loss: 2.18e-01
 test time : 64.2 Train 0.0 Validation 0.5501781702041626 Test 0.5545147657394409
Epoch 28 train time : 377.0 loss: 2.18e-01
 test time : 63.9 Train 0.0 Validation 0.5717667937278748 Test 0.5542680621147156
Epoch 29 train time : 382.5 loss: 2.16e-01
 test time : 66.2 Train 0.0 Validation 0.5554872751235962 Test 0.5432325601577759
Epoch 30 train time : 392.9 loss: 2.15e-01
 test time : 73.1 Train 0.0 Validation 0.5620932579040527 Test 0.554377019405365
Epoch 31 train time : 404.4 loss: 2.15e-01
 test time : 69.4 Train 0.0 Validation 0.5833035111427307 Test 0.5573875308036804
Epoch 32 train time : 388.5 loss: 2.13e-01
 test time : 63.4 Train 0.0 Validation 0.5648530721664429 Test 0.561421275138855
Epoch 33 train time : 375.2 loss: 2.09e-01
 test time : 63.9 Train 0.0 Validation 0.5895782709121704 Test 0.5634473562240601
Epoch 34 train time : 374.8 loss: 2.10e-01
 test time : 64.8 Train 0.0 Validation 0.5849772691726685 Test 0.5552071928977966
Epoch 35 train time : 384.4 loss: 2.09e-01
 test time : 69.7 Train 0.0 Validation 0.576424777507782 Test 0.5557450652122498
Epoch 36 train time : 394.9 loss: 2.07e-01
 test time : 70.1 Train 0.0 Validation 0.5752027630805969 Test 0.568233847618103
Epoch 37 train time : 404.5 loss: 2.06e-01
 test time : 74.6 Train 0.0 Validation 0.5877093076705933 Test 0.5796960592269897
Epoch 38 train time : 394.2 loss: 2.04e-01
 test time : 65.0 Train 0.0 Validation 0.577438473701477 Test 0.5589420795440674
Epoch 39 train time : 378.6 loss: 2.03e-01
 test time : 64.6 Train 0.0 Validation 0.5922864675521851 Test 0.5812836289405823
Epoch 40 train time : 376.6 loss: 2.01e-01
 test time : 63.4 Train 0.0 Validation 0.5928758382797241 Test 0.581595242023468
Epoch 41 train time : 383.7 loss: 2.01e-01
 test time : 68.0 Train 0.0 Validation 0.5783669948577881 Test 0.5594149827957153
Epoch 42 train time : 396.4 loss: 2.02e-01
 test time : 70.2 Train 0.0 Validation 0.5884417295455933 Test 0.5592514276504517
Epoch 43 train time : 411.3 loss: 2.00e-01
 test time : 70.8 Train 0.0 Validation 0.6043217778205872 Test 0.570117712020874
Epoch 44 train time : 393.5 loss: 1.98e-01
 test time : 63.4 Train 0.0 Validation 0.5872907638549805 Test 0.5788134336471558
Epoch 45 train time : 376.2 loss: 1.97e-01
 test time : 64.6 Train 0.0 Validation 0.5996031761169434 Test 0.5652193427085876
Epoch 46 train time : 377.2 loss: 1.96e-01
 test time : 64.2 Train 0.0 Validation 0.5985304117202759 Test 0.5862032771110535
Epoch 47 train time : 383.0 loss: 1.95e-01
 test time : 69.4 Train 0.0 Validation 0.5641579031944275 Test 0.5527547597885132
Epoch 48 train time : 395.2 loss: 1.93e-01
 test time : 68.7 Train 0.0 Validation 0.6094877123832703 Test 0.5871545076370239
Epoch 49 train time : 407.6 loss: 1.92e-01
 test time : 72.8 Train 0.0 Validation 0.5967878103256226 Test 0.5801817774772644
Epoch 50 train time : 393.0 loss: 1.92e-01
 test time : 64.3 Train 0.0 Validation 0.5891941785812378 Test 0.5839771032333374
Epoch 51 train time : 374.8 loss: 1.90e-01
 test time : 63.4 Train 0.0 Validation 0.5869176983833313 Test 0.5596376657485962
Epoch 52 train time : 372.8 loss: 1.89e-01
 test time : 63.3 Train 0.0 Validation 0.6252039670944214 Test 0.5958950519561768
Epoch 53 train time : 379.2 loss: 1.89e-01
 test time : 70.3 Train 0.0 Validation 0.6070974469184875 Test 0.5761057138442993
Epoch 54 train time : 397.9 loss: 1.86e-01
 test time : 69.2 Train 0.0 Validation 0.6276559233665466 Test 0.5937680006027222
Epoch 55 train time : 408.0 loss: 1.88e-01
 test time : 70.8 Train 0.0 Validation 0.6089037656784058 Test 0.5844632387161255
Epoch 56 train time : 394.2 loss: 1.84e-01
 test time : 64.3 Train 0.0 Validation 0.591501772403717 Test 0.5793458819389343
Epoch 57 train time : 376.2 loss: 1.86e-01
 test time : 64.9 Train 0.0 Validation 0.5990890264511108 Test 0.5916767716407776
Epoch 58 train time : 375.0 loss: 1.84e-01
 test time : 63.8 Train 0.0 Validation 0.61992347240448 Test 0.5886213779449463
Epoch 59 train time : 380.1 loss: 1.82e-01
 test time : 69.4 Train 0.0 Validation 0.6040774583816528 Test 0.5955550670623779
Epoch 60 train time : 394.7 loss: 1.83e-01
 test time : 67.8 Train 0.0 Validation 0.5886393785476685 Test 0.5728716254234314
Epoch 61 train time : 410.7 loss: 1.83e-01
 test time : 69.7 Train 0.0 Validation 0.5876822471618652 Test 0.5830917358398438
Epoch 62 train time : 394.6 loss: 1.81e-01
 test time : 63.2 Train 0.0 Validation 0.5853112936019897 Test 0.5297467112541199
Epoch 63 train time : 375.0 loss: 1.80e-01
 test time : 64.2 Train 0.0 Validation 0.6167737245559692 Test 0.5999369621276855
Epoch 64 train time : 378.1 loss: 1.80e-01
 test time : 65.9 Train 0.0 Validation 0.6064862012863159 Test 0.5873263478279114
Epoch 65 train time : 379.2 loss: 1.79e-01
 test time : 68.1 Train 0.0 Validation 0.6050600409507751 Test 0.5857192277908325
Epoch 66 train time : 396.6 loss: 1.78e-01
 test time : 68.8 Train 0.0 Validation 0.6186125874519348 Test 0.5913753509521484
Epoch 67 train time : 406.2 loss: 1.79e-01
 test time : 72.4 Train 0.0 Validation 0.608444333076477 Test 0.5853073000907898
Epoch 68 train time : 396.9 loss: 1.76e-01
 test time : 65.1 Train 0.0 Validation 0.5872241854667664 Test 0.5628517270088196
Epoch 69 train time : 378.0 loss: 1.76e-01
 test time : 63.8 Train 0.0 Validation 0.5990460515022278 Test 0.588695228099823
Epoch 70 train time : 375.6 loss: 1.76e-01
 test time : 63.2 Train 0.0 Validation 0.6143189072608948 Test 0.6029056310653687
Epoch 71 train time : 376.3 loss: 1.75e-01
 test time : 69.7 Train 0.0 Validation 0.6201094388961792 Test 0.60881507396698
Epoch 72 train time : 400.8 loss: 1.73e-01
 test time : 65.1 Train 0.0 Validation 0.6243301033973694 Test 0.6030029654502869
Epoch 73 train time : 407.3 loss: 1.72e-01
 test time : 70.8 Train 0.0 Validation 0.6091466546058655 Test 0.599400520324707
Epoch 74 train time : 400.2 loss: 1.68e-01
 test time : 63.7 Train 0.0 Validation 0.598080039024353 Test 0.5787815451622009
Epoch 75 train time : 379.4 loss: 1.60e-01
 test time : 65.1 Train 0.0 Validation 0.6120215654373169 Test 0.6000873446464539
Epoch 76 train time : 374.4 loss: 1.49e-01
 test time : 64.7 Train 0.0 Validation 0.623333752155304 Test 0.6127355694770813
Epoch 77 train time : 378.1 loss: 1.36e-01
 test time : 66.4 Train 0.0 Validation 0.632655680179596 Test 0.6185358762741089
Epoch 78 train time : 394.9 loss: 1.22e-01
 test time : 66.4 Train 0.0 Validation 0.6357436180114746 Test 0.6327421069145203
Epoch 79 train time : 402.2 loss: 1.11e-01
 test time : 72.8 Train 0.0 Validation 0.6381385326385498 Test 0.6303235292434692
Epoch 80 train time : 403.9 loss: 1.04e-01
 test time : 63.4 Train 0.0 Validation 0.6375848054885864 Test 0.6311857104301453
Best @78 validation score: 0.6381 Test score: 0.6303
[[78, tensor(0.6381), tensor(0.6303)]]
all runs:  78.0 0.6381385326385498 0.6303235292434692 0.0 0.0 0.0 
