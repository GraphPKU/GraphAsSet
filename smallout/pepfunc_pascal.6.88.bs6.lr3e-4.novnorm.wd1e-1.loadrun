/ceph/home/muhan01/wangxiyuan/GraphAsSet/utils.py:20: UserWarning: not equivalent to Identity
  warnings.warn("not equivalent to Identity")
Namespace(dataset='pepfunc', repeat=1, num_workers=0, amp=True, compile=True, batch_size=6, testbatch_size=6, epochs=80, wd=0.1, lr=0.0003, beta=0.9, minlr=0.0, K=0.0, gradclipnorm=1.0, decompnoise=1e-06, seedoffset=0, warmstart=8, conststep=64, cosstep=8, use_y_scale=False, dp=0.0, eldp=0.0, act='silu', lossparam=0.0, advloss=False, embdp=0.0, embbn=False, emborthoinit=False, degreeemb=False, embln=True, featdim=-1, hiddim=88, caldim=-1, normA=False, laplacian=True, sqrtlambda=True, elres=True, usesvmix=True, vmean=True, vnorm=False, elvmean=True, elvnorm=True, snorm=True, gsizenorm=1.85, l_encoder='deepset', l_layers=3, l_combine='mul', l_aggr='mean', l_res=True, l_mlptailact1=True, l_mlplayers1=2, l_mlpnorm1='ln', l_mlptailact2=False, l_mlplayers2=0, l_mlpnorm2='none', num_layers=6, sv_uselinv=True, sv_tailact=True, sv_res=True, sv_numlayer=1, sv_norm='none', el_uselinv=True, el_uselins=False, el_tailact=True, el_numlayer=2, el_norm='none', el_uses=False, conv_uselinv=True, conv_tailact=True, conv_numlayer=1, conv_norm='none', predlin_numlayer=1, predlin_norm='none', lexp='mlp', lexp_layer=2, lexp_norm='ln', outln=False, pool='mean', Tm=1, save='pepfunc.novnorm.wd1e-1', load=None, use_pos=False, align_size=32)
fixed bincls
10873 2331 2331
split 10873 2331 2331
num_task 10
PiOModel(
  (inputencoder): QInputEncoder(
    (xemb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0): Embedding(18, 88, padding_idx=0)
        (1): Embedding(4, 88, padding_idx=0)
        (2-3): 2 x Embedding(8, 88, padding_idx=0)
        (4): Embedding(6, 88, padding_idx=0)
        (5): Embedding(2, 88, padding_idx=0)
        (6): Embedding(7, 88, padding_idx=0)
        (7-8): 2 x Embedding(3, 88, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
      )
    )
    (edgeEmb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0-2): 3 x Embedding(5, 88, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
      )
    )
    (LambdaEmb): MLPEncoding(
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=1, out_features=176, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((176,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=176, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (LambdaEncoder): PermEquiLayer(
    (set2set): Sequential(
      (0): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (1): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (2): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (3): Identity()
    )
    (set2vec): Sequential(
      (0): MLP(
      (lin): Sequential(
        (0): NoneNorm()
      )
    )
    )
  )
  (elprojs): ModuleList(
    (0-5): 6 x sv2el(
      (linv1): Linear(in_features=88, out_features=88, bias=False)
      (linv2): Linear(in_features=88, out_features=88, bias=False)
      (lins1): Identity()
      (lins2): Identity()
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): NoneNorm()
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (svmixs): ModuleList(
    (0-5): 6 x svMix(
      (linv1): Linear(in_features=88, out_features=88, bias=False)
      (linv2): Linear(in_features=88, out_features=88, bias=False)
      (linv3): Identity()
      (lins1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins3): Identity()
    )
  )
  (convs): ModuleList(
    (0-5): 6 x DirCFConv(
      (lins): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (linv): Linear(in_features=88, out_features=88, bias=False)
    )
  )
  (predlin): MLP(
    (lin): Sequential(
      (0): Linear(in_features=88, out_features=10, bias=True)
    )
  )
  (predln): Identity()
  (vln): Sequential(
    (0): VMean()
    (1): Identity()
  )
  (elvln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (sln): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
)
numel 587234
Epoch 1 train time : 590.0 loss: 4.92e-01
 test time : 324.2 Train 0.0 Validation 0.2803638279438019 Test 0.2807464599609375
GPU memory 19.86
Epoch 2 train time : 381.0 loss: 3.22e-01
 test time : 61.1 Train 0.0 Validation 0.31843101978302 Test 0.3240066468715668
Epoch 3 train time : 361.2 loss: 3.13e-01
 test time : 61.0 Train 0.0 Validation 0.3425086736679077 Test 0.34526681900024414
Epoch 4 train time : 359.1 loss: 3.05e-01
 test time : 61.0 Train 0.0 Validation 0.3643713593482971 Test 0.36266711354255676
Epoch 5 train time : 356.6 loss: 2.99e-01
 test time : 61.0 Train 0.0 Validation 0.3754855990409851 Test 0.37866705656051636
Epoch 6 train time : 361.6 loss: 2.94e-01
 test time : 61.0 Train 0.0 Validation 0.38620859384536743 Test 0.38645291328430176
Epoch 7 train time : 360.3 loss: 2.87e-01
 test time : 61.0 Train 0.0 Validation 0.40607699751853943 Test 0.4027012288570404
Epoch 8 train time : 361.2 loss: 2.83e-01
 test time : 61.0 Train 0.0 Validation 0.41906851530075073 Test 0.4146011471748352
Epoch 9 train time : 360.1 loss: 2.78e-01
 test time : 61.1 Train 0.0 Validation 0.4364221692085266 Test 0.4189748764038086
Epoch 10 train time : 359.7 loss: 2.74e-01
 test time : 60.9 Train 0.0 Validation 0.4403849244117737 Test 0.43097123503685
Epoch 11 train time : 359.2 loss: 2.70e-01
 test time : 61.0 Train 0.0 Validation 0.4552029073238373 Test 0.434822142124176
Epoch 12 train time : 358.0 loss: 2.67e-01
 test time : 61.0 Train 0.0 Validation 0.4543543756008148 Test 0.4473676085472107
Epoch 13 train time : 361.0 loss: 2.63e-01
 test time : 61.0 Train 0.0 Validation 0.4792429506778717 Test 0.4611976146697998
Epoch 14 train time : 361.3 loss: 2.61e-01
 test time : 61.0 Train 0.0 Validation 0.4734434485435486 Test 0.4524034559726715
Epoch 15 train time : 357.6 loss: 2.58e-01
 test time : 61.0 Train 0.0 Validation 0.48008212447166443 Test 0.45324674248695374
Epoch 16 train time : 357.3 loss: 2.55e-01
 test time : 61.6 Train 0.0 Validation 0.4941225051879883 Test 0.46079516410827637
Epoch 17 train time : 355.7 loss: 2.52e-01
 test time : 61.0 Train 0.0 Validation 0.49453306198120117 Test 0.47807931900024414
Epoch 18 train time : 362.1 loss: 2.51e-01
 test time : 61.0 Train 0.0 Validation 0.5135183930397034 Test 0.4983827471733093
Epoch 19 train time : 357.1 loss: 2.49e-01
 test time : 61.0 Train 0.0 Validation 0.4731675684452057 Test 0.4661669135093689
Epoch 20 train time : 359.4 loss: 2.47e-01
 test time : 61.0 Train 0.0 Validation 0.5070006847381592 Test 0.4842871129512787
Epoch 21 train time : 360.5 loss: 2.45e-01
 test time : 60.9 Train 0.0 Validation 0.5167221426963806 Test 0.5025487542152405
Epoch 22 train time : 358.0 loss: 2.43e-01
 test time : 61.0 Train 0.0 Validation 0.49643486738204956 Test 0.4838690757751465
Epoch 23 train time : 359.1 loss: 2.42e-01
 test time : 61.5 Train 0.0 Validation 0.47456493973731995 Test 0.46384477615356445
Epoch 24 train time : 358.1 loss: 2.40e-01
 test time : 61.0 Train 0.0 Validation 0.5214584469795227 Test 0.512588381767273
Epoch 25 train time : 357.7 loss: 2.38e-01
 test time : 61.0 Train 0.0 Validation 0.5339080691337585 Test 0.5161100625991821
Epoch 26 train time : 360.0 loss: 2.36e-01
 test time : 61.0 Train 0.0 Validation 0.5280700922012329 Test 0.515873372554779
Epoch 27 train time : 358.2 loss: 2.36e-01
 test time : 61.0 Train 0.0 Validation 0.5453373789787292 Test 0.5160037279129028
Epoch 28 train time : 356.2 loss: 2.33e-01
 test time : 60.9 Train 0.0 Validation 0.5435746908187866 Test 0.5150582790374756
Epoch 29 train time : 359.9 loss: 2.32e-01
 test time : 61.0 Train 0.0 Validation 0.566632866859436 Test 0.5311844348907471
Epoch 30 train time : 360.0 loss: 2.32e-01
 test time : 61.5 Train 0.0 Validation 0.5392314791679382 Test 0.5101455450057983
Epoch 31 train time : 358.3 loss: 2.30e-01
 test time : 60.9 Train 0.0 Validation 0.5529915690422058 Test 0.5298548340797424
Epoch 32 train time : 355.6 loss: 2.29e-01
 test time : 60.9 Train 0.0 Validation 0.5418950319290161 Test 0.5240463018417358
Epoch 33 train time : 356.9 loss: 2.29e-01
 test time : 60.9 Train 0.0 Validation 0.543921172618866 Test 0.5220637321472168
Epoch 34 train time : 359.9 loss: 2.28e-01
 test time : 61.0 Train 0.0 Validation 0.5571446418762207 Test 0.5437318682670593
Epoch 35 train time : 360.5 loss: 2.28e-01
 test time : 60.9 Train 0.0 Validation 0.5564175844192505 Test 0.5443806052207947
Epoch 36 train time : 358.6 loss: 2.26e-01
 test time : 60.9 Train 0.0 Validation 0.5622608661651611 Test 0.5416501760482788
Epoch 37 train time : 358.1 loss: 2.25e-01
 test time : 60.9 Train 0.0 Validation 0.5669317841529846 Test 0.5370678305625916
Epoch 38 train time : 359.0 loss: 2.23e-01
 test time : 60.9 Train 0.0 Validation 0.5637634992599487 Test 0.5416794419288635
Epoch 39 train time : 360.1 loss: 2.23e-01
 test time : 60.9 Train 0.0 Validation 0.5730786919593811 Test 0.5420104265213013
Epoch 40 train time : 359.0 loss: 2.22e-01
 test time : 60.9 Train 0.0 Validation 0.5608671307563782 Test 0.5340651273727417
Epoch 41 train time : 357.7 loss: 2.22e-01
 test time : 61.0 Train 0.0 Validation 0.549730122089386 Test 0.5407659411430359
Epoch 42 train time : 358.7 loss: 2.22e-01
 test time : 60.9 Train 0.0 Validation 0.5546119213104248 Test 0.522549033164978
Epoch 43 train time : 356.6 loss: 2.21e-01
 test time : 61.0 Train 0.0 Validation 0.5556085109710693 Test 0.5202137231826782
Epoch 44 train time : 358.1 loss: 2.20e-01
 test time : 60.9 Train 0.0 Validation 0.561074435710907 Test 0.528502881526947
Epoch 45 train time : 357.2 loss: 2.19e-01
 test time : 61.5 Train 0.0 Validation 0.5751503109931946 Test 0.540794849395752
Epoch 46 train time : 358.7 loss: 2.18e-01
 test time : 60.9 Train 0.0 Validation 0.5394138097763062 Test 0.5343512296676636
Epoch 47 train time : 360.0 loss: 2.19e-01
 test time : 61.0 Train 0.0 Validation 0.5890840888023376 Test 0.5549066662788391
Epoch 48 train time : 373.0 loss: 2.18e-01
 test time : 60.9 Train 0.0 Validation 0.5651188492774963 Test 0.5347157716751099
Epoch 49 train time : 361.6 loss: 2.17e-01
 test time : 61.1 Train 0.0 Validation 0.580710768699646 Test 0.5339611768722534
Epoch 50 train time : 357.8 loss: 2.16e-01
 test time : 60.9 Train 0.0 Validation 0.5474058985710144 Test 0.5215489268302917
Epoch 51 train time : 357.5 loss: 2.17e-01
 test time : 60.8 Train 0.0 Validation 0.5907619595527649 Test 0.5594423413276672
Epoch 52 train time : 355.7 loss: 2.18e-01
 test time : 61.6 Train 0.0 Validation 0.5764342546463013 Test 0.5462815761566162
Epoch 53 train time : 356.9 loss: 2.18e-01
 test time : 61.0 Train 0.0 Validation 0.5809338688850403 Test 0.5554296374320984
Epoch 54 train time : 359.2 loss: 2.15e-01
 test time : 61.4 Train 0.0 Validation 0.5904573202133179 Test 0.5633469820022583
Epoch 55 train time : 361.2 loss: 2.13e-01
 test time : 61.0 Train 0.0 Validation 0.5972615480422974 Test 0.5722315907478333
Epoch 56 train time : 359.8 loss: 2.16e-01
 test time : 61.1 Train 0.0 Validation 0.5860366225242615 Test 0.553192138671875
Epoch 57 train time : 358.4 loss: 2.13e-01
 test time : 61.0 Train 0.0 Validation 0.570285439491272 Test 0.5462963581085205
Epoch 58 train time : 357.4 loss: 2.15e-01
 test time : 61.1 Train 0.0 Validation 0.5471580624580383 Test 0.5282639265060425
Epoch 59 train time : 360.0 loss: 2.13e-01
 test time : 61.0 Train 0.0 Validation 0.5851905941963196 Test 0.5451380014419556
Epoch 60 train time : 362.1 loss: 2.12e-01
 test time : 61.0 Train 0.0 Validation 0.5985940098762512 Test 0.5552256107330322
Epoch 61 train time : 358.1 loss: 2.12e-01
 test time : 61.0 Train 0.0 Validation 0.5713398456573486 Test 0.5334383845329285
Epoch 62 train time : 356.5 loss: 2.11e-01
 test time : 61.2 Train 0.0 Validation 0.5934313535690308 Test 0.544491171836853
Epoch 63 train time : 362.9 loss: 2.10e-01
 test time : 61.0 Train 0.0 Validation 0.5946069955825806 Test 0.5722344517707825
Epoch 64 train time : 360.2 loss: 2.10e-01
 test time : 61.0 Train 0.0 Validation 0.5879608392715454 Test 0.5537928342819214
Epoch 65 train time : 359.5 loss: 2.10e-01
 test time : 61.0 Train 0.0 Validation 0.6035671830177307 Test 0.5683294534683228
Epoch 66 train time : 358.2 loss: 2.10e-01
 test time : 60.9 Train 0.0 Validation 0.5759958028793335 Test 0.5397125482559204
Epoch 67 train time : 357.8 loss: 2.09e-01
 test time : 61.9 Train 0.0 Validation 0.5584245920181274 Test 0.5360189080238342
Epoch 68 train time : 359.9 loss: 2.09e-01
 test time : 60.9 Train 0.0 Validation 0.5931804776191711 Test 0.5716572999954224
Epoch 69 train time : 358.2 loss: 2.08e-01
 test time : 61.3 Train 0.0 Validation 0.5992051362991333 Test 0.5549683570861816
Epoch 70 train time : 359.8 loss: 2.06e-01
 test time : 61.2 Train 0.0 Validation 0.5854989290237427 Test 0.5597898364067078
Epoch 71 train time : 355.9 loss: 2.05e-01
 test time : 61.0 Train 0.0 Validation 0.5744131803512573 Test 0.5583706498146057
Epoch 72 train time : 358.9 loss: 2.05e-01
 test time : 61.2 Train 0.0 Validation 0.574682354927063 Test 0.5533777475357056
Epoch 73 train time : 357.8 loss: 2.05e-01
 test time : 60.9 Train 0.0 Validation 0.6046658754348755 Test 0.5738478302955627
Epoch 74 train time : 359.2 loss: 2.02e-01
 test time : 61.6 Train 0.0 Validation 0.5925414562225342 Test 0.5618215203285217
Epoch 75 train time : 357.1 loss: 1.97e-01
 test time : 60.9 Train 0.0 Validation 0.6143004894256592 Test 0.5874606370925903
Epoch 76 train time : 358.6 loss: 1.90e-01
 test time : 61.0 Train 0.0 Validation 0.62894606590271 Test 0.5946801900863647
Epoch 77 train time : 361.4 loss: 1.79e-01
 test time : 61.2 Train 0.0 Validation 0.628393292427063 Test 0.6008616089820862
Epoch 78 train time : 363.4 loss: 1.71e-01
 test time : 61.3 Train 0.0 Validation 0.6185261607170105 Test 0.5988869667053223
Epoch 79 train time : 361.9 loss: 1.63e-01
 test time : 61.1 Train 0.0 Validation 0.6351909041404724 Test 0.6125916838645935
Epoch 80 train time : 358.9 loss: 1.57e-01
 test time : 61.3 Train 0.0 Validation 0.6330705881118774 Test 0.6147127151489258
Best @78 validation score: 0.6352 Test score: 0.6126
[[78, tensor(0.6352), tensor(0.6126)]]
all runs:  78.0 0.6351909041404724 0.6125916838645935 0.0 0.0 0.0 
