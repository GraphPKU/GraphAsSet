/ceph/home/muhan01/wangxiyuan/GraphAsSet/utils.py:20: UserWarning: not equivalent to Identity
  warnings.warn("not equivalent to Identity")
Namespace(dataset='pepstruct', repeat=1, num_workers=0, amp=True, compile=True, batch_size=4, testbatch_size=4, epochs=80, wd=0.1, lr=0.0002, beta=0.9, minlr=0.0, K=0.0, gradclipnorm=1.0, decompnoise=1e-06, seedoffset=0, warmstart=8, conststep=84, cosstep=8, use_y_scale=False, dp=0.0, eldp=0.0, act='silu', lossparam=0.0, advloss=False, embdp=0.0, embbn=False, emborthoinit=False, degreeemb=False, embln=True, featdim=-1, hiddim=64, caldim=-1, normA=False, laplacian=True, sqrtlambda=True, elres=True, usesvmix=True, vmean=True, vnorm=True, elvmean=True, elvnorm=True, snorm=True, gsizenorm=1.85, l_encoder='deepset', l_layers=3, l_combine='mul', l_aggr='mean', l_res=True, l_mlptailact1=True, l_mlplayers1=2, l_mlpnorm1='ln', l_mlptailact2=False, l_mlplayers2=0, l_mlpnorm2='none', num_layers=10, sv_uselinv=True, sv_tailact=True, sv_res=True, sv_numlayer=1, sv_norm='none', el_uselinv=True, el_uselins=False, el_tailact=True, el_numlayer=2, el_norm='none', el_uses=False, conv_uselinv=True, conv_tailact=True, conv_numlayer=1, conv_norm='none', predlin_numlayer=1, predlin_norm='none', lexp='mlp', lexp_layer=2, lexp_norm='ln', outln=False, pool='mean', Tm=1, save='pepstruct.10.64.wd1e-1', load=None, use_pos=False, align_size=32)
fixed l1reg
10873 2331 2331
split 10873 2331 2331
num_task 11
PiOModel(
  (inputencoder): QInputEncoder(
    (xemb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0): Embedding(18, 64, padding_idx=0)
        (1): Embedding(4, 64, padding_idx=0)
        (2-3): 2 x Embedding(8, 64, padding_idx=0)
        (4): Embedding(6, 64, padding_idx=0)
        (5): Embedding(2, 64, padding_idx=0)
        (6): Embedding(7, 64, padding_idx=0)
        (7-8): 2 x Embedding(3, 64, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=False)
      )
    )
    (edgeEmb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0-2): 3 x Embedding(5, 64, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((64,), eps=1e-05, elementwise_affine=False)
      )
    )
    (LambdaEmb): MLPEncoding(
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=1, out_features=128, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=128, out_features=64, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (LambdaEncoder): PermEquiLayer(
    (set2set): Sequential(
      (0): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (1): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (2): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (3): Identity()
    )
    (set2vec): Sequential(
      (0): MLP(
      (lin): Sequential(
        (0): NoneNorm()
      )
    )
    )
  )
  (elprojs): ModuleList(
    (0-9): 10 x sv2el(
      (linv1): Linear(in_features=64, out_features=64, bias=False)
      (linv2): Linear(in_features=64, out_features=64, bias=False)
      (lins1): Identity()
      (lins2): Identity()
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
          (3): Linear(in_features=64, out_features=64, bias=True)
          (4): NoneNorm()
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (svmixs): ModuleList(
    (0-9): 10 x svMix(
      (linv1): Linear(in_features=64, out_features=64, bias=False)
      (linv2): Linear(in_features=64, out_features=64, bias=False)
      (linv3): Identity()
      (lins1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins3): Identity()
    )
  )
  (convs): ModuleList(
    (0-9): 10 x DirCFConv(
      (lins): MLP(
        (lin): Sequential(
          (0): Linear(in_features=64, out_features=64, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (linv): Linear(in_features=64, out_features=64, bias=False)
    )
  )
  (predlin): MLP(
    (lin): Sequential(
      (0): Linear(in_features=64, out_features=11, bias=True)
    )
  )
  (predln): Identity()
  (vln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (elvln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (sln): LayerNorm((64,), eps=1e-05, elementwise_affine=False)
)
numel 478603
Epoch 1 train time : 1140.5 loss: 5.37e-01
 test time : 605.0 Train 0.0 Validation 0.366813063621521 Test 0.3757805824279785
GPU memory 14.89
Epoch 2 train time : 368.7 loss: 3.63e-01
 test time : 60.7 Train 0.0 Validation 0.32842564582824707 Test 0.3370777666568756
Epoch 3 train time : 364.6 loss: 3.39e-01
 test time : 60.4 Train 0.0 Validation 0.31023314595222473 Test 0.3170202672481537
Epoch 4 train time : 368.8 loss: 3.25e-01
 test time : 60.5 Train 0.0 Validation 0.2910894751548767 Test 0.29752492904663086
Epoch 5 train time : 366.4 loss: 3.23e-01
 test time : 60.5 Train 0.0 Validation 0.30435681343078613 Test 0.31095585227012634
Epoch 6 train time : 367.4 loss: 3.23e-01
 test time : 60.7 Train 0.0 Validation 0.29944828152656555 Test 0.3043856918811798
Epoch 7 train time : 368.6 loss: 3.17e-01
 test time : 60.5 Train 0.0 Validation 0.2969092130661011 Test 0.3040429949760437
Epoch 8 train time : 369.0 loss: 3.16e-01
 test time : 60.7 Train 0.0 Validation 0.31489479541778564 Test 0.32345452904701233
Epoch 9 train time : 368.1 loss: 3.12e-01
 test time : 60.6 Train 0.0 Validation 0.30328354239463806 Test 0.3071894347667694
Epoch 10 train time : 367.6 loss: 3.11e-01
 test time : 60.6 Train 0.0 Validation 0.29430532455444336 Test 0.300137460231781
Epoch 11 train time : 366.1 loss: 3.07e-01
 test time : 60.7 Train 0.0 Validation 0.3374520540237427 Test 0.3474673330783844
Epoch 12 train time : 367.8 loss: 3.05e-01
 test time : 60.5 Train 0.0 Validation 0.29131022095680237 Test 0.2980765700340271
Epoch 13 train time : 368.3 loss: 3.03e-01
 test time : 60.6 Train 0.0 Validation 0.28753381967544556 Test 0.29306840896606445
Epoch 14 train time : 365.7 loss: 3.01e-01
 test time : 60.5 Train 0.0 Validation 0.2932667136192322 Test 0.2990504801273346
Epoch 15 train time : 368.3 loss: 3.01e-01
 test time : 60.6 Train 0.0 Validation 0.2933184802532196 Test 0.29900091886520386
Epoch 16 train time : 364.1 loss: 2.98e-01
 test time : 60.5 Train 0.0 Validation 0.28466054797172546 Test 0.28898710012435913
Epoch 17 train time : 367.7 loss: 2.97e-01
 test time : 60.6 Train 0.0 Validation 0.27711620926856995 Test 0.2823442220687866
Epoch 18 train time : 367.1 loss: 2.96e-01
 test time : 60.5 Train 0.0 Validation 0.27918338775634766 Test 0.2821725308895111
Epoch 19 train time : 365.4 loss: 2.95e-01
 test time : 60.5 Train 0.0 Validation 0.2771551311016083 Test 0.2841250002384186
Epoch 20 train time : 368.3 loss: 2.95e-01
 test time : 60.2 Train 0.0 Validation 0.2779805064201355 Test 0.28414279222488403
Epoch 21 train time : 364.6 loss: 2.92e-01
 test time : 60.6 Train 0.0 Validation 0.2847178280353546 Test 0.2901470959186554
Epoch 22 train time : 366.3 loss: 2.92e-01
 test time : 60.5 Train 0.0 Validation 0.28194719552993774 Test 0.28714513778686523
Epoch 23 train time : 366.4 loss: 2.91e-01
 test time : 60.3 Train 0.0 Validation 0.2768719494342804 Test 0.2792772948741913
Epoch 24 train time : 365.6 loss: 2.90e-01
 test time : 60.5 Train 0.0 Validation 0.2813815176486969 Test 0.2864084541797638
Epoch 25 train time : 366.9 loss: 2.91e-01
 test time : 60.5 Train 0.0 Validation 0.2807457149028778 Test 0.2843051850795746
Epoch 26 train time : 366.0 loss: 2.89e-01
 test time : 60.5 Train 0.0 Validation 0.2747873067855835 Test 0.28178125619888306
Epoch 27 train time : 366.4 loss: 2.88e-01
 test time : 60.4 Train 0.0 Validation 0.2798561751842499 Test 0.2825525104999542
Epoch 28 train time : 362.9 loss: 2.88e-01
 test time : 60.6 Train 0.0 Validation 0.2726087272167206 Test 0.2795250713825226
Epoch 29 train time : 365.7 loss: 2.87e-01
 test time : 60.3 Train 0.0 Validation 0.2774350345134735 Test 0.27955982089042664
Epoch 30 train time : 365.7 loss: 2.87e-01
 test time : 60.6 Train 0.0 Validation 0.27335721254348755 Test 0.27810895442962646
Epoch 31 train time : 367.9 loss: 2.87e-01
 test time : 60.4 Train 0.0 Validation 0.27681905031204224 Test 0.2819433808326721
Epoch 32 train time : 366.9 loss: 2.86e-01
 test time : 60.5 Train 0.0 Validation 0.2800673842430115 Test 0.28442540764808655
Epoch 33 train time : 366.3 loss: 2.85e-01
 test time : 60.5 Train 0.0 Validation 0.27248886227607727 Test 0.27747032046318054
Epoch 34 train time : 365.1 loss: 2.86e-01
 test time : 60.1 Train 0.0 Validation 0.27434253692626953 Test 0.27925875782966614
Epoch 35 train time : 363.2 loss: 2.86e-01
 test time : 59.9 Train 0.0 Validation 0.27313604950904846 Test 0.28069818019866943
Epoch 36 train time : 361.5 loss: 2.84e-01
 test time : 60.1 Train 0.0 Validation 0.27357742190361023 Test 0.2774626910686493
Epoch 37 train time : 363.8 loss: 2.84e-01
 test time : 59.9 Train 0.0 Validation 0.2718043029308319 Test 0.2772909998893738
Epoch 38 train time : 362.9 loss: 2.84e-01
 test time : 60.1 Train 0.0 Validation 0.2882010042667389 Test 0.29734495282173157
Epoch 39 train time : 364.2 loss: 2.84e-01
 test time : 59.9 Train 0.0 Validation 0.27196332812309265 Test 0.2772398889064789
Epoch 40 train time : 362.1 loss: 2.85e-01
 test time : 59.9 Train 0.0 Validation 0.2848217487335205 Test 0.2868446111679077
Epoch 41 train time : 361.0 loss: 2.84e-01
 test time : 59.9 Train 0.0 Validation 0.286228746175766 Test 0.2845425009727478
Epoch 42 train time : 363.0 loss: 2.83e-01
 test time : 59.8 Train 0.0 Validation 0.2824974060058594 Test 0.2891821563243866
Epoch 43 train time : 361.6 loss: 2.83e-01
 test time : 60.0 Train 0.0 Validation 0.2802967131137848 Test 0.2804540693759918
Epoch 44 train time : 362.6 loss: 2.82e-01
 test time : 59.8 Train 0.0 Validation 0.2736900746822357 Test 0.2780163884162903
Epoch 45 train time : 364.5 loss: 2.83e-01
 test time : 60.0 Train 0.0 Validation 0.28789082169532776 Test 0.2921903729438782
Epoch 46 train time : 361.1 loss: 2.82e-01
 test time : 59.7 Train 0.0 Validation 0.2820011079311371 Test 0.2808302044868469
Epoch 47 train time : 361.6 loss: 2.82e-01
 test time : 59.8 Train 0.0 Validation 0.2806604206562042 Test 0.2847757339477539
Epoch 48 train time : 364.3 loss: 2.82e-01
 test time : 60.1 Train 0.0 Validation 0.27278104424476624 Test 0.2759777903556824
Epoch 49 train time : 362.5 loss: 2.81e-01
 test time : 59.8 Train 0.0 Validation 0.2732183635234833 Test 0.2814055383205414
Epoch 50 train time : 361.3 loss: 2.83e-01
 test time : 60.1 Train 0.0 Validation 0.2679654657840729 Test 0.27115005254745483
Epoch 51 train time : 362.3 loss: 2.81e-01
 test time : 59.8 Train 0.0 Validation 0.2739555239677429 Test 0.2786920964717865
Epoch 52 train time : 362.3 loss: 2.80e-01
 test time : 60.1 Train 0.0 Validation 0.29809245467185974 Test 0.3030192255973816
Epoch 53 train time : 362.7 loss: 2.80e-01
 test time : 59.9 Train 0.0 Validation 0.2835477590560913 Test 0.2876232862472534
Epoch 54 train time : 363.3 loss: 2.80e-01
 test time : 60.1 Train 0.0 Validation 0.2749936878681183 Test 0.2786853611469269
Epoch 55 train time : 364.8 loss: 2.81e-01
 test time : 60.0 Train 0.0 Validation 0.2711443305015564 Test 0.27565640211105347
Epoch 56 train time : 360.3 loss: 2.81e-01
 test time : 60.0 Train 0.0 Validation 0.27118363976478577 Test 0.2761019468307495
Epoch 57 train time : 364.4 loss: 2.82e-01
 test time : 60.0 Train 0.0 Validation 0.26735836267471313 Test 0.27179014682769775
Epoch 58 train time : 360.5 loss: 2.79e-01
 test time : 59.9 Train 0.0 Validation 0.27265939116477966 Test 0.2802684009075165
Epoch 59 train time : 362.7 loss: 2.80e-01
 test time : 60.0 Train 0.0 Validation 0.28253474831581116 Test 0.2868629992008209
Epoch 60 train time : 360.6 loss: 2.80e-01
 test time : 59.8 Train 0.0 Validation 0.2704801857471466 Test 0.27478906512260437
Epoch 61 train time : 360.6 loss: 2.79e-01
 test time : 60.0 Train 0.0 Validation 0.2712688744068146 Test 0.2703908085823059
Epoch 62 train time : 365.0 loss: 2.79e-01
 test time : 59.8 Train 0.0 Validation 0.27982109785079956 Test 0.2829744517803192
Epoch 63 train time : 364.2 loss: 2.78e-01
 test time : 60.1 Train 0.0 Validation 0.2754767835140228 Test 0.2834184169769287
Epoch 64 train time : 363.8 loss: 2.78e-01
 test time : 59.8 Train 0.0 Validation 0.27198681235313416 Test 0.27795669436454773
Epoch 65 train time : 361.2 loss: 2.78e-01
 test time : 60.1 Train 0.0 Validation 0.26869893074035645 Test 0.27195513248443604
Epoch 66 train time : 362.8 loss: 2.77e-01
 test time : 59.9 Train 0.0 Validation 0.26944586634635925 Test 0.28000304102897644
Epoch 67 train time : 362.0 loss: 2.77e-01
 test time : 60.0 Train 0.0 Validation 0.2730553150177002 Test 0.27574679255485535
Epoch 68 train time : 361.8 loss: 2.76e-01
 test time : 59.9 Train 0.0 Validation 0.2929248809814453 Test 0.2983012795448303
Epoch 69 train time : 364.4 loss: 2.77e-01
 test time : 60.0 Train 0.0 Validation 0.2692197561264038 Test 0.27500683069229126
Epoch 70 train time : 362.7 loss: 2.77e-01
 test time : 60.0 Train 0.0 Validation 0.2759951949119568 Test 0.2841036915779114
Epoch 71 train time : 361.5 loss: 2.75e-01
 test time : 60.0 Train 0.0 Validation 0.2660202085971832 Test 0.27479949593544006
Epoch 72 train time : 365.4 loss: 2.75e-01
 test time : 60.0 Train 0.0 Validation 0.2687682509422302 Test 0.27404117584228516
Epoch 73 train time : 360.2 loss: 2.76e-01
 test time : 59.7 Train 0.0 Validation 0.26420095562934875 Test 0.2688223421573639
Epoch 74 train time : 361.1 loss: 2.76e-01
 test time : 59.8 Train 0.0 Validation 0.2666529715061188 Test 0.27142712473869324
Epoch 75 train time : 362.1 loss: 2.75e-01
 test time : 59.9 Train 0.0 Validation 0.2700217664241791 Test 0.2778099477291107
Epoch 76 train time : 362.4 loss: 2.75e-01
 test time : 59.9 Train 0.0 Validation 0.26584893465042114 Test 0.27168145775794983
Epoch 77 train time : 364.2 loss: 2.76e-01
 test time : 60.0 Train 0.0 Validation 0.28223177790641785 Test 0.2849962115287781
Epoch 78 train time : 362.1 loss: 2.75e-01
 test time : 59.9 Train 0.0 Validation 0.2673688530921936 Test 0.2765266001224518
Epoch 79 train time : 362.8 loss: 2.75e-01
 test time : 60.0 Train 0.0 Validation 0.2696175277233124 Test 0.2730088531970978
Epoch 80 train time : 362.8 loss: 2.74e-01
 test time : 59.9 Train 0.0 Validation 0.264847993850708 Test 0.2732676863670349
Best @72 validation score: 0.2642 Test score: 0.2688
[[72, tensor(0.2642), tensor(0.2688)]]
all runs:  72.0 0.26420095562934875 0.2688223421573639 0.0 0.0 0.0 
