Namespace(dataset='pepstruct', repeat=1, num_workers=0, amp=True, compile=True, batch_size=2, testbatch_size=2, epochs=40, wd=0, lr=0.0008, beta=0.98, minlr=0.0, K=0.0, gradclipnorm=1.0, decompnoise=1e-06, seedoffset=0, warmstart=40, conststep=0, cosstep=8, use_y_scale=False, dp=0.0, eldp=0.0, act='silu', lossparam=0.0, advloss=False, embdp=0.0, embbn=False, emborthoinit=False, degreeemb=False, embln=True, featdim=-1, hiddim=72, caldim=-1, normA=False, laplacian=True, sqrtlambda=True, elres=True, usesvmix=True, vmean=False, vnorm=False, elvmean=False, elvnorm=False, snorm=True, gsizenorm=1.9, l_encoder='deepset', l_layers=4, l_combine='mul', l_aggr='mean', l_res=True, l_mlptailact1=True, l_mlplayers1=2, l_mlpnorm1='ln', l_mlptailact2=False, l_mlplayers2=0, l_mlpnorm2='none', num_layers=8, sv_uselinv=True, sv_tailact=False, sv_res=True, sv_numlayer=1, sv_norm='none', el_uselinv=True, el_uselins=False, el_tailact=True, el_numlayer=2, el_norm='ln', el_uses=False, conv_uselinv=True, conv_tailact=False, conv_numlayer=1, conv_norm='none', predlin_numlayer=1, predlin_norm='none', lexp='mlp', lexp_layer=2, lexp_norm='ln', outln=False, pool='mean', Tm=1, save=None, load=None, use_pos=False, align_size=32)
fixed l1reg
10873 2331 2331
split 10873 2331 2331
num_task 11
PiOModel(
  (inputencoder): QInputEncoder(
    (xemb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0): Embedding(18, 72, padding_idx=0)
        (1): Embedding(4, 72, padding_idx=0)
        (2-3): 2 x Embedding(8, 72, padding_idx=0)
        (4): Embedding(6, 72, padding_idx=0)
        (5): Embedding(2, 72, padding_idx=0)
        (6): Embedding(7, 72, padding_idx=0)
        (7-8): 2 x Embedding(3, 72, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((72,), eps=1e-05, elementwise_affine=False)
      )
    )
    (edgeEmb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0-2): 3 x Embedding(5, 72, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((72,), eps=1e-05, elementwise_affine=False)
      )
    )
    (LambdaEmb): MLPEncoding(
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=1, out_features=144, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=144, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
    (distEmb): MLPEncoding(
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=1, out_features=144, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=144, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (LambdaEncoder): PermEquiLayer(
    (set2set): Sequential(
      (0): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (1): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (2): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (3): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (4): Identity()
    )
    (set2vec): Sequential(
      (0): MLP(
      (lin): Sequential(
        (0): NoneNorm()
      )
    )
    )
  )
  (elprojs): ModuleList(
    (0-7): 8 x sv2el(
      (linv1): Linear(in_features=72, out_features=72, bias=False)
      (linv2): Linear(in_features=72, out_features=72, bias=False)
      (lins1): Identity()
      (lins2): Identity()
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (svmixs): ModuleList(
    (0-7): 8 x svMix(
      (linv1): Linear(in_features=72, out_features=72, bias=False)
      (linv2): Linear(in_features=72, out_features=72, bias=False)
      (linv3): Identity()
      (lins1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
        )
      )
      (lins2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
        )
      )
      (lins3): Identity()
    )
  )
  (convs): ModuleList(
    (0-7): 8 x DirCFConv(
      (lins): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
        )
      )
      (linv): Linear(in_features=72, out_features=72, bias=False)
    )
  )
  (predlin): MLP(
    (lin): Sequential(
      (0): Linear(in_features=72, out_features=11, bias=True)
    )
  )
  (predln): Identity()
  (vln): Sequential(
    (0): Identity()
    (1): Identity()
  )
  (elvln): Sequential(
    (0): Identity()
    (1): Identity()
  )
  (sln): LayerNorm((72,), eps=1e-05, elementwise_affine=False)
)
numel 534755
Epoch 1 train time : 1648.9 loss: 5.56e-01
 test time : 644.4 Train 0.0 Validation 0.40373319387435913 Test 0.4213162064552307
GPU memory 8.86
Epoch 2 train time : 410.3 loss: 4.60e-01
 test time : 70.2 Train 0.0 Validation 0.5348725318908691 Test 0.5484289526939392
Epoch 3 train time : 475.6 loss: 4.52e-01
 test time : 84.8 Train 0.0 Validation 0.33686161041259766 Test 0.34456348419189453
Epoch 4 train time : 546.7 loss: 4.20e-01
 test time : 82.2 Train 0.0 Validation 0.39327722787857056 Test 0.4053051769733429
Epoch 5 train time : 408.4 loss: 3.77e-01
 test time : 51.9 Train 0.0 Validation 0.391529381275177 Test 0.39611002802848816
Epoch 6 train time : 393.7 loss: 3.43e-01
 test time : 51.4 Train 0.0 Validation 0.3631536662578583 Test 0.37017154693603516
Epoch 7 train time : 391.3 loss: 3.38e-01
 test time : 51.8 Train 0.0 Validation 0.3077446520328522 Test 0.31018105149269104
Epoch 8 train time : 388.9 loss: 3.32e-01
 test time : 51.5 Train 0.0 Validation 0.3102470338344574 Test 0.31665945053100586
Epoch 9 train time : 391.6 loss: 3.26e-01
 test time : 52.8 Train 0.0 Validation 0.30399906635284424 Test 0.31237882375717163
Epoch 10 train time : 391.6 loss: 3.22e-01
 test time : 52.8 Train 0.0 Validation 0.29792237281799316 Test 0.3048737645149231
Epoch 11 train time : 390.9 loss: 3.19e-01
 test time : 52.0 Train 0.0 Validation 0.32583826780319214 Test 0.3314817547798157
Epoch 12 train time : 478.4 loss: 3.16e-01
 test time : 71.3 Train 0.0 Validation 0.29660141468048096 Test 0.3039225935935974
Epoch 13 train time : 482.6 loss: 3.16e-01
 test time : 73.2 Train 0.0 Validation 0.290413498878479 Test 0.2968745231628418
Epoch 14 train time : 463.8 loss: 3.12e-01
 test time : 49.9 Train 0.0 Validation 0.2988993525505066 Test 0.30482402443885803
Epoch 15 train time : 377.3 loss: 3.11e-01
 test time : 50.2 Train 0.0 Validation 0.3097149729728699 Test 0.3179303705692291
Epoch 16 train time : 378.6 loss: 3.06e-01
 test time : 50.3 Train 0.0 Validation 0.293565571308136 Test 0.3018631041049957
Epoch 17 train time : 376.5 loss: 3.05e-01
 test time : 51.0 Train 0.0 Validation 0.2839348614215851 Test 0.28619807958602905
Epoch 18 train time : 377.7 loss: 3.05e-01
 test time : 50.2 Train 0.0 Validation 0.28981247544288635 Test 0.2922114133834839
Epoch 19 train time : 378.0 loss: 3.03e-01
 test time : 50.0 Train 0.0 Validation 0.2853512167930603 Test 0.29059898853302
Epoch 20 train time : 376.8 loss: 3.03e-01
 test time : 50.6 Train 0.0 Validation 0.3082523047924042 Test 0.31446701288223267
Epoch 21 train time : 382.7 loss: 3.02e-01
 test time : 63.7 Train 0.0 Validation 0.287934809923172 Test 0.29013895988464355
Epoch 22 train time : 470.5 loss: 2.99e-01
 test time : 61.7 Train 0.0 Validation 0.286501407623291 Test 0.2928950786590576
Epoch 23 train time : 499.1 loss: 2.99e-01
 test time : 73.8 Train 0.0 Validation 0.3037322759628296 Test 0.3105437755584717
Epoch 24 train time : 429.7 loss: 2.96e-01
 test time : 50.3 Train 0.0 Validation 0.2828103005886078 Test 0.2877174913883209
Epoch 25 train time : 377.9 loss: 2.96e-01
 test time : 50.5 Train 0.0 Validation 0.2855888903141022 Test 0.28979718685150146
Epoch 26 train time : 376.2 loss: 2.95e-01
 test time : 50.4 Train 0.0 Validation 0.2863510847091675 Test 0.29577329754829407
Epoch 27 train time : 377.3 loss: 2.93e-01
 test time : 50.2 Train 0.0 Validation 0.2770387530326843 Test 0.2823920249938965
Epoch 28 train time : 378.4 loss: 2.91e-01
 test time : 50.0 Train 0.0 Validation 0.28077855706214905 Test 0.28838911652565
Epoch 29 train time : 376.5 loss: 2.93e-01
 test time : 50.2 Train 0.0 Validation 0.2755475640296936 Test 0.28041189908981323
Epoch 30 train time : 377.6 loss: 2.91e-01
 test time : 50.4 Train 0.0 Validation 0.27532291412353516 Test 0.2820342183113098
Epoch 31 train time : 399.5 loss: 2.90e-01
 test time : 69.2 Train 0.0 Validation 0.28940337896347046 Test 0.2912816107273102
Epoch 32 train time : 451.1 loss: 2.89e-01
 test time : 73.7 Train 0.0 Validation 0.27435460686683655 Test 0.2799762487411499
Epoch 33 train time : 507.8 loss: 2.91e-01
 test time : 74.2 Train 0.0 Validation 0.27864137291908264 Test 0.2846337556838989
Epoch 34 train time : 402.4 loss: 2.89e-01
 test time : 50.5 Train 0.0 Validation 0.27578938007354736 Test 0.2829425632953644
Epoch 35 train time : 377.6 loss: 2.87e-01
 test time : 50.2 Train 0.0 Validation 0.2796739637851715 Test 0.2861039936542511
Epoch 36 train time : 376.4 loss: 2.88e-01
 test time : 50.7 Train 0.0 Validation 0.27580416202545166 Test 0.28500622510910034
Epoch 37 train time : 378.1 loss: 2.86e-01
 test time : 50.7 Train 0.0 Validation 0.2737460136413574 Test 0.28208211064338684
Epoch 38 train time : 377.9 loss: 2.87e-01
 test time : 49.9 Train 0.0 Validation 0.2772180736064911 Test 0.2829126715660095
Epoch 39 train time : 377.8 loss: 2.87e-01
 test time : 50.3 Train 0.0 Validation 0.2952089011669159 Test 0.30732420086860657
Epoch 40 train time : 376.0 loss: 2.85e-01
 test time : 50.5 Train 0.0 Validation 0.28817757964134216 Test 0.29574060440063477
Best @36 validation score: 0.2737 Test score: 0.2821
[[36, tensor(0.2737), tensor(0.2821)]]
all runs:  36.0 0.2737460136413574 0.28208211064338684 0.0 0.0 0.0 
