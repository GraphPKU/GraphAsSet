/ceph/home/muhan01/wangxiyuan/GraphAsSet/utils.py:20: UserWarning: not equivalent to Identity
  warnings.warn("not equivalent to Identity")
Namespace(dataset='pepstruct', repeat=1, num_workers=0, amp=True, compile=True, batch_size=6, testbatch_size=6, epochs=80, wd=0.01, lr=0.0003, beta=0.9, minlr=0.0, K=0.0, gradclipnorm=1.0, decompnoise=1e-06, seedoffset=0, warmstart=8, conststep=64, cosstep=8, use_y_scale=False, dp=0.0, eldp=0.0, act='silu', lossparam=0.0, advloss=False, embdp=0.0, embbn=False, emborthoinit=False, degreeemb=False, embln=True, featdim=-1, hiddim=88, caldim=-1, normA=False, laplacian=True, sqrtlambda=True, elres=True, usesvmix=True, vmean=True, vnorm=True, elvmean=True, elvnorm=True, snorm=True, gsizenorm=1.85, l_encoder='deepset', l_layers=3, l_combine='mul', l_aggr='mean', l_res=True, l_mlptailact1=True, l_mlplayers1=2, l_mlpnorm1='ln', l_mlptailact2=False, l_mlplayers2=0, l_mlpnorm2='none', num_layers=6, sv_uselinv=True, sv_tailact=True, sv_res=True, sv_numlayer=1, sv_norm='none', el_uselinv=True, el_uselins=False, el_tailact=True, el_numlayer=2, el_norm='none', el_uses=False, conv_uselinv=True, conv_tailact=True, conv_numlayer=1, conv_norm='none', predlin_numlayer=1, predlin_norm='none', lexp='mlp', lexp_layer=2, lexp_norm='ln', outln=False, pool='mean', Tm=1, save='pepstruct.wd1e-2', load=None, use_pos=False, align_size=32)
fixed l1reg
10873 2331 2331
split 10873 2331 2331
num_task 11
PiOModel(
  (inputencoder): QInputEncoder(
    (xemb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0): Embedding(18, 88, padding_idx=0)
        (1): Embedding(4, 88, padding_idx=0)
        (2-3): 2 x Embedding(8, 88, padding_idx=0)
        (4): Embedding(6, 88, padding_idx=0)
        (5): Embedding(2, 88, padding_idx=0)
        (6): Embedding(7, 88, padding_idx=0)
        (7-8): 2 x Embedding(3, 88, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
      )
    )
    (edgeEmb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0-2): 3 x Embedding(5, 88, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
      )
    )
    (LambdaEmb): MLPEncoding(
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=1, out_features=176, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((176,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=176, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (LambdaEncoder): PermEquiLayer(
    (set2set): Sequential(
      (0): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (1): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (2): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (3): Identity()
    )
    (set2vec): Sequential(
      (0): MLP(
      (lin): Sequential(
        (0): NoneNorm()
      )
    )
    )
  )
  (elprojs): ModuleList(
    (0-5): 6 x sv2el(
      (linv1): Linear(in_features=88, out_features=88, bias=False)
      (linv2): Linear(in_features=88, out_features=88, bias=False)
      (lins1): Identity()
      (lins2): Identity()
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): NoneNorm()
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (svmixs): ModuleList(
    (0-5): 6 x svMix(
      (linv1): Linear(in_features=88, out_features=88, bias=False)
      (linv2): Linear(in_features=88, out_features=88, bias=False)
      (linv3): Identity()
      (lins1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins3): Identity()
    )
  )
  (convs): ModuleList(
    (0-5): 6 x DirCFConv(
      (lins): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (linv): Linear(in_features=88, out_features=88, bias=False)
    )
  )
  (predlin): MLP(
    (lin): Sequential(
      (0): Linear(in_features=88, out_features=11, bias=True)
    )
  )
  (predln): Identity()
  (vln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (elvln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (sln): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
)
numel 587323
Epoch 1 train time : 970.8 loss: 5.37e-01
 test time : 410.5 Train 0.0 Validation 0.35141223669052124 Test 0.36150506138801575
GPU memory 19.32
Epoch 2 train time : 364.5 loss: 3.58e-01
 test time : 62.9 Train 0.0 Validation 0.3154461681842804 Test 0.3222518265247345
Epoch 3 train time : 365.4 loss: 3.38e-01
 test time : 63.0 Train 0.0 Validation 0.2976709306240082 Test 0.3056185245513916
Epoch 4 train time : 361.4 loss: 3.25e-01
 test time : 63.0 Train 0.0 Validation 0.31798139214515686 Test 0.32296350598335266
Epoch 5 train time : 363.9 loss: 3.21e-01
 test time : 62.9 Train 0.0 Validation 0.29715120792388916 Test 0.30546799302101135
Epoch 6 train time : 469.3 loss: 3.16e-01
 test time : 62.9 Train 0.0 Validation 0.30100977420806885 Test 0.30789169669151306
Epoch 7 train time : 366.5 loss: 3.16e-01
 test time : 62.9 Train 0.0 Validation 0.305103063583374 Test 0.31471940875053406
Epoch 8 train time : 366.4 loss: 3.13e-01
 test time : 62.9 Train 0.0 Validation 0.29522937536239624 Test 0.3021344840526581
Epoch 9 train time : 367.3 loss: 3.09e-01
 test time : 62.9 Train 0.0 Validation 0.28832295536994934 Test 0.29232409596443176
Epoch 10 train time : 365.1 loss: 3.06e-01
 test time : 62.9 Train 0.0 Validation 0.28690794110298157 Test 0.2936243414878845
Epoch 11 train time : 366.3 loss: 3.02e-01
 test time : 63.0 Train 0.0 Validation 0.2815043330192566 Test 0.28583529591560364
Epoch 12 train time : 365.7 loss: 2.97e-01
 test time : 63.0 Train 0.0 Validation 0.2777913808822632 Test 0.2811111807823181
Epoch 13 train time : 365.9 loss: 2.96e-01
 test time : 63.0 Train 0.0 Validation 0.28074759244918823 Test 0.28871458768844604
Epoch 14 train time : 363.7 loss: 2.93e-01
 test time : 62.9 Train 0.0 Validation 0.30504024028778076 Test 0.3123963177204132
Epoch 15 train time : 366.2 loss: 2.89e-01
 test time : 63.0 Train 0.0 Validation 0.27779754996299744 Test 0.2809525728225708
Epoch 16 train time : 365.1 loss: 2.86e-01
 test time : 62.9 Train 0.0 Validation 0.2968519628047943 Test 0.2994651794433594
Epoch 17 train time : 365.7 loss: 2.87e-01
 test time : 63.0 Train 0.0 Validation 0.27273133397102356 Test 0.27579477429389954
Epoch 18 train time : 367.8 loss: 2.85e-01
 test time : 62.9 Train 0.0 Validation 0.2774488627910614 Test 0.2791141867637634
Epoch 19 train time : 368.6 loss: 2.85e-01
 test time : 62.9 Train 0.0 Validation 0.2743898332118988 Test 0.2764868438243866
Epoch 20 train time : 363.8 loss: 2.83e-01
 test time : 62.9 Train 0.0 Validation 0.3035303056240082 Test 0.3079192340373993
Epoch 21 train time : 365.0 loss: 2.82e-01
 test time : 63.0 Train 0.0 Validation 0.2688978910446167 Test 0.2714923918247223
Epoch 22 train time : 366.2 loss: 2.80e-01
 test time : 62.9 Train 0.0 Validation 0.26859110593795776 Test 0.27568069100379944
Epoch 23 train time : 363.9 loss: 2.79e-01
 test time : 62.9 Train 0.0 Validation 0.26915663480758667 Test 0.2741045355796814
Epoch 24 train time : 364.3 loss: 2.78e-01
 test time : 62.9 Train 0.0 Validation 0.2650332450866699 Test 0.26858267188072205
Epoch 25 train time : 366.0 loss: 2.77e-01
 test time : 62.9 Train 0.0 Validation 0.27311113476753235 Test 0.27677464485168457
Epoch 26 train time : 365.7 loss: 2.76e-01
 test time : 62.9 Train 0.0 Validation 0.26747915148735046 Test 0.273738294839859
Epoch 27 train time : 365.6 loss: 2.75e-01
 test time : 62.9 Train 0.0 Validation 0.26741379499435425 Test 0.27176690101623535
Epoch 28 train time : 367.1 loss: 2.75e-01
 test time : 63.0 Train 0.0 Validation 0.2672017514705658 Test 0.27177920937538147
Epoch 29 train time : 365.3 loss: 2.75e-01
 test time : 62.9 Train 0.0 Validation 0.2716292142868042 Test 0.27245113253593445
Epoch 30 train time : 363.4 loss: 2.75e-01
 test time : 63.0 Train 0.0 Validation 0.272563636302948 Test 0.27530530095100403
Epoch 31 train time : 365.6 loss: 2.73e-01
 test time : 62.9 Train 0.0 Validation 0.2709885835647583 Test 0.2750832140445709
Epoch 32 train time : 365.0 loss: 2.72e-01
 test time : 62.9 Train 0.0 Validation 0.2615467309951782 Test 0.2665345072746277
Epoch 33 train time : 365.7 loss: 2.70e-01
 test time : 62.9 Train 0.0 Validation 0.26628822088241577 Test 0.27060753107070923
Epoch 34 train time : 366.2 loss: 2.70e-01
 test time : 62.9 Train 0.0 Validation 0.2693796157836914 Test 0.27447497844696045
Epoch 35 train time : 364.8 loss: 2.69e-01
 test time : 62.9 Train 0.0 Validation 0.2786315083503723 Test 0.281108021736145
Epoch 36 train time : 365.8 loss: 2.68e-01
 test time : 62.8 Train 0.0 Validation 0.2641806900501251 Test 0.26937055587768555
Epoch 37 train time : 364.2 loss: 2.67e-01
 test time : 62.8 Train 0.0 Validation 0.2600153386592865 Test 0.26243507862091064
Epoch 38 train time : 366.3 loss: 2.66e-01
 test time : 62.9 Train 0.0 Validation 0.26047682762145996 Test 0.267831027507782
Epoch 39 train time : 364.9 loss: 2.67e-01
 test time : 62.9 Train 0.0 Validation 0.29665544629096985 Test 0.3052554130554199
Epoch 40 train time : 364.8 loss: 2.67e-01
 test time : 62.9 Train 0.0 Validation 0.26114439964294434 Test 0.268030047416687
Epoch 41 train time : 364.9 loss: 2.65e-01
 test time : 62.9 Train 0.0 Validation 0.27176448702812195 Test 0.278839111328125
Epoch 42 train time : 366.2 loss: 2.64e-01
 test time : 62.9 Train 0.0 Validation 0.26384490728378296 Test 0.26923441886901855
Epoch 43 train time : 366.0 loss: 2.64e-01
 test time : 62.9 Train 0.0 Validation 0.26375627517700195 Test 0.26426154375076294
Epoch 44 train time : 362.3 loss: 2.64e-01
 test time : 63.0 Train 0.0 Validation 0.2600465714931488 Test 0.26447445154190063
Epoch 45 train time : 365.3 loss: 2.64e-01
 test time : 62.9 Train 0.0 Validation 0.26202043890953064 Test 0.2652806341648102
Epoch 46 train time : 365.7 loss: 2.61e-01
 test time : 63.0 Train 0.0 Validation 0.2644885778427124 Test 0.27081793546676636
Epoch 47 train time : 368.6 loss: 2.62e-01
 test time : 62.9 Train 0.0 Validation 0.26453712582588196 Test 0.26900583505630493
Epoch 48 train time : 363.5 loss: 2.62e-01
 test time : 62.9 Train 0.0 Validation 0.2631939947605133 Test 0.264326810836792
Epoch 49 train time : 365.7 loss: 2.61e-01
 test time : 62.8 Train 0.0 Validation 0.2600957453250885 Test 0.26420751214027405
Epoch 50 train time : 364.0 loss: 2.60e-01
 test time : 62.9 Train 0.0 Validation 0.258033812046051 Test 0.2650923430919647
Epoch 51 train time : 365.7 loss: 2.60e-01
 test time : 62.9 Train 0.0 Validation 0.2678177058696747 Test 0.2701610028743744
Epoch 52 train time : 363.7 loss: 2.59e-01
 test time : 62.9 Train 0.0 Validation 0.2588873505592346 Test 0.26636090874671936
Epoch 53 train time : 364.8 loss: 2.57e-01
 test time : 62.9 Train 0.0 Validation 0.2889776825904846 Test 0.2936233580112457
Epoch 54 train time : 366.3 loss: 2.57e-01
 test time : 62.9 Train 0.0 Validation 0.25821545720100403 Test 0.26346176862716675
Epoch 55 train time : 365.3 loss: 2.56e-01
 test time : 62.9 Train 0.0 Validation 0.2601475715637207 Test 0.26852622628211975
Epoch 56 train time : 363.4 loss: 2.56e-01
 test time : 62.9 Train 0.0 Validation 0.26133671402931213 Test 0.26685723662376404
Epoch 57 train time : 364.9 loss: 2.56e-01
 test time : 62.9 Train 0.0 Validation 0.2639095187187195 Test 0.2721787989139557
Epoch 58 train time : 368.3 loss: 2.54e-01
 test time : 62.9 Train 0.0 Validation 0.27773916721343994 Test 0.2830227017402649
Epoch 59 train time : 366.3 loss: 2.55e-01
 test time : 62.9 Train 0.0 Validation 0.26294443011283875 Test 0.26429125666618347
Epoch 60 train time : 367.5 loss: 2.54e-01
 test time : 62.9 Train 0.0 Validation 0.256208211183548 Test 0.26309844851493835
Epoch 61 train time : 364.6 loss: 2.53e-01
 test time : 63.0 Train 0.0 Validation 0.2636529505252838 Test 0.2665916681289673
Epoch 62 train time : 361.9 loss: 2.52e-01
 test time : 62.9 Train 0.0 Validation 0.25780871510505676 Test 0.2665800154209137
Epoch 63 train time : 364.1 loss: 2.52e-01
 test time : 62.9 Train 0.0 Validation 0.2631951570510864 Test 0.2628863751888275
Epoch 64 train time : 364.2 loss: 2.51e-01
 test time : 62.9 Train 0.0 Validation 0.2612490653991699 Test 0.26254183053970337
Epoch 65 train time : 362.2 loss: 2.51e-01
 test time : 62.9 Train 0.0 Validation 0.25765669345855713 Test 0.26553547382354736
Epoch 66 train time : 366.9 loss: 2.50e-01
 test time : 62.9 Train 0.0 Validation 0.26436248421669006 Test 0.26689183712005615
Epoch 67 train time : 364.6 loss: 2.49e-01
 test time : 62.9 Train 0.0 Validation 0.258510947227478 Test 0.26483970880508423
Epoch 68 train time : 364.9 loss: 2.47e-01
 test time : 62.9 Train 0.0 Validation 0.26161012053489685 Test 0.26627179980278015
Epoch 69 train time : 366.6 loss: 2.47e-01
 test time : 62.9 Train 0.0 Validation 0.2586944103240967 Test 0.2616995573043823
Epoch 70 train time : 363.9 loss: 2.46e-01
 test time : 62.9 Train 0.0 Validation 0.2595318853855133 Test 0.26620230078697205
Epoch 71 train time : 364.6 loss: 2.46e-01
 test time : 62.9 Train 0.0 Validation 0.2585628628730774 Test 0.26588112115859985
Epoch 72 train time : 365.3 loss: 2.46e-01
 test time : 62.9 Train 0.0 Validation 0.2672722637653351 Test 0.2701144218444824
Epoch 73 train time : 365.0 loss: 2.44e-01
 test time : 62.9 Train 0.0 Validation 0.2598317861557007 Test 0.26577165722846985
Epoch 74 train time : 361.8 loss: 2.43e-01
 test time : 62.8 Train 0.0 Validation 0.2726976275444031 Test 0.2776990532875061
Epoch 75 train time : 363.0 loss: 2.40e-01
 test time : 62.9 Train 0.0 Validation 0.25621798634529114 Test 0.2613968551158905
Epoch 76 train time : 365.9 loss: 2.35e-01
 test time : 62.8 Train 0.0 Validation 0.26178351044654846 Test 0.2608090341091156
Epoch 77 train time : 362.1 loss: 2.29e-01
 test time : 62.9 Train 0.0 Validation 0.2532697319984436 Test 0.25570785999298096
Epoch 78 train time : 367.0 loss: 2.24e-01
 test time : 62.8 Train 0.0 Validation 0.2541428506374359 Test 0.2539713680744171
Epoch 79 train time : 363.6 loss: 2.19e-01
 test time : 62.9 Train 0.0 Validation 0.2541741132736206 Test 0.25606492161750793
Epoch 80 train time : 363.4 loss: 2.16e-01
 test time : 62.8 Train 0.0 Validation 0.25458917021751404 Test 0.2556164860725403
Best @76 validation score: 0.2533 Test score: 0.2557
[[76, tensor(0.2533), tensor(0.2557)]]
all runs:  76.0 0.2532697319984436 0.25570785999298096 0.0 0.0 0.0 
