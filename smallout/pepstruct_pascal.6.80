Namespace(dataset='pepstruct', repeat=1, num_workers=0, amp=True, compile=True, batch_size=6, testbatch_size=6, epochs=80, wd=0.1, lr=0.001, beta=0.9, minlr=0.0, K=0.0, gradclipnorm=1.0, decompnoise=1e-06, seedoffset=0, warmstart=8, conststep=56, cosstep=8, use_y_scale=False, dp=0.0, eldp=0.0, act='silu', lossparam=0.0, advloss=False, embdp=0.0, embbn=False, emborthoinit=False, degreeemb=False, embln=True, featdim=-1, hiddim=80, caldim=-1, normA=False, laplacian=True, sqrtlambda=True, elres=True, usesvmix=True, vmean=True, vnorm=True, elvmean=True, elvnorm=True, snorm=True, gsizenorm=1.85, l_encoder='deepset', l_layers=3, l_combine='mul', l_aggr='mean', l_res=True, l_mlptailact1=True, l_mlplayers1=2, l_mlpnorm1='ln', l_mlptailact2=False, l_mlplayers2=0, l_mlpnorm2='none', num_layers=6, sv_uselinv=True, sv_tailact=True, sv_res=True, sv_numlayer=1, sv_norm='none', el_uselinv=True, el_uselins=False, el_tailact=True, el_numlayer=2, el_norm='none', el_uses=False, conv_uselinv=True, conv_tailact=True, conv_numlayer=1, conv_norm='none', predlin_numlayer=1, predlin_norm='none', lexp='mlp', lexp_layer=2, lexp_norm='ln', outln=False, pool='mean', Tm=1, save=None, load=None, use_pos=False, align_size=32)
fixed l1reg
10873 2331 2331
split 10873 2331 2331
num_task 11
PiOModel(
  (inputencoder): QInputEncoder(
    (xemb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0): Embedding(18, 80, padding_idx=0)
        (1): Embedding(4, 80, padding_idx=0)
        (2-3): 2 x Embedding(8, 80, padding_idx=0)
        (4): Embedding(6, 80, padding_idx=0)
        (5): Embedding(2, 80, padding_idx=0)
        (6): Embedding(7, 80, padding_idx=0)
        (7-8): 2 x Embedding(3, 80, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((80,), eps=1e-05, elementwise_affine=False)
      )
    )
    (edgeEmb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0-2): 3 x Embedding(5, 80, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((80,), eps=1e-05, elementwise_affine=False)
      )
    )
    (LambdaEmb): MLPEncoding(
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=1, out_features=160, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=160, out_features=80, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
    (distEmb): MLPEncoding(
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=1, out_features=160, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=160, out_features=80, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (LambdaEncoder): PermEquiLayer(
    (set2set): Sequential(
      (0): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=80, out_features=80, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=80, out_features=80, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=80, out_features=80, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=80, out_features=80, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (1): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=80, out_features=80, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=80, out_features=80, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=80, out_features=80, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=80, out_features=80, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (2): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=80, out_features=80, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=80, out_features=80, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=80, out_features=80, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=80, out_features=80, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((80,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (3): Identity()
    )
    (set2vec): Sequential(
      (0): MLP(
      (lin): Sequential(
        (0): NoneNorm()
      )
    )
    )
  )
  (elprojs): ModuleList(
    (0-5): 6 x sv2el(
      (linv1): Linear(in_features=80, out_features=80, bias=False)
      (linv2): Linear(in_features=80, out_features=80, bias=False)
      (lins1): Identity()
      (lins2): Identity()
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=80, out_features=80, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
          (3): Linear(in_features=80, out_features=80, bias=True)
          (4): NoneNorm()
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (svmixs): ModuleList(
    (0-5): 6 x svMix(
      (linv1): Linear(in_features=80, out_features=80, bias=False)
      (linv2): Linear(in_features=80, out_features=80, bias=False)
      (linv3): Identity()
      (lins1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=80, out_features=80, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=80, out_features=80, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins3): Identity()
    )
  )
  (convs): ModuleList(
    (0-5): 6 x DirCFConv(
      (lins): MLP(
        (lin): Sequential(
          (0): Linear(in_features=80, out_features=80, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (linv): Linear(in_features=80, out_features=80, bias=False)
    )
  )
  (predlin): MLP(
    (lin): Sequential(
      (0): Linear(in_features=80, out_features=11, bias=True)
    )
  )
  (predln): Identity()
  (vln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (elvln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (sln): LayerNorm((80,), eps=1e-05, elementwise_affine=False)
)
numel 500251
Epoch 1 train time : 865.1 loss: 4.66e-01
 test time : 472.8 Train 0.0 Validation 0.33683058619499207 Test 0.3453155755996704
GPU memory 17.55
Epoch 2 train time : 351.0 loss: 3.45e-01
 test time : 59.7 Train 0.0 Validation 0.3174562156200409 Test 0.3241179287433624
Epoch 3 train time : 353.2 loss: 3.33e-01
 test time : 60.0 Train 0.0 Validation 0.3065917193889618 Test 0.3109803795814514
Epoch 4 train time : 352.8 loss: 3.28e-01
 test time : 60.2 Train 0.0 Validation 0.3164331912994385 Test 0.3257598280906677
Epoch 5 train time : 355.2 loss: 3.22e-01
 test time : 60.0 Train 0.0 Validation 0.30903157591819763 Test 0.3144499361515045
Epoch 6 train time : 352.4 loss: 3.20e-01
 test time : 59.9 Train 0.0 Validation 0.2949564754962921 Test 0.3039620816707611
Epoch 7 train time : 355.1 loss: 3.16e-01
 test time : 60.2 Train 0.0 Validation 0.29807981848716736 Test 0.3057592511177063
Epoch 8 train time : 353.8 loss: 3.13e-01
 test time : 60.0 Train 0.0 Validation 0.28266361355781555 Test 0.2872484028339386
Epoch 9 train time : 354.6 loss: 3.11e-01
 test time : 59.7 Train 0.0 Validation 0.33676639199256897 Test 0.3443141281604767
Epoch 10 train time : 354.1 loss: 3.06e-01
 test time : 59.5 Train 0.0 Validation 0.3089255094528198 Test 0.3126446604728699
Epoch 11 train time : 352.7 loss: 3.05e-01
 test time : 59.8 Train 0.0 Validation 0.2948664724826813 Test 0.296607106924057
Epoch 12 train time : 355.2 loss: 3.03e-01
 test time : 59.6 Train 0.0 Validation 0.28428366780281067 Test 0.2885744571685791
Epoch 13 train time : 354.5 loss: 3.03e-01
 test time : 59.5 Train 0.0 Validation 0.2808680236339569 Test 0.285565584897995
Epoch 14 train time : 463.0 loss: 3.02e-01
 test time : 60.2 Train 0.0 Validation 0.32589560747146606 Test 0.330114483833313
Epoch 15 train time : 354.6 loss: 3.01e-01
 test time : 59.6 Train 0.0 Validation 0.2971378266811371 Test 0.3044726252555847
Epoch 16 train time : 355.2 loss: 3.00e-01
 test time : 59.7 Train 0.0 Validation 0.31718018651008606 Test 0.32297495007514954
Epoch 17 train time : 353.5 loss: 3.00e-01
 test time : 60.1 Train 0.0 Validation 0.2848517596721649 Test 0.28934308886528015
Epoch 18 train time : 352.0 loss: 3.01e-01
 test time : 60.3 Train 0.0 Validation 0.30174535512924194 Test 0.30996328592300415
Epoch 19 train time : 353.5 loss: 3.00e-01
 test time : 60.0 Train 0.0 Validation 0.27945148944854736 Test 0.28312236070632935
Epoch 20 train time : 351.8 loss: 3.00e-01
 test time : 60.1 Train 0.0 Validation 0.2890315353870392 Test 0.29317328333854675
Epoch 21 train time : 355.2 loss: 2.99e-01
 test time : 60.1 Train 0.0 Validation 0.2830330431461334 Test 0.2886429727077484
Epoch 22 train time : 354.6 loss: 2.98e-01
 test time : 60.1 Train 0.0 Validation 0.2871650457382202 Test 0.2928462028503418
Epoch 23 train time : 354.2 loss: 2.98e-01
 test time : 60.0 Train 0.0 Validation 0.3005845844745636 Test 0.30439943075180054
Epoch 24 train time : 352.4 loss: 2.98e-01
 test time : 59.8 Train 0.0 Validation 0.33506956696510315 Test 0.33709508180618286
Epoch 25 train time : 350.5 loss: 2.99e-01
 test time : 59.5 Train 0.0 Validation 0.2828647792339325 Test 0.28689709305763245
Epoch 26 train time : 351.2 loss: 3.00e-01
 test time : 59.7 Train 0.0 Validation 0.2777022123336792 Test 0.2848249673843384
Epoch 27 train time : 354.7 loss: 3.00e-01
 test time : 59.5 Train 0.0 Validation 0.29141050577163696 Test 0.2950799763202667
Epoch 28 train time : 355.0 loss: 2.98e-01
 test time : 60.1 Train 0.0 Validation 0.27780967950820923 Test 0.28277572989463806
Epoch 29 train time : 353.9 loss: 2.95e-01
 test time : 59.7 Train 0.0 Validation 0.2824551463127136 Test 0.2846810817718506
Epoch 30 train time : 351.6 loss: 2.96e-01
 test time : 60.1 Train 0.0 Validation 0.2849107086658478 Test 0.29053300619125366
Epoch 31 train time : 353.5 loss: 2.96e-01
 test time : 60.0 Train 0.0 Validation 0.301025927066803 Test 0.3072074353694916
Epoch 32 train time : 351.4 loss: 2.96e-01
 test time : 60.0 Train 0.0 Validation 0.27291789650917053 Test 0.2779974341392517
Epoch 33 train time : 353.7 loss: 2.96e-01
 test time : 59.9 Train 0.0 Validation 0.34421852231025696 Test 0.3499465882778168
Epoch 34 train time : 353.8 loss: 2.95e-01
 test time : 59.8 Train 0.0 Validation 0.3000900149345398 Test 0.3068004846572876
Epoch 35 train time : 352.3 loss: 2.96e-01
 test time : 60.1 Train 0.0 Validation 0.27711763978004456 Test 0.28255707025527954
Epoch 36 train time : 350.9 loss: 2.95e-01
 test time : 59.9 Train 0.0 Validation 0.28566664457321167 Test 0.29152369499206543
Epoch 37 train time : 349.8 loss: 2.95e-01
 test time : 59.9 Train 0.0 Validation 0.2783430218696594 Test 0.2825887203216553
Epoch 38 train time : 351.2 loss: 2.96e-01
 test time : 59.9 Train 0.0 Validation 0.2922104299068451 Test 0.29654523730278015
Epoch 39 train time : 353.1 loss: 2.94e-01
 test time : 60.1 Train 0.0 Validation 0.2849806845188141 Test 0.2898890972137451
Epoch 40 train time : 350.4 loss: 2.95e-01
 test time : 59.8 Train 0.0 Validation 0.2874625027179718 Test 0.2940804660320282
Epoch 41 train time : 351.8 loss: 2.97e-01
 test time : 60.1 Train 0.0 Validation 0.3029145300388336 Test 0.31060534715652466
Epoch 42 train time : 352.2 loss: 2.95e-01
 test time : 59.9 Train 0.0 Validation 0.27912604808807373 Test 0.28562018275260925
Epoch 43 train time : 351.9 loss: 2.95e-01
 test time : 59.8 Train 0.0 Validation 0.3142293691635132 Test 0.32006940245628357
Epoch 44 train time : 352.5 loss: 2.93e-01
 test time : 59.8 Train 0.0 Validation 0.28399333357810974 Test 0.29120370745658875
Epoch 45 train time : 354.0 loss: 2.94e-01
 test time : 59.9 Train 0.0 Validation 0.3017003834247589 Test 0.30843648314476013
Epoch 46 train time : 354.1 loss: 2.91e-01
 test time : 59.8 Train 0.0 Validation 0.2843044102191925 Test 0.29051652550697327
Epoch 47 train time : 350.3 loss: 2.91e-01
 test time : 59.8 Train 0.0 Validation 0.30440792441368103 Test 0.31309276819229126
Epoch 48 train time : 354.8 loss: 2.93e-01
 test time : 60.0 Train 0.0 Validation 0.3347744345664978 Test 0.34443143010139465
Epoch 49 train time : 351.9 loss: 2.93e-01
 test time : 59.5 Train 0.0 Validation 0.2826361656188965 Test 0.28701886534690857
Epoch 50 train time : 349.7 loss: 2.93e-01
 test time : 59.5 Train 0.0 Validation 0.2921674847602844 Test 0.2958866059780121
Epoch 51 train time : 345.8 loss: 2.91e-01
 test time : 59.2 Train 0.0 Validation 0.28122347593307495 Test 0.2875153422355652
Epoch 52 train time : 347.8 loss: 2.91e-01
 test time : 59.1 Train 0.0 Validation 0.28654396533966064 Test 0.2919982373714447
Epoch 53 train time : 344.7 loss: 2.90e-01
 test time : 59.2 Train 0.0 Validation 0.28621068596839905 Test 0.28770798444747925
Epoch 54 train time : 348.6 loss: 2.91e-01
 test time : 59.0 Train 0.0 Validation 0.2787681519985199 Test 0.2829068899154663
Epoch 55 train time : 344.4 loss: 2.91e-01
 test time : 58.8 Train 0.0 Validation 0.2853579819202423 Test 0.28830787539482117
Epoch 56 train time : 346.5 loss: 2.92e-01
 test time : 59.2 Train 0.0 Validation 0.2824748158454895 Test 0.289068341255188
Epoch 57 train time : 347.6 loss: 2.89e-01
 test time : 58.8 Train 0.0 Validation 0.2846023738384247 Test 0.284654438495636
Epoch 58 train time : 343.4 loss: 2.89e-01
 test time : 58.9 Train 0.0 Validation 0.2734181880950928 Test 0.2760150134563446
Epoch 59 train time : 348.8 loss: 2.90e-01
 test time : 59.0 Train 0.0 Validation 0.27795901894569397 Test 0.2831289768218994
Epoch 60 train time : 348.3 loss: 2.90e-01
 test time : 58.9 Train 0.0 Validation 0.29190897941589355 Test 0.30466967821121216
Epoch 61 train time : 346.8 loss: 2.91e-01
 test time : 59.0 Train 0.0 Validation 0.2688131332397461 Test 0.27393853664398193
Epoch 62 train time : 349.8 loss: 2.88e-01
 test time : 59.0 Train 0.0 Validation 0.2740688621997833 Test 0.2826841175556183
Epoch 63 train time : 346.8 loss: 2.88e-01
 test time : 59.1 Train 0.0 Validation 0.2832354009151459 Test 0.2877877354621887
Epoch 64 train time : 345.0 loss: 2.90e-01
 test time : 59.0 Train 0.0 Validation 0.27630797028541565 Test 0.28021547198295593
Epoch 65 train time : 349.8 loss: 2.88e-01
 test time : 59.1 Train 0.0 Validation 0.3160287141799927 Test 0.31799569725990295
Epoch 66 train time : 349.1 loss: 2.87e-01
 test time : 59.0 Train 0.0 Validation 0.27993831038475037 Test 0.2862858474254608
Epoch 67 train time : 346.7 loss: 2.84e-01
 test time : 59.0 Train 0.0 Validation 0.2826884984970093 Test 0.28780150413513184
Epoch 68 train time : 348.2 loss: 2.78e-01
 test time : 59.1 Train 0.0 Validation 0.2653486728668213 Test 0.2659149765968323
Epoch 69 train time : 347.2 loss: 2.72e-01
 test time : 58.9 Train 0.0 Validation 0.2640842795372009 Test 0.26803335547447205
Epoch 70 train time : 347.9 loss: 2.67e-01
 test time : 59.1 Train 0.0 Validation 0.26762324571609497 Test 0.2705037295818329
Epoch 71 train time : 348.0 loss: 2.61e-01
 test time : 59.1 Train 0.0 Validation 0.25735384225845337 Test 0.25868505239486694
Epoch 72 train time : 348.4 loss: 2.58e-01
 test time : 59.1 Train 0.0 Validation 0.2583855390548706 Test 0.26108318567276
Epoch 73 train time : 344.6 loss: 2.92e-01
 test time : 59.0 Train 0.0 Validation 0.28042173385620117 Test 0.28061309456825256
Epoch 74 train time : 346.0 loss: 2.88e-01
 test time : 59.2 Train 0.0 Validation 0.2775850296020508 Test 0.2840902507305145
Epoch 75 train time : 343.7 loss: 2.85e-01
 test time : 59.1 Train 0.0 Validation 0.2689717411994934 Test 0.27174490690231323
Epoch 76 train time : 347.8 loss: 2.79e-01
 test time : 58.8 Train 0.0 Validation 0.26976272463798523 Test 0.27499714493751526
Epoch 77 train time : 346.7 loss: 2.72e-01
 test time : 59.0 Train 0.0 Validation 0.2668786644935608 Test 0.27085423469543457
Epoch 78 train time : 344.8 loss: 2.66e-01
 test time : 59.0 Train 0.0 Validation 0.26276856660842896 Test 0.2645278573036194
Epoch 79 train time : 345.3 loss: 2.60e-01
 test time : 59.1 Train 0.0 Validation 0.25703898072242737 Test 0.2605280578136444
Epoch 80 train time : 346.8 loss: 2.56e-01
 test time : 58.8 Train 0.0 Validation 0.2557702362537384 Test 0.2584609091281891
Best @79 validation score: 0.2558 Test score: 0.2585
[[79, tensor(0.2558), tensor(0.2585)]]
all runs:  79.0 0.2557702362537384 0.2584609091281891 0.0 0.0 0.0 
