/ceph/home/muhan01/wangxiyuan/GraphAsSet/utils.py:20: UserWarning: not equivalent to Identity
  warnings.warn("not equivalent to Identity")
Namespace(dataset='pepstruct', repeat=1, num_workers=0, amp=True, compile=True, batch_size=6, testbatch_size=6, epochs=80, wd=0.1, lr=0.0003, beta=0.9, minlr=0.0, K=0.0, gradclipnorm=1.0, decompnoise=1e-06, seedoffset=0, warmstart=8, conststep=64, cosstep=8, use_y_scale=False, dp=0.0, eldp=0.0, act='silu', lossparam=0.0, advloss=False, embdp=0.0, embbn=False, emborthoinit=False, degreeemb=False, embln=True, featdim=-1, hiddim=88, caldim=-1, normA=False, laplacian=True, sqrtlambda=True, elres=True, usesvmix=True, vmean=True, vnorm=False, elvmean=True, elvnorm=True, snorm=True, gsizenorm=1.85, l_encoder='deepset', l_layers=3, l_combine='mul', l_aggr='mean', l_res=True, l_mlptailact1=True, l_mlplayers1=2, l_mlpnorm1='ln', l_mlptailact2=False, l_mlplayers2=0, l_mlpnorm2='none', num_layers=6, sv_uselinv=True, sv_tailact=True, sv_res=True, sv_numlayer=1, sv_norm='none', el_uselinv=True, el_uselins=False, el_tailact=True, el_numlayer=2, el_norm='none', el_uses=False, conv_uselinv=True, conv_tailact=True, conv_numlayer=1, conv_norm='none', predlin_numlayer=1, predlin_norm='none', lexp='mlp', lexp_layer=2, lexp_norm='ln', outln=False, pool='mean', Tm=1, save='pepstruct.novnorm.wd1e-1', load=None, use_pos=False, align_size=32)
fixed l1reg
10873 2331 2331
split 10873 2331 2331
num_task 11
PiOModel(
  (inputencoder): QInputEncoder(
    (xemb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0): Embedding(18, 88, padding_idx=0)
        (1): Embedding(4, 88, padding_idx=0)
        (2-3): 2 x Embedding(8, 88, padding_idx=0)
        (4): Embedding(6, 88, padding_idx=0)
        (5): Embedding(2, 88, padding_idx=0)
        (6): Embedding(7, 88, padding_idx=0)
        (7-8): 2 x Embedding(3, 88, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
      )
    )
    (edgeEmb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0-2): 3 x Embedding(5, 88, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
      )
    )
    (LambdaEmb): MLPEncoding(
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=1, out_features=176, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((176,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=176, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (LambdaEncoder): PermEquiLayer(
    (set2set): Sequential(
      (0): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (1): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (2): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (3): Identity()
    )
    (set2vec): Sequential(
      (0): MLP(
      (lin): Sequential(
        (0): NoneNorm()
      )
    )
    )
  )
  (elprojs): ModuleList(
    (0-5): 6 x sv2el(
      (linv1): Linear(in_features=88, out_features=88, bias=False)
      (linv2): Linear(in_features=88, out_features=88, bias=False)
      (lins1): Identity()
      (lins2): Identity()
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): NoneNorm()
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (svmixs): ModuleList(
    (0-5): 6 x svMix(
      (linv1): Linear(in_features=88, out_features=88, bias=False)
      (linv2): Linear(in_features=88, out_features=88, bias=False)
      (linv3): Identity()
      (lins1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins3): Identity()
    )
  )
  (convs): ModuleList(
    (0-5): 6 x DirCFConv(
      (lins): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (linv): Linear(in_features=88, out_features=88, bias=False)
    )
  )
  (predlin): MLP(
    (lin): Sequential(
      (0): Linear(in_features=88, out_features=11, bias=True)
    )
  )
  (predln): Identity()
  (vln): Sequential(
    (0): VMean()
    (1): Identity()
  )
  (elvln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (sln): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
)
numel 587323
Epoch 1 train time : 621.1 loss: 5.93e-01
 test time : 216.7 Train 0.0 Validation 0.37038373947143555 Test 0.3852885067462921
GPU memory 19.91
Epoch 2 train time : 361.9 loss: 3.58e-01
 test time : 62.2 Train 0.0 Validation 0.33345848321914673 Test 0.34514403343200684
Epoch 3 train time : 364.0 loss: 3.39e-01
 test time : 62.2 Train 0.0 Validation 0.31735551357269287 Test 0.32697153091430664
Epoch 4 train time : 359.6 loss: 3.27e-01
 test time : 62.2 Train 0.0 Validation 0.32912391424179077 Test 0.33517396450042725
Epoch 5 train time : 364.2 loss: 3.19e-01
 test time : 62.4 Train 0.0 Validation 0.30135396122932434 Test 0.3084881603717804
Epoch 6 train time : 471.6 loss: 3.15e-01
 test time : 62.2 Train 0.0 Validation 0.30785852670669556 Test 0.3149339258670807
Epoch 7 train time : 364.5 loss: 3.11e-01
 test time : 62.5 Train 0.0 Validation 0.30405935645103455 Test 0.3123975098133087
Epoch 8 train time : 363.9 loss: 3.11e-01
 test time : 62.2 Train 0.0 Validation 0.2951785624027252 Test 0.30150941014289856
Epoch 9 train time : 366.1 loss: 3.07e-01
 test time : 62.5 Train 0.0 Validation 0.2848699688911438 Test 0.2919794023036957
Epoch 10 train time : 363.5 loss: 3.06e-01
 test time : 62.2 Train 0.0 Validation 0.2857048511505127 Test 0.29258450865745544
Epoch 11 train time : 364.5 loss: 3.03e-01
 test time : 62.4 Train 0.0 Validation 0.28730928897857666 Test 0.2932293117046356
Epoch 12 train time : 363.8 loss: 3.00e-01
 test time : 62.4 Train 0.0 Validation 0.2855808436870575 Test 0.29256901144981384
Epoch 13 train time : 364.0 loss: 3.01e-01
 test time : 62.5 Train 0.0 Validation 0.2903149127960205 Test 0.2991184890270233
Epoch 14 train time : 362.6 loss: 3.01e-01
 test time : 62.5 Train 0.0 Validation 0.28136101365089417 Test 0.288180410861969
Epoch 15 train time : 365.3 loss: 2.97e-01
 test time : 62.5 Train 0.0 Validation 0.28966596722602844 Test 0.29603344202041626
Epoch 16 train time : 364.7 loss: 2.96e-01
 test time : 62.4 Train 0.0 Validation 0.27815908193588257 Test 0.2845236659049988
Epoch 17 train time : 364.7 loss: 2.95e-01
 test time : 62.3 Train 0.0 Validation 0.28016263246536255 Test 0.28686121106147766
Epoch 18 train time : 367.1 loss: 2.93e-01
 test time : 62.3 Train 0.0 Validation 0.29384204745292664 Test 0.2997365891933441
Epoch 19 train time : 365.7 loss: 2.94e-01
 test time : 62.1 Train 0.0 Validation 0.2862163782119751 Test 0.2917879819869995
Epoch 20 train time : 361.9 loss: 2.93e-01
 test time : 62.4 Train 0.0 Validation 0.31452304124832153 Test 0.32043635845184326
Epoch 21 train time : 362.8 loss: 2.92e-01
 test time : 62.1 Train 0.0 Validation 0.27709051966667175 Test 0.28377610445022583
Epoch 22 train time : 364.4 loss: 2.89e-01
 test time : 62.4 Train 0.0 Validation 0.27757740020751953 Test 0.28661075234413147
Epoch 23 train time : 362.8 loss: 2.88e-01
 test time : 62.3 Train 0.0 Validation 0.27402034401893616 Test 0.27796393632888794
Epoch 24 train time : 362.6 loss: 2.89e-01
 test time : 62.5 Train 0.0 Validation 0.2796412408351898 Test 0.28411737084388733
Epoch 25 train time : 365.1 loss: 2.88e-01
 test time : 62.3 Train 0.0 Validation 0.2764541804790497 Test 0.28315332531929016
Epoch 26 train time : 363.5 loss: 2.87e-01
 test time : 62.4 Train 0.0 Validation 0.27646681666374207 Test 0.2812737822532654
Epoch 27 train time : 363.8 loss: 2.87e-01
 test time : 62.3 Train 0.0 Validation 0.2744100093841553 Test 0.2791585922241211
Epoch 28 train time : 365.0 loss: 2.86e-01
 test time : 62.4 Train 0.0 Validation 0.277268648147583 Test 0.28311821818351746
Epoch 29 train time : 364.1 loss: 2.85e-01
 test time : 62.3 Train 0.0 Validation 0.2756258547306061 Test 0.28035667538642883
Epoch 30 train time : 362.6 loss: 2.86e-01
 test time : 62.3 Train 0.0 Validation 0.27421924471855164 Test 0.27889519929885864
Epoch 31 train time : 364.0 loss: 2.88e-01
 test time : 62.1 Train 0.0 Validation 0.28550857305526733 Test 0.29747819900512695
Epoch 32 train time : 363.7 loss: 2.89e-01
 test time : 62.3 Train 0.0 Validation 0.27373501658439636 Test 0.27810850739479065
Epoch 33 train time : 362.9 loss: 2.86e-01
 test time : 62.1 Train 0.0 Validation 0.27541640400886536 Test 0.27901434898376465
Epoch 34 train time : 365.0 loss: 2.85e-01
 test time : 62.4 Train 0.0 Validation 0.27291378378868103 Test 0.2773694097995758
Epoch 35 train time : 363.6 loss: 2.85e-01
 test time : 62.3 Train 0.0 Validation 0.28078123927116394 Test 0.2892290949821472
Epoch 36 train time : 364.7 loss: 2.84e-01
 test time : 62.3 Train 0.0 Validation 0.27319806814193726 Test 0.2777429521083832
Epoch 37 train time : 362.7 loss: 2.84e-01
 test time : 62.2 Train 0.0 Validation 0.26813873648643494 Test 0.2742113471031189
Epoch 38 train time : 365.0 loss: 2.84e-01
 test time : 62.5 Train 0.0 Validation 0.2757028043270111 Test 0.28545334935188293
Epoch 39 train time : 363.9 loss: 2.82e-01
 test time : 62.3 Train 0.0 Validation 0.28257590532302856 Test 0.29231053590774536
Epoch 40 train time : 363.1 loss: 2.82e-01
 test time : 62.4 Train 0.0 Validation 0.2740528881549835 Test 0.2806526720523834
Epoch 41 train time : 363.5 loss: 2.83e-01
 test time : 62.4 Train 0.0 Validation 0.2686932682991028 Test 0.275531142950058
Epoch 42 train time : 364.1 loss: 2.82e-01
 test time : 62.4 Train 0.0 Validation 0.27030760049819946 Test 0.2743819057941437
Epoch 43 train time : 365.0 loss: 2.81e-01
 test time : 62.1 Train 0.0 Validation 0.27290719747543335 Test 0.277100145816803
Epoch 44 train time : 360.2 loss: 2.81e-01
 test time : 62.3 Train 0.0 Validation 0.2679142653942108 Test 0.2756507694721222
Epoch 45 train time : 364.1 loss: 2.80e-01
 test time : 62.3 Train 0.0 Validation 0.2702559232711792 Test 0.27593743801116943
Epoch 46 train time : 364.3 loss: 2.81e-01
 test time : 62.2 Train 0.0 Validation 0.27316534519195557 Test 0.2810852527618408
Epoch 47 train time : 367.4 loss: 2.80e-01
 test time : 62.4 Train 0.0 Validation 0.27008602023124695 Test 0.2771931290626526
Epoch 48 train time : 362.0 loss: 2.81e-01
 test time : 62.3 Train 0.0 Validation 0.2835739254951477 Test 0.28662073612213135
Epoch 49 train time : 364.4 loss: 2.80e-01
 test time : 62.4 Train 0.0 Validation 0.276458203792572 Test 0.2820446193218231
Epoch 50 train time : 362.4 loss: 2.79e-01
 test time : 62.3 Train 0.0 Validation 0.2684662640094757 Test 0.2735684812068939
Epoch 51 train time : 363.9 loss: 2.80e-01
 test time : 62.3 Train 0.0 Validation 0.27054929733276367 Test 0.27290773391723633
Epoch 52 train time : 362.3 loss: 2.79e-01
 test time : 62.3 Train 0.0 Validation 0.2694808542728424 Test 0.27631518244743347
Epoch 53 train time : 364.0 loss: 2.79e-01
 test time : 62.4 Train 0.0 Validation 0.28134119510650635 Test 0.2867031991481781
Epoch 54 train time : 365.7 loss: 2.79e-01
 test time : 62.3 Train 0.0 Validation 0.27195674180984497 Test 0.27879244089126587
Epoch 55 train time : 364.0 loss: 2.78e-01
 test time : 62.4 Train 0.0 Validation 0.28252583742141724 Test 0.2888212502002716
Epoch 56 train time : 362.2 loss: 2.78e-01
 test time : 62.3 Train 0.0 Validation 0.2716796100139618 Test 0.2777290940284729
Epoch 57 train time : 363.9 loss: 2.77e-01
 test time : 62.3 Train 0.0 Validation 0.273468941450119 Test 0.28001031279563904
Epoch 58 train time : 367.3 loss: 2.77e-01
 test time : 62.2 Train 0.0 Validation 0.26687008142471313 Test 0.26996928453445435
Epoch 59 train time : 365.2 loss: 2.78e-01
 test time : 62.3 Train 0.0 Validation 0.2707993686199188 Test 0.2776795029640198
Epoch 60 train time : 367.8 loss: 2.77e-01
 test time : 62.4 Train 0.0 Validation 0.26824697852134705 Test 0.27383071184158325
Epoch 61 train time : 363.8 loss: 2.77e-01
 test time : 62.3 Train 0.0 Validation 0.2746768295764923 Test 0.2835950553417206
Epoch 62 train time : 361.0 loss: 2.78e-01
 test time : 62.3 Train 0.0 Validation 0.27065610885620117 Test 0.2792048752307892
Epoch 63 train time : 362.8 loss: 2.77e-01
 test time : 62.2 Train 0.0 Validation 0.265900194644928 Test 0.27119356393814087
Epoch 64 train time : 363.4 loss: 2.76e-01
 test time : 62.3 Train 0.0 Validation 0.27315953373908997 Test 0.27777689695358276
Epoch 65 train time : 361.2 loss: 2.76e-01
 test time : 62.4 Train 0.0 Validation 0.2767164409160614 Test 0.28371429443359375
Epoch 66 train time : 365.8 loss: 2.78e-01
 test time : 62.4 Train 0.0 Validation 0.26615285873413086 Test 0.2722192406654358
Epoch 67 train time : 363.4 loss: 2.77e-01
 test time : 62.3 Train 0.0 Validation 0.2713395655155182 Test 0.2791425883769989
Epoch 68 train time : 363.6 loss: 2.76e-01
 test time : 62.4 Train 0.0 Validation 0.27698633074760437 Test 0.2816872000694275
Epoch 69 train time : 366.1 loss: 2.76e-01
 test time : 62.3 Train 0.0 Validation 0.27648821473121643 Test 0.2827598452568054
Epoch 70 train time : 363.1 loss: 2.75e-01
 test time : 62.3 Train 0.0 Validation 0.26718735694885254 Test 0.27324050664901733
Epoch 71 train time : 364.6 loss: 2.75e-01
 test time : 62.3 Train 0.0 Validation 0.26553088426589966 Test 0.27163031697273254
Epoch 72 train time : 364.5 loss: 2.77e-01
 test time : 62.2 Train 0.0 Validation 0.27703583240509033 Test 0.28237512707710266
Epoch 73 train time : 363.7 loss: 2.74e-01
 test time : 62.3 Train 0.0 Validation 0.2716362178325653 Test 0.2781882882118225
Epoch 74 train time : 360.7 loss: 2.75e-01
 test time : 62.3 Train 0.0 Validation 0.26509717106819153 Test 0.270956814289093
Epoch 75 train time : 362.0 loss: 2.72e-01
 test time : 62.3 Train 0.0 Validation 0.2670888602733612 Test 0.27205729484558105
Epoch 76 train time : 365.6 loss: 2.70e-01
 test time : 62.2 Train 0.0 Validation 0.2667452096939087 Test 0.2694578468799591
Epoch 77 train time : 361.2 loss: 2.65e-01
 test time : 62.4 Train 0.0 Validation 0.26164376735687256 Test 0.2673989236354828
Epoch 78 train time : 365.8 loss: 2.62e-01
 test time : 62.4 Train 0.0 Validation 0.25926893949508667 Test 0.2629179358482361
Epoch 79 train time : 363.3 loss: 2.59e-01
 test time : 62.3 Train 0.0 Validation 0.2574447691440582 Test 0.2619633972644806
Epoch 80 train time : 360.9 loss: 2.57e-01
 test time : 62.1 Train 0.0 Validation 0.25821059942245483 Test 0.2614728510379791
Best @78 validation score: 0.2574 Test score: 0.2620
[[78, tensor(0.2574), tensor(0.2620)]]
all runs:  78.0 0.2574447691440582 0.2619633972644806 0.0 0.0 0.0 
