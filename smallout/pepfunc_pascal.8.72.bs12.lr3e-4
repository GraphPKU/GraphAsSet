/ceph/home/muhan01/wangxiyuan/GraphAsSet/utils.py:20: UserWarning: not equivalent to Identity
  warnings.warn("not equivalent to Identity")
Namespace(dataset='pepfunc', repeat=1, num_workers=0, amp=True, compile=True, batch_size=12, testbatch_size=12, epochs=80, wd=0.1, lr=0.0003, beta=0.9, minlr=0.0, K=0.0, gradclipnorm=1.0, decompnoise=1e-06, seedoffset=0, warmstart=8, conststep=84, cosstep=8, use_y_scale=False, dp=0.0, eldp=0.0, act='silu', lossparam=0.0, advloss=False, embdp=0.0, embbn=False, emborthoinit=False, degreeemb=False, embln=True, featdim=-1, hiddim=72, caldim=-1, normA=False, laplacian=True, sqrtlambda=True, elres=True, usesvmix=True, vmean=True, vnorm=True, elvmean=True, elvnorm=True, snorm=True, gsizenorm=1.85, l_encoder='deepset', l_layers=3, l_combine='mul', l_aggr='mean', l_res=True, l_mlptailact1=True, l_mlplayers1=2, l_mlpnorm1='ln', l_mlptailact2=False, l_mlplayers2=0, l_mlpnorm2='none', num_layers=8, sv_uselinv=True, sv_tailact=True, sv_res=True, sv_numlayer=1, sv_norm='none', el_uselinv=True, el_uselins=False, el_tailact=True, el_numlayer=2, el_norm='none', el_uses=False, conv_uselinv=True, conv_tailact=True, conv_numlayer=1, conv_norm='none', predlin_numlayer=1, predlin_norm='none', lexp='mlp', lexp_layer=2, lexp_norm='ln', outln=False, pool='mean', Tm=1, save='pepfunc.8.72.wd1e-1', load=None, use_pos=False, align_size=32)
fixed bincls
10873 2331 2331
split 10873 2331 2331
num_task 10
PiOModel(
  (inputencoder): QInputEncoder(
    (xemb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0): Embedding(18, 72, padding_idx=0)
        (1): Embedding(4, 72, padding_idx=0)
        (2-3): 2 x Embedding(8, 72, padding_idx=0)
        (4): Embedding(6, 72, padding_idx=0)
        (5): Embedding(2, 72, padding_idx=0)
        (6): Embedding(7, 72, padding_idx=0)
        (7-8): 2 x Embedding(3, 72, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((72,), eps=1e-05, elementwise_affine=False)
      )
    )
    (edgeEmb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0-2): 3 x Embedding(5, 72, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((72,), eps=1e-05, elementwise_affine=False)
      )
    )
    (LambdaEmb): MLPEncoding(
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=1, out_features=144, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((144,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=144, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (LambdaEncoder): PermEquiLayer(
    (set2set): Sequential(
      (0): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (1): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (2): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((72,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (3): Identity()
    )
    (set2vec): Sequential(
      (0): MLP(
      (lin): Sequential(
        (0): NoneNorm()
      )
    )
    )
  )
  (elprojs): ModuleList(
    (0-7): 8 x sv2el(
      (linv1): Linear(in_features=72, out_features=72, bias=False)
      (linv2): Linear(in_features=72, out_features=72, bias=False)
      (lins1): Identity()
      (lins2): Identity()
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
          (3): Linear(in_features=72, out_features=72, bias=True)
          (4): NoneNorm()
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (svmixs): ModuleList(
    (0-7): 8 x svMix(
      (linv1): Linear(in_features=72, out_features=72, bias=False)
      (linv2): Linear(in_features=72, out_features=72, bias=False)
      (linv3): Identity()
      (lins1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins3): Identity()
    )
  )
  (convs): ModuleList(
    (0-7): 8 x DirCFConv(
      (lins): MLP(
        (lin): Sequential(
          (0): Linear(in_features=72, out_features=72, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (linv): Linear(in_features=72, out_features=72, bias=False)
    )
  )
  (predlin): MLP(
    (lin): Sequential(
      (0): Linear(in_features=72, out_features=10, bias=True)
    )
  )
  (predln): Identity()
  (vln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (elvln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (sln): LayerNorm((72,), eps=1e-05, elementwise_affine=False)
)
numel 499618
Epoch 1 train time : 798.0 loss: 4.87e-01
 test time : 395.2 Train 0.0 Validation 0.2554118037223816 Test 0.2536579966545105
GPU memory 40.52
Epoch 2 train time : 418.7 loss: 3.28e-01
 test time : 76.7 Train 0.0 Validation 0.2999379634857178 Test 0.3002169728279114
Epoch 3 train time : 420.1 loss: 3.20e-01
 test time : 75.2 Train 0.0 Validation 0.3291134834289551 Test 0.3332131505012512
Epoch 4 train time : 415.5 loss: 3.08e-01
 test time : 75.7 Train 0.0 Validation 0.3567051291465759 Test 0.3635367155075073
Epoch 5 train time : 420.1 loss: 2.98e-01
 test time : 76.1 Train 0.0 Validation 0.3857007324695587 Test 0.3870038688182831
Epoch 6 train time : 469.9 loss: 2.90e-01
 test time : 75.9 Train 0.0 Validation 0.3973696827888489 Test 0.3928989768028259
Epoch 7 train time : 421.4 loss: 2.85e-01
 test time : 76.7 Train 0.0 Validation 0.4021685719490051 Test 0.4013669490814209
Epoch 8 train time : 418.4 loss: 2.80e-01
 test time : 76.0 Train 0.0 Validation 0.41525864601135254 Test 0.40732675790786743
Epoch 9 train time : 417.7 loss: 2.76e-01
 test time : 75.4 Train 0.0 Validation 0.4365456700325012 Test 0.4280542731285095
Epoch 10 train time : 413.7 loss: 2.71e-01
 test time : 76.1 Train 0.0 Validation 0.44178062677383423 Test 0.4230618476867676
Epoch 11 train time : 416.2 loss: 2.66e-01
 test time : 76.0 Train 0.0 Validation 0.44970399141311646 Test 0.4326913356781006
Epoch 12 train time : 414.7 loss: 2.63e-01
 test time : 75.9 Train 0.0 Validation 0.4722859263420105 Test 0.4471905827522278
Epoch 13 train time : 418.1 loss: 2.58e-01
 test time : 76.1 Train 0.0 Validation 0.47652697563171387 Test 0.44915255904197693
Epoch 14 train time : 419.6 loss: 2.54e-01
 test time : 76.0 Train 0.0 Validation 0.4994870126247406 Test 0.4774846136569977
Epoch 15 train time : 419.4 loss: 2.50e-01
 test time : 75.3 Train 0.0 Validation 0.49751394987106323 Test 0.48200497031211853
Epoch 16 train time : 418.7 loss: 2.48e-01
 test time : 76.0 Train 0.0 Validation 0.5025081038475037 Test 0.4928678572177887
Epoch 17 train time : 416.0 loss: 2.45e-01
 test time : 76.1 Train 0.0 Validation 0.5057498216629028 Test 0.4987197816371918
Epoch 18 train time : 415.1 loss: 2.40e-01
 test time : 75.9 Train 0.0 Validation 0.5183030366897583 Test 0.5029550790786743
Epoch 19 train time : 420.1 loss: 2.37e-01
 test time : 76.0 Train 0.0 Validation 0.528558611869812 Test 0.5054401755332947
Epoch 20 train time : 417.8 loss: 2.33e-01
 test time : 75.9 Train 0.0 Validation 0.5463439226150513 Test 0.5236300230026245
Epoch 21 train time : 416.8 loss: 2.32e-01
 test time : 76.0 Train 0.0 Validation 0.5424932837486267 Test 0.5219751596450806
Epoch 22 train time : 417.0 loss: 2.27e-01
 test time : 76.0 Train 0.0 Validation 0.5321647524833679 Test 0.5203987956047058
Epoch 23 train time : 416.5 loss: 2.27e-01
 test time : 75.9 Train 0.0 Validation 0.5423380136489868 Test 0.5202193260192871
Epoch 24 train time : 412.0 loss: 2.24e-01
 test time : 75.8 Train 0.0 Validation 0.5622760057449341 Test 0.5435953140258789
Epoch 25 train time : 418.9 loss: 2.21e-01
 test time : 75.1 Train 0.0 Validation 0.5401185750961304 Test 0.5325161814689636
Epoch 26 train time : 417.0 loss: 2.20e-01
 test time : 76.1 Train 0.0 Validation 0.5556216239929199 Test 0.5477981567382812
Epoch 27 train time : 417.9 loss: 2.17e-01
 test time : 76.1 Train 0.0 Validation 0.5530668497085571 Test 0.5357603430747986
Epoch 28 train time : 416.0 loss: 2.16e-01
 test time : 76.1 Train 0.0 Validation 0.5747604966163635 Test 0.550192654132843
Epoch 29 train time : 419.4 loss: 2.14e-01
 test time : 75.7 Train 0.0 Validation 0.5532150864601135 Test 0.5397880673408508
Epoch 30 train time : 419.0 loss: 2.12e-01
 test time : 76.1 Train 0.0 Validation 0.5769773721694946 Test 0.5576686859130859
Epoch 31 train time : 415.2 loss: 2.10e-01
 test time : 76.0 Train 0.0 Validation 0.5722934007644653 Test 0.5525467991828918
Epoch 32 train time : 414.3 loss: 2.08e-01
 test time : 75.9 Train 0.0 Validation 0.574847936630249 Test 0.5516101121902466
Epoch 33 train time : 418.0 loss: 2.07e-01
 test time : 75.3 Train 0.0 Validation 0.5860530734062195 Test 0.5544633269309998
Epoch 34 train time : 415.6 loss: 2.05e-01
 test time : 75.9 Train 0.0 Validation 0.588591456413269 Test 0.561351478099823
Epoch 35 train time : 415.0 loss: 2.03e-01
 test time : 75.7 Train 0.0 Validation 0.5923501253128052 Test 0.5709518194198608
Epoch 36 train time : 416.2 loss: 2.03e-01
 test time : 75.8 Train 0.0 Validation 0.5842532515525818 Test 0.5688546299934387
Epoch 37 train time : 417.0 loss: 2.00e-01
 test time : 75.8 Train 0.0 Validation 0.5824981927871704 Test 0.5560054183006287
Epoch 38 train time : 416.4 loss: 1.99e-01
 test time : 75.8 Train 0.0 Validation 0.577576756477356 Test 0.5559436678886414
Epoch 39 train time : 415.1 loss: 1.98e-01
 test time : 75.8 Train 0.0 Validation 0.5761399269104004 Test 0.5667998790740967
Epoch 40 train time : 414.5 loss: 1.95e-01
 test time : 76.0 Train 0.0 Validation 0.5949102640151978 Test 0.5844286680221558
Epoch 41 train time : 420.7 loss: 1.94e-01
 test time : 75.7 Train 0.0 Validation 0.5919310450553894 Test 0.5748074650764465
Epoch 42 train time : 418.4 loss: 1.93e-01
 test time : 76.1 Train 0.0 Validation 0.593887448310852 Test 0.5672149658203125
Epoch 43 train time : 421.4 loss: 1.91e-01
 test time : 76.0 Train 0.0 Validation 0.5817427039146423 Test 0.5692951083183289
Epoch 44 train time : 420.7 loss: 1.91e-01
 test time : 75.9 Train 0.0 Validation 0.5872077941894531 Test 0.5614386200904846
Epoch 45 train time : 419.3 loss: 1.90e-01
 test time : 75.9 Train 0.0 Validation 0.6093929409980774 Test 0.5938811898231506
Epoch 46 train time : 417.0 loss: 1.88e-01
 test time : 76.0 Train 0.0 Validation 0.5942773222923279 Test 0.5881089568138123
Epoch 47 train time : 418.9 loss: 1.85e-01
 test time : 75.9 Train 0.0 Validation 0.6089497208595276 Test 0.5888898372650146
Epoch 48 train time : 418.7 loss: 1.85e-01
 test time : 76.0 Train 0.0 Validation 0.6031631827354431 Test 0.5876539349555969
Epoch 49 train time : 413.0 loss: 1.82e-01
 test time : 75.6 Train 0.0 Validation 0.6116827726364136 Test 0.5967455506324768
Epoch 50 train time : 415.2 loss: 1.81e-01
 test time : 75.9 Train 0.0 Validation 0.6087788939476013 Test 0.5908476114273071
Epoch 51 train time : 419.1 loss: 1.80e-01
 test time : 75.9 Train 0.0 Validation 0.5933893918991089 Test 0.5947971343994141
Epoch 52 train time : 416.1 loss: 1.79e-01
 test time : 77.2 Train 0.0 Validation 0.6070596575737 Test 0.6027511358261108
Epoch 53 train time : 416.2 loss: 1.78e-01
 test time : 76.1 Train 0.0 Validation 0.6134236454963684 Test 0.5918687582015991
Epoch 54 train time : 418.0 loss: 1.77e-01
 test time : 75.7 Train 0.0 Validation 0.618955135345459 Test 0.5985246896743774
Epoch 55 train time : 417.8 loss: 1.77e-01
 test time : 76.1 Train 0.0 Validation 0.6090828776359558 Test 0.5908926725387573
Epoch 56 train time : 418.8 loss: 1.75e-01
 test time : 76.1 Train 0.0 Validation 0.6027376651763916 Test 0.5972946286201477
Epoch 57 train time : 413.7 loss: 1.73e-01
 test time : 75.8 Train 0.0 Validation 0.584382176399231 Test 0.5747877359390259
Epoch 58 train time : 418.4 loss: 1.73e-01
 test time : 75.8 Train 0.0 Validation 0.6127763986587524 Test 0.613057553768158
Epoch 59 train time : 416.5 loss: 1.71e-01
 test time : 76.1 Train 0.0 Validation 0.6004418134689331 Test 0.5860604047775269
Epoch 60 train time : 418.9 loss: 1.71e-01
 test time : 75.1 Train 0.0 Validation 0.6135550141334534 Test 0.5998947024345398
Epoch 61 train time : 418.5 loss: 1.69e-01
 test time : 76.0 Train 0.0 Validation 0.6222450137138367 Test 0.6116929650306702
Epoch 62 train time : 415.9 loss: 1.68e-01
 test time : 75.2 Train 0.0 Validation 0.6148994565010071 Test 0.599766731262207
Epoch 63 train time : 416.8 loss: 1.68e-01
 test time : 75.7 Train 0.0 Validation 0.6188222765922546 Test 0.5943259000778198
Epoch 64 train time : 415.1 loss: 1.66e-01
 test time : 77.4 Train 0.0 Validation 0.621158242225647 Test 0.6111608743667603
Epoch 65 train time : 419.0 loss: 1.65e-01
 test time : 76.0 Train 0.0 Validation 0.6051927804946899 Test 0.6102185249328613
Epoch 66 train time : 416.9 loss: 1.65e-01
 test time : 76.0 Train 0.0 Validation 0.6142736673355103 Test 0.5979379415512085
Epoch 67 train time : 418.5 loss: 1.64e-01
 test time : 77.5 Train 0.0 Validation 0.6158043146133423 Test 0.6062303781509399
Epoch 68 train time : 417.1 loss: 1.63e-01
 test time : 76.1 Train 0.0 Validation 0.6030276417732239 Test 0.6088811159133911
Epoch 69 train time : 417.3 loss: 1.61e-01
 test time : 76.1 Train 0.0 Validation 0.6312845945358276 Test 0.616875946521759
Epoch 70 train time : 417.4 loss: 1.60e-01
 test time : 75.3 Train 0.0 Validation 0.6183763146400452 Test 0.6114840507507324
Epoch 71 train time : 415.4 loss: 1.61e-01
 test time : 76.1 Train 0.0 Validation 0.6166017055511475 Test 0.609500527381897
Epoch 72 train time : 422.1 loss: 1.58e-01
 test time : 76.1 Train 0.0 Validation 0.5872936248779297 Test 0.5944653749465942
Epoch 73 train time : 417.2 loss: 1.57e-01
 test time : 76.6 Train 0.0 Validation 0.6184593439102173 Test 0.6013627052307129
Epoch 74 train time : 417.5 loss: 1.56e-01
 test time : 76.1 Train 0.0 Validation 0.6016924977302551 Test 0.5843015909194946
Epoch 75 train time : 417.0 loss: 1.56e-01
 test time : 76.1 Train 0.0 Validation 0.615760862827301 Test 0.6066792011260986
Epoch 76 train time : 417.8 loss: 1.55e-01
 test time : 77.3 Train 0.0 Validation 0.6259740591049194 Test 0.607819676399231
Epoch 77 train time : 417.8 loss: 1.55e-01
 test time : 76.3 Train 0.0 Validation 0.6039608716964722 Test 0.5980004668235779
Epoch 78 train time : 413.6 loss: 1.52e-01
 test time : 75.3 Train 0.0 Validation 0.6238011717796326 Test 0.6100993752479553
Epoch 79 train time : 415.2 loss: 1.53e-01
 test time : 76.1 Train 0.0 Validation 0.609186589717865 Test 0.5942612886428833
Epoch 80 train time : 413.2 loss: 1.50e-01
 test time : 75.3 Train 0.0 Validation 0.6114071607589722 Test 0.6111241579055786
Best @68 validation score: 0.6313 Test score: 0.6169
[[68, tensor(0.6313), tensor(0.6169)]]
all runs:  68.0 0.6312845945358276 0.616875946521759 0.0 0.0 0.0 
