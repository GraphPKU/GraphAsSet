/ceph/home/muhan01/wangxiyuan/GraphAsSet/utils.py:20: UserWarning: not equivalent to Identity
  warnings.warn("not equivalent to Identity")
Namespace(dataset='pepstruct', repeat=1, num_workers=0, amp=True, compile=True, batch_size=6, testbatch_size=6, epochs=80, wd=0.1, lr=0.0003, beta=0.9, minlr=0.0, K=0.0, gradclipnorm=1.0, decompnoise=1e-06, seedoffset=0, warmstart=8, conststep=64, cosstep=8, use_y_scale=False, dp=0.0, eldp=0.0, act='silu', lossparam=0.0, advloss=False, embdp=0.0, embbn=False, emborthoinit=False, degreeemb=False, embln=True, featdim=-1, hiddim=88, caldim=-1, normA=False, laplacian=True, sqrtlambda=True, elres=True, usesvmix=True, vmean=True, vnorm=True, elvmean=True, elvnorm=True, snorm=True, gsizenorm=1.85, l_encoder='deepset', l_layers=3, l_combine='mul', l_aggr='mean', l_res=True, l_mlptailact1=True, l_mlplayers1=2, l_mlpnorm1='ln', l_mlptailact2=False, l_mlplayers2=0, l_mlpnorm2='none', num_layers=6, sv_uselinv=True, sv_tailact=True, sv_res=True, sv_numlayer=1, sv_norm='none', el_uselinv=True, el_uselins=False, el_tailact=True, el_numlayer=2, el_norm='none', el_uses=False, conv_uselinv=True, conv_tailact=True, conv_numlayer=1, conv_norm='none', predlin_numlayer=1, predlin_norm='none', lexp='mlp', lexp_layer=2, lexp_norm='ln', outln=False, pool='mean', Tm=1, save='pepstruct.wd1e-1', load=None, use_pos=False, align_size=32)
fixed l1reg
10873 2331 2331
split 10873 2331 2331
num_task 11
PiOModel(
  (inputencoder): QInputEncoder(
    (xemb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0): Embedding(18, 88, padding_idx=0)
        (1): Embedding(4, 88, padding_idx=0)
        (2-3): 2 x Embedding(8, 88, padding_idx=0)
        (4): Embedding(6, 88, padding_idx=0)
        (5): Embedding(2, 88, padding_idx=0)
        (6): Embedding(7, 88, padding_idx=0)
        (7-8): 2 x Embedding(3, 88, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
      )
    )
    (edgeEmb): MultiEmbedding(
      (embedding_list): ModuleList(
        (0-2): 3 x Embedding(5, 88, padding_idx=0)
      )
      (postemb): Sequential(
        (0): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
      )
    )
    (LambdaEmb): MLPEncoding(
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=1, out_features=176, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((176,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=176, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (LambdaEncoder): PermEquiLayer(
    (set2set): Sequential(
      (0): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (1): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (2): Set2Set(
      (mlp1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
      (mlp2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): LayerNorm(
            (norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)
          )
          (5): SiLU(inplace=True)
        )
      )
    )
      (3): Identity()
    )
    (set2vec): Sequential(
      (0): MLP(
      (lin): Sequential(
        (0): NoneNorm()
      )
    )
    )
  )
  (elprojs): ModuleList(
    (0-5): 6 x sv2el(
      (linv1): Linear(in_features=88, out_features=88, bias=False)
      (linv2): Linear(in_features=88, out_features=88, bias=False)
      (lins1): Identity()
      (lins2): Identity()
      (lin): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
          (3): Linear(in_features=88, out_features=88, bias=True)
          (4): NoneNorm()
          (5): SiLU(inplace=True)
        )
      )
    )
  )
  (svmixs): ModuleList(
    (0-5): 6 x svMix(
      (linv1): Linear(in_features=88, out_features=88, bias=False)
      (linv2): Linear(in_features=88, out_features=88, bias=False)
      (linv3): Identity()
      (lins1): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins2): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (lins3): Identity()
    )
  )
  (convs): ModuleList(
    (0-5): 6 x DirCFConv(
      (lins): MLP(
        (lin): Sequential(
          (0): Linear(in_features=88, out_features=88, bias=True)
          (1): NoneNorm()
          (2): SiLU(inplace=True)
        )
      )
      (linv): Linear(in_features=88, out_features=88, bias=False)
    )
  )
  (predlin): MLP(
    (lin): Sequential(
      (0): Linear(in_features=88, out_features=11, bias=True)
    )
  )
  (predln): Identity()
  (vln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (elvln): Sequential(
    (0): VMean()
    (1): VNorm()
  )
  (sln): LayerNorm((88,), eps=1e-05, elementwise_affine=False)
)
numel 587323
Epoch 1 train time : 1114.9 loss: 5.33e-01
 test time : 692.4 Train 0.0 Validation 0.350379079580307 Test 0.3630825877189636
GPU memory 19.32
Epoch 2 train time : 392.1 loss: 3.59e-01
 test time : 64.0 Train 0.0 Validation 0.3206862509250641 Test 0.32903212308883667
Epoch 3 train time : 375.3 loss: 3.35e-01
 test time : 63.8 Train 0.0 Validation 0.29810866713523865 Test 0.3055395781993866
Epoch 4 train time : 371.1 loss: 3.24e-01
 test time : 64.0 Train 0.0 Validation 0.3020572364330292 Test 0.30760541558265686
Epoch 5 train time : 385.3 loss: 3.28e-01
 test time : 70.4 Train 0.0 Validation 0.2997269630432129 Test 0.30728861689567566
Epoch 6 train time : 512.2 loss: 3.17e-01
 test time : 75.9 Train 0.0 Validation 0.28973710536956787 Test 0.29572972655296326
Epoch 7 train time : 407.0 loss: 3.16e-01
 test time : 72.9 Train 0.0 Validation 0.2937001585960388 Test 0.3013533353805542
Epoch 8 train time : 381.2 loss: 3.15e-01
 test time : 63.8 Train 0.0 Validation 0.29044240713119507 Test 0.29508674144744873
Epoch 9 train time : 374.6 loss: 3.10e-01
 test time : 64.0 Train 0.0 Validation 0.2867255210876465 Test 0.29094398021698
Epoch 10 train time : 373.6 loss: 3.07e-01
 test time : 63.9 Train 0.0 Validation 0.30899450182914734 Test 0.3159753382205963
Epoch 11 train time : 396.3 loss: 3.03e-01
 test time : 71.9 Train 0.0 Validation 0.2837858200073242 Test 0.2878304123878479
Epoch 12 train time : 402.3 loss: 3.00e-01
 test time : 77.0 Train 0.0 Validation 0.27741539478302 Test 0.2802708148956299
Epoch 13 train time : 416.2 loss: 2.98e-01
 test time : 75.1 Train 0.0 Validation 0.2845686674118042 Test 0.2912510633468628
Epoch 14 train time : 381.5 loss: 2.96e-01
 test time : 64.4 Train 0.0 Validation 0.3060600161552429 Test 0.31055399775505066
Epoch 15 train time : 374.1 loss: 2.92e-01
 test time : 63.7 Train 0.0 Validation 0.27967822551727295 Test 0.28371521830558777
Epoch 16 train time : 373.3 loss: 2.92e-01
 test time : 63.7 Train 0.0 Validation 0.280985027551651 Test 0.28193947672843933
Epoch 17 train time : 395.2 loss: 2.91e-01
 test time : 70.2 Train 0.0 Validation 0.29539790749549866 Test 0.29783618450164795
Epoch 18 train time : 400.3 loss: 2.89e-01
 test time : 75.0 Train 0.0 Validation 0.28830471634864807 Test 0.289145290851593
Epoch 19 train time : 419.3 loss: 2.89e-01
 test time : 75.4 Train 0.0 Validation 0.28134188055992126 Test 0.2828911244869232
Epoch 20 train time : 378.9 loss: 2.88e-01
 test time : 64.1 Train 0.0 Validation 0.2902676463127136 Test 0.2939182221889496
Epoch 21 train time : 374.2 loss: 2.88e-01
 test time : 64.4 Train 0.0 Validation 0.27562716603279114 Test 0.27898794412612915
Epoch 22 train time : 374.8 loss: 2.86e-01
 test time : 64.4 Train 0.0 Validation 0.27745965123176575 Test 0.2830241620540619
Epoch 23 train time : 394.3 loss: 2.85e-01
 test time : 71.1 Train 0.0 Validation 0.2715749740600586 Test 0.2739325761795044
Epoch 24 train time : 405.7 loss: 2.85e-01
 test time : 76.2 Train 0.0 Validation 0.2727571725845337 Test 0.2741134464740753
Epoch 25 train time : 420.3 loss: 2.84e-01
 test time : 75.5 Train 0.0 Validation 0.27295610308647156 Test 0.2742633819580078
Epoch 26 train time : 379.9 loss: 2.84e-01
 test time : 63.5 Train 0.0 Validation 0.2694838047027588 Test 0.27440381050109863
Epoch 27 train time : 374.0 loss: 2.86e-01
 test time : 64.0 Train 0.0 Validation 0.27255040407180786 Test 0.27683284878730774
Epoch 28 train time : 375.6 loss: 2.83e-01
 test time : 64.3 Train 0.0 Validation 0.28569671511650085 Test 0.2848568856716156
Epoch 29 train time : 391.9 loss: 2.83e-01
 test time : 67.6 Train 0.0 Validation 0.28709685802459717 Test 0.28790083527565
Epoch 30 train time : 399.6 loss: 2.82e-01
 test time : 74.1 Train 0.0 Validation 0.28002703189849854 Test 0.2827520966529846
Epoch 31 train time : 404.1 loss: 2.81e-01
 test time : 73.2 Train 0.0 Validation 0.28779685497283936 Test 0.2883702516555786
Epoch 32 train time : 383.2 loss: 2.80e-01
 test time : 64.0 Train 0.0 Validation 0.2725928723812103 Test 0.27459073066711426
Epoch 33 train time : 375.8 loss: 2.81e-01
 test time : 63.7 Train 0.0 Validation 0.26920774579048157 Test 0.2725994884967804
Epoch 34 train time : 374.7 loss: 2.80e-01
 test time : 63.7 Train 0.0 Validation 0.2684018611907959 Test 0.27084094285964966
Epoch 35 train time : 397.1 loss: 2.80e-01
 test time : 69.9 Train 0.0 Validation 0.2990087866783142 Test 0.3059122562408447
Epoch 36 train time : 399.0 loss: 2.79e-01
 test time : 73.9 Train 0.0 Validation 0.2690453827381134 Test 0.2721448838710785
Epoch 37 train time : 417.0 loss: 2.79e-01
 test time : 74.9 Train 0.0 Validation 0.2706867456436157 Test 0.2699795961380005
Epoch 38 train time : 383.7 loss: 2.79e-01
 test time : 63.8 Train 0.0 Validation 0.26860129833221436 Test 0.27221089601516724
Epoch 39 train time : 373.8 loss: 2.78e-01
 test time : 63.9 Train 0.0 Validation 0.2809099555015564 Test 0.28814464807510376
Epoch 40 train time : 373.7 loss: 2.78e-01
 test time : 63.8 Train 0.0 Validation 0.26926854252815247 Test 0.2744349539279938
Epoch 41 train time : 394.4 loss: 2.78e-01
 test time : 69.1 Train 0.0 Validation 0.26839086413383484 Test 0.2734261751174927
Epoch 42 train time : 400.0 loss: 2.77e-01
 test time : 75.4 Train 0.0 Validation 0.26924023032188416 Test 0.2725810706615448
Epoch 43 train time : 419.0 loss: 2.76e-01
 test time : 77.2 Train 0.0 Validation 0.26688146591186523 Test 0.267394483089447
Epoch 44 train time : 377.0 loss: 2.76e-01
 test time : 63.8 Train 0.0 Validation 0.27236178517341614 Test 0.2740574777126312
Epoch 45 train time : 374.0 loss: 2.78e-01
 test time : 63.6 Train 0.0 Validation 0.27280235290527344 Test 0.2759539783000946
Epoch 46 train time : 374.1 loss: 2.76e-01
 test time : 63.9 Train 0.0 Validation 0.26879000663757324 Test 0.27353841066360474
Epoch 47 train time : 395.0 loss: 2.77e-01
 test time : 69.5 Train 0.0 Validation 0.29035061597824097 Test 0.29879605770111084
Epoch 48 train time : 400.0 loss: 2.76e-01
 test time : 76.3 Train 0.0 Validation 0.27469494938850403 Test 0.27851009368896484
Epoch 49 train time : 419.1 loss: 2.75e-01
 test time : 75.5 Train 0.0 Validation 0.27050289511680603 Test 0.27062055468559265
Epoch 50 train time : 379.5 loss: 2.76e-01
 test time : 64.1 Train 0.0 Validation 0.273282915353775 Test 0.2798689007759094
Epoch 51 train time : 374.6 loss: 2.75e-01
 test time : 63.8 Train 0.0 Validation 0.2682872414588928 Test 0.27139636874198914
Epoch 52 train time : 372.7 loss: 2.77e-01
 test time : 63.6 Train 0.0 Validation 0.27669820189476013 Test 0.27845171093940735
Epoch 53 train time : 390.3 loss: 2.74e-01
 test time : 68.4 Train 0.0 Validation 0.3091450333595276 Test 0.3171294331550598
Epoch 54 train time : 403.5 loss: 2.74e-01
 test time : 74.6 Train 0.0 Validation 0.26442280411720276 Test 0.26864513754844666
Epoch 55 train time : 419.5 loss: 2.75e-01
 test time : 75.4 Train 0.0 Validation 0.26631397008895874 Test 0.2688923478126526
Epoch 56 train time : 376.6 loss: 2.72e-01
 test time : 64.5 Train 0.0 Validation 0.26588699221611023 Test 0.2719508409500122
Epoch 57 train time : 374.3 loss: 2.74e-01
 test time : 65.1 Train 0.0 Validation 0.2765210270881653 Test 0.2833957374095917
Epoch 58 train time : 377.2 loss: 2.73e-01
 test time : 63.3 Train 0.0 Validation 0.2658504247665405 Test 0.2716441750526428
Epoch 59 train time : 396.0 loss: 2.73e-01
 test time : 66.6 Train 0.0 Validation 0.28154149651527405 Test 0.28303298354148865
Epoch 60 train time : 402.3 loss: 2.73e-01
 test time : 74.1 Train 0.0 Validation 0.26963290572166443 Test 0.277063250541687
Epoch 61 train time : 419.6 loss: 2.73e-01
 test time : 75.3 Train 0.0 Validation 0.2758884131908417 Test 0.28069737553596497
Epoch 62 train time : 377.4 loss: 2.73e-01
 test time : 64.1 Train 0.0 Validation 0.27651911973953247 Test 0.28112590312957764
Epoch 63 train time : 374.7 loss: 2.74e-01
 test time : 64.5 Train 0.0 Validation 0.2673918604850769 Test 0.26887276768684387
Epoch 64 train time : 373.7 loss: 2.72e-01
 test time : 65.0 Train 0.0 Validation 0.26970046758651733 Test 0.27008092403411865
Epoch 65 train time : 390.7 loss: 2.72e-01
 test time : 70.8 Train 0.0 Validation 0.2667466104030609 Test 0.26978832483291626
Epoch 66 train time : 401.7 loss: 2.74e-01
 test time : 75.6 Train 0.0 Validation 0.2692394256591797 Test 0.2710953950881958
Epoch 67 train time : 416.8 loss: 2.72e-01
 test time : 75.1 Train 0.0 Validation 0.26340121030807495 Test 0.26953354477882385
Epoch 68 train time : 381.0 loss: 2.72e-01
 test time : 63.9 Train 0.0 Validation 0.270345538854599 Test 0.2725156247615814
Epoch 69 train time : 374.8 loss: 2.72e-01
 test time : 63.7 Train 0.0 Validation 0.2629718780517578 Test 0.2669113874435425
Epoch 70 train time : 373.2 loss: 2.73e-01
 test time : 63.8 Train 0.0 Validation 0.2703794240951538 Test 0.27461880445480347
Epoch 71 train time : 395.3 loss: 2.72e-01
 test time : 68.9 Train 0.0 Validation 0.26827189326286316 Test 0.27412405610084534
Epoch 72 train time : 401.7 loss: 2.72e-01
 test time : 75.6 Train 0.0 Validation 0.28112977743148804 Test 0.2899342179298401
Epoch 73 train time : 417.2 loss: 2.70e-01
 test time : 75.6 Train 0.0 Validation 0.27327415347099304 Test 0.28065794706344604
Epoch 74 train time : 376.9 loss: 2.69e-01
 test time : 64.2 Train 0.0 Validation 0.26668456196784973 Test 0.273636132478714
Epoch 75 train time : 371.1 loss: 2.66e-01
 test time : 64.1 Train 0.0 Validation 0.2620942294597626 Test 0.2680979371070862
Epoch 76 train time : 374.9 loss: 2.61e-01
 test time : 63.5 Train 0.0 Validation 0.2580379843711853 Test 0.2601093053817749
Epoch 77 train time : 391.4 loss: 2.55e-01
 test time : 71.1 Train 0.0 Validation 0.2564223110675812 Test 0.2641899287700653
Epoch 78 train time : 402.7 loss: 2.51e-01
 test time : 75.2 Train 0.0 Validation 0.2597869336605072 Test 0.27090996503829956
Epoch 79 train time : 416.1 loss: 2.46e-01
 test time : 73.5 Train 0.0 Validation 0.25394734740257263 Test 0.25888410210609436
Epoch 80 train time : 379.8 loss: 2.43e-01
 test time : 63.7 Train 0.0 Validation 0.25210291147232056 Test 0.25867101550102234
Best @79 validation score: 0.2521 Test score: 0.2587
[[79, tensor(0.2521), tensor(0.2587)]]
all runs:  79.0 0.25210291147232056 0.25867101550102234 0.0 0.0 0.0 
